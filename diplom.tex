\documentclass[a4paper, 12pt, DIVcalc, onepage, pdftex, headsepline, footsepline]{scrreprt}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{setspace}
\onehalfspacing

\usepackage[ngerman]{babel}
\usepackage{natbib}
\bibliographystyle{dinat}
\usepackage{url} %correct url display in cites

\usepackage[locale=DE]{siunitx}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}

\definecolor{light-gray}{gray}{0.95}

\lstset{%
basicstyle=\scriptsize,
backgroundcolor=\color{light-gray}
}

\pagestyle{headings}

\typearea[current]{calc}

%add hyphenation later

\begin{document}
\title{Visuell programmierbarer Non-Standard-Informationsvisualisierer}
\author{Benjamin Knofe}
\subject{Diplomarbeit}
\publishers{Hochschule für Technik, Wirtschaft und Kultur Leipzig}
\dedication{Dank an \\ Christina Sanko, Pyry Jahkola, Ted Mosby, Sarah Walter, Professor Dr. Robert Müller, Philip Whitfield}
\maketitle
\tableofcontents

\chapter{Einleitung}
\label{cha:Einleitung}
Die Menge an digital gespeicherten Daten nimmt stetig zu. Im Jahr 2011 werden laut einer neuen
Studie\footnote{Vgl. \citep{EMC}} voraussichtlich 1,8 Zettabyte\footnote{1 Zettabyte = \num{1d21}
Byte = 1.000.000.000.000 Gigabyte} an Daten erzeugt und kopiert. In nahezu allen Bereichen unseres
täglichen Lebens werden Daten erhoben, gemessen und gespeichert. Neben der Wissenschaft, Wirtschaft
und Kultur, verfolgen öffentliche Bereiche der Politik und Verwaltung eine neue Strategie im Umgang
mit Daten. So haben Städte wie beispielsweise Leipzig eine öffentliche Datenschnittstelle oder
Staaten wie Großbritannien verfolgen ein ganzheitliches Konzept des e-Government. Aufgrund dieser
aktuellen Entwicklung ist es notwendig, neue Strategien zu entwickeln, die diese Daten
für die jeweiligen Zielgruppen sinnvoll extrahieren, aufarbeiten und darstellen. Aus diesem
Grund wurden in verschiedenen Forschungsfeldern, wie beispielsweise Statistik, Data Mining,
Computergrafik und Informatik spezielle Lösungsansätze entwickelt. Ein Forschungsgebiet verbindet diese
Ansätze, um den aktuellen Entwicklungen unserer digitalen Welt Rechnung zu tragen: die Informationsvisualisierung.
In diesem Forschungsgebiet wird die Frage geklärt, wie immer abstrakter und komplexer werdende Daten
in einer für den Menschen adäquaten Weise aufbereitet und dargestellt werden können, um die gewünschten
Informationen in Form von Mustern, Wiederholungen und Anomalien identifizieren zu können und damit wichtige
Rückschlüsse auf den eigentlichen Forschungsgegenstand ziehen zu können. Ursprünglich aus dem rein
wissenschaftlichen Kontext kommend, zeichnet sich eine Entwicklung hin zu einem populäreren Arbeitsfeld ab,
um auch alltägliche Probleme mithilfe der Informationsvisualisierung lösen zu können.
Auch wenn die Informationsvisualisierung konkrete Ziele hat, mit denen sehr spezielle Probleme gelöst
werden, addressieren diese nicht mehr nur Experten und Wissenschaftler. Auch alltägliche Anwendungen
im Bereich der sozialen Netzwerke, beim Onlineshopping oder beim Einkauf im Supermarkt und bei der Suche nach Informationen
im Internet oder in der Bibliothek können mit der Informationsvisualisierung unterstützt
werden. Benutzerschnittstellen können somit verständlicher und benutzerfreundlicher gestaltet werden.
Die Informationsvisualisierung soll darüberhinaus ansprechend sein, um eine angenehme und ästhetisch ansprechende Benutzung
gewährleisten zu können, aber gleichzeitig auch intuitiv sein, um ohne Vorkenntnisse Nutzen aus
dieser Form der Mensch-Maschine-Interaktion ziehen zu können. Damit kann es auch Gelegenheitsanwendern
leicht gemacht werden, Informationen und
Wissen noch besser mit anderen kommunizieren und teilen zu können. Das erfordert (digitale) Werkzeuge,
die den Benutzer unterstützen und ihm die Möglichkeit geben, diese Daten für seine Problemlösung nutzen zu können.
Um die Informationsvisualisierung erfolgreich einsetzen zu können, muss eine Vielzahl von Fragstellungen
beantwortet und gelöst werden.
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/beispiel.pdf}
\caption{Beispiel einer Informationsvisualisierung aus \citep[S.\,76]{McCandless}}
\label{fig:beispiel}
\end{figure}
\section{Problemstellung}
Abbildung \ref{fig:beispiel} zeigt beispielhaft eine Informationsvisualisierung.\footnote{In dieser
Informationsvisualisierung wird die unterschiedliche Bedeutung von Farben in unterschiedlichen
Kulturkreisen dargestellt. Die einzelnen Ringe der kreisförmigen Darstellung bilden zehn
unterschiedliche Kulturkreise ab. Der Kreis ist unterteilt in 84 unterschiedliche Bedeutungen.
Der Farbton der Rechtecke stellt dar, welche Farbe einem Begriff zugeordnet wird.}
Sie wurde von David McCandless mit einem Vektorgrafikprogramm erstellt, um
eine tiefgreifende Auseinandersetzung zwischen ihm (als menschlichen Betrachter) und den Informationen
zu ermöglichen und Entscheidungen über das Design direkt treffen zu können.\footnote{Vgl. \citep{infoblog}} Der Nachteil dieser
Arbeitsweise ist eine zeitaufwändige manuelle Transkription aller Datenwerte in eine grafische
Darstellung. Bei der Visualisierung von komplexeren Zusammenhängen und größeren Datenmengen würde dieser 
Nachteil noch verstärkt werden und es teilweise unmöglich machen eine Visualisierung durchzuführen.

In dieser Arbeit soll untersucht werden, ob es möglich und sinnvoll ist, diesen Prozess  zu automatisieren,
ohne Einschränkungen für den Anwender festlegen zu müssen.
Eine Software muss dafür einen universellen Ansatz verfolgen, um ein möglichst breites Spektrum an
unterschiedlichsten Bearbeitungsfällen abdecken zu können. 
Aktuelle Softwarestandards wie beispielsweise Tabellenkalkulationsprogramme oder Programmierbibliotheken
können das nur teilweise leisten oder beschränken sich auf spezielle Anwendungsgebiete.
Meist kann dabei, für die Transformation von Daten zu einer grafischen Darstellung, nur
aus einer begrenzten Auswahl an Voreinstellungen ausgewählt werden.

Um eine möglichst universelle Software zu konzipieren, die dem Benutzer größtmögliche
Gestaltungsfreiheit einräumt, sind folgende Vorüberlegungen notwendig:
\begin{itemize}
\item{Welche Art von Daten gibt es und wie können diese klassifiziert werden?}
\item{Welche Möglichkeiten der grafischen Darstellung gibt es und wie können diese eingesetzt werden?}
\item{Wie können Daten sinnvoll in eine grafische Darstellung transkribiert werden?}
\end{itemize}
Diese Vorüberlegungen fordern ein Softwarekonzept, das den Anwender besonders bei der 
arbeitsintensiven Transkription
von Daten in eine grafische Darstellung unterstützt. Um eine passende Metapher für diesen Arbeitsprozess zu benutzen,
sollte diese Software durch visuelle Programmierung steuerbar sein. Damit kann die Verbindung zwischen Datenobjekten
und Grafikobjekten auch auf der Benutzeroberfläche deutlich gemacht werden.
Um eine iterative und kreative Benutzung zu ermöglichen, muss der arbeitsintensive Vorgang
der Transkription großer Datenmengen in eine grafische Darstellung
automatisch und unmittelbar erfolgen.
Eine auf diese Aspekte spezialisierte Software konnte bei der
Recherche für diese Arbeit nicht gefunden werden. Die Konzeption einer solchen Software ist Gegenstand dieser Arbeit.
\section{Aufbau der Arbeit}
Um einen Lösungansatz für das Problem einer universellen Informationsvisualisierung
zu finden, werden in dieser Arbeit Schritte durchgeführt, die die Konzeption einer Software zum Ziel haben.
Diese Software wird prototypisch implementiert.

In Kapitel \ref{cha:Grundlagen} im Abschnitt \ref{sec:DatenInfo} werden die Begriffe Daten und
Informationen definiert und im Kontext der Informationsvisualisierung betrachtet.
Im Abschnitt \ref{sec:EigenschaftenDaten} werden die
unterschiedlichen Eigenschaften von Daten untersucht. Mit diesem Kriterienkatalog können Daten im
Abschnitt \ref{sec:KlassifikationDaten} klassifiziert werden.
Im folgenden Abschnitt \ref{sec:Datentypen} werden die verschiedenen Datentypen behandelt, die die eigentlichen
Datenwerte beschreiben.
Abschnitt \ref{sec:grafischeSemiologie} beschreibt ein System zur Klassifikation von grafischen Variablen,
die grundlegenden Elemente einer grafischen Darstellung.
Die Information, die in unterschiedlichen Klassen von Daten codiert ist, und das visuelle Zeichensystem bilden
die "`Rohstoffe"' für die Informationsvisualisierung, die im Kapitel \ref{cha:Informationsvisualisierung}
beschrieben wird. Abschnitt \ref{sec:Definition} definiert den Begriff
der Informationsvisualisierung, die als eine Weiterentwicklung der wissenschaftlichen
Datenvisualisierung beschrieben wird. Danach folgt im Abschnitt \ref{sec:Arbeitsfelder} eine Abgrenzung zu den verwandten
Arbeitsfeldern, die mit den Techniken Informationsvisualisierung arbeiten oder Teilbereiche der Informationsvisualisierung
sind. Welche Ziele eine Informationsvisualisierung hat und wie man diese klassifizieren und bewerten kann wird
im Abschnitt \ref{sec:Ziele} behandelt. Im folgenden Abschnitt \ref{sec:Pipeline} wird der eigentliche Arbeitsablauf
einer Informationsvisualisierung anhand verschiedener Arbeitsschritte beschrieben um im Abschnitt
\ref{sec:Darstellungen} die grafische Darstellung und deren Formen als Ergebnis dessen zu zeigen.

Das Kapitel \ref{cha:Software} beschreibt nun die Konzeption einer Informationsvisualisierungssoftware.
Dabei wird im Abschnitt \ref{sec:Grundprinzip} noch einmal das Grundprinzip der Informationsvisualisierung
beschrieben und eine Einordnung der Software in den Visualisierungsprozess vorgenommen.
Im Abschnitt \ref{sec:Rahmenbedingungen} werden die Rahmenbedingungen der Software festgelegt um im Abschnitt
\ref{sec:Anforderungen} Anforderungen definieren zu können. Der Abschnitt \ref{sec:bestehendeSoftware}
zeigt exemplarisch vorhandene Softwarelösungen.

Im Kapitel \ref{cha:Umsetzung} wird die Implementation eines Prototyps dokumentiert. Dabei wird in Abschnitt
\ref{sec:Technologien} auf die verwendeten Technologien eingegangen. Danach wird in Abschnitt
\ref{sec:visPro} das Konzept der visuellen Programmierung als wesentliches Merkmal der Benutzerinteraktion
beschrieben und Gründe für diese Entscheidung genannt.
Als letzter Punkt dieses Kapitels werden in Abschnitt \ref{sec:Kernfunktionen} beispielhaft Kernfunktionen
der Software mit Quelltext gezeigt und erläutert.

Das vorletzte Kapitel \ref{cha:Auswertung} nennt in Abschnitt \ref{sec:Probleme} die Probleme, die während
der Entwicklung aufgetreten sind und wertet die Vorteile (Abschnitt \ref{sec:Vorteile}) und Nachteile
(Abschnitt \ref{sec:Nachteile}) aus.

Das Kapitel \ref{cha:Zusammenfassung} schließt die Arbeit mit einem Fazit in Abschnitt \ref{sec:Fazit} und
einem Ausblick in Abschnitt \ref{sec:Ausblick} ab.

\chapter{Grundlagen}
\label{cha:Grundlagen}
Dieser Teil der Arbeit beschreibt die grundlegenden Begriffe, die einen Zugang
zum Arbeitsfeld der Informationsvisualisierung ermöglichen.
\section{Daten und Information}
\label{sec:DatenInfo}
Daten werden in \citep{Gabler} als "`zum Zweck der Verarbeitung zusammengefasste Zeichen,
die aufgrund bekannter oder unterstellter Abmachungen
Informationen (d.h. Angaben über Sachverhalte und Vorgänge) darstellen"', beschrieben.
Als Gegenstand dieser Arbeit werden digital gespeicherte Daten betrachtet.
Diese liegen in einer standardisierten Form vor und können für die elektrische Weiterverarbeitung
und Kommunikation genutzt werden. Diese Daten sind dabei formalisierte Repäsentationen einer
oder mehrerer Informationen, die übermittelt werden sollen.
Daten können dabei aus der realen Welt stammen, beispielsweise erhoben durch
die Messung einer physikalischen Größe, oder sie wurden digital erzeugt, beispielsweise durch
computergestützte Simulationen oder durch die Nutzung von Telekommunikationstechnik.
Der Anwender dieser Daten ist nicht direkt an den Daten als solche interessiert, sondern
an den Informationen und dem aus ihnen resultierenden Erkenntnisgewinn, die er mit verschiedenen
Techniken aus diesen Daten gewinnen kann.

Der Begriff der Information ist schwer einzugrenzen und wird in unterschiedlichen Wissenschaften
in verschiedenen Formen ausgelegt. Der philosophische Bereich der Erkenntnistheorie versucht
einen allgemeingültigen Informationsbegriff zu definieren. Trotzdem kann noch nicht von einer
einheitlichen Theorie der Information gesprochen werden und es beschäftigen sich viele verschiedene
Gebiete wie die Informatik, Informationstheorie, Nachrichtentechnik und andere mit diesem
Begriff.\footnote{Vgl. \citep{wiki_info}} In \citep[S.\,3]{Hoeher} wird die Information wie folgt beschrieben:
\begin{quote}
"`Die Informationstheorie definiert Information als eine quantitativ bestimmbare Wissenzunahme durch
die Übermittlung von Zeichen in einem Kommunikationssystem."'
\end{quote}
Information ist das Ergebnis der Kommunikation, das beim Empfänger einen Erkenntnisgewinn auslöst,
sofern dieser den Informationsinhalt entschlüsseln kann. Dafür müssen sich Sender und Empfänger
auf ein Zeichensystem einigen.
In Bezug auf grafische Darstellungen wird in \citep{Bertin} die Information als der transkribierbare
Inhalt eines Gedankens definiert, das heißt die Information ist der Teil der Daten, die in einer
Informationsvisualisierung dargestellt werden kann. Die Informationsvisualisierung als solche hat die
Aufgabe, diese Information für den Menschen aufzudecken und in verständlicher Form aufzubereiten.
Die reinen Daten, die zwar diese Informationen enthalten,
aber für den menschlichen Betrachter nicht erfassbar sind, werden in ein grafisches
Zeichensystem transformiert. Dieses grafische System erlaubt dem Menschen eine natürliche, visuelle und
damit effektivere Analyse.

\section{Eigenschaften von Daten}
\label{sec:EigenschaftenDaten}
In diesem Kapitel werden die Eigenschaften von Daten beschrieben. Sie bestimmen wie die eigentlichen Informationen
in den Daten codiert sind.
Digitale Daten gelten als Ausgangspunkt für die Konzeption einer Informationsvisualisierung. Die speziellen
Eigenschaften von Daten sind maßgeblich für weitere Schritte der Informationsvisualisierung.\footnote{Vgl. 
Abschnitt \ref{sec:Pipeline}}
Die Kenntnis der Beschaffenheit der Daten ist somit Voraussetzung für alle nachfolgenden Schritte.
\citep{Schumann} beschreiben ein Modell der Eigenschaften von Daten. Jeder Datensatz\footnote{Menge von Daten}
hat folgende Eigenschaften nach denen er klassifiziert werden kann:
\begin{description}
\item[Beobachtungsraum]
Der Beobachtungsraum beschreibt den Raum in dem Daten erhoben werden. Dieser Raum kann ein
dreidimensionaler Raum sein, kann aber auch abstrakt beschrieben werden und nur eine einzige oder
mehr als drei Dimensionen besitzen. Alle Dimensionen des Beobachtungsraumes werden als \textit{unabhängige
Variablen} bezeichnet, da sie vor der Datenerhebung festgelegt werden und als beschreibende Begriffe für
den zu visualisierenden Sachverhalt gelten.\footnote{\citep[S.\,24]{Bertin} bezeichnet die unabhängigen
Variablen als Invariante und definiert: "`Die Invariante ist der vollständige und in bezug auf alle vorgegebenen
Begriffe invariable Kennzeichnungsbegriff."'} Im Beispiel aus Abbildung \ref{fig:beispiel} sind die
unabhängigen Variablen die gewählten Kulturkreise und die verschiedenen Begriffe.
\item[Beobachtungspunkt]
Ein Beobachtungspunkt beschreibt eine Position im Beobachtungsraum an dem Daten vorhanden sind. Die Anzahl und Verteilung
der Beobachtunspunkte ist unabhängig von der Beschaffenheit des Beobachtungsraumes. Beobachtunsgpunkte haben einen
Wirkungskreis, der die "räumliche" Gültigkeit der Werte beschreibt. Dieser kann punktuell, lokal oder global sein.
Im Beispiel aus Abbildung \ref{fig:beispiel} sind alle farbigen Rechtecke im Kreis Beobachtungspunkte, denn an
diesen konnte ein zugehöriger Farbwert recherchiert werden.
\item[Merkmal]
Das Merkmal ist eine Größe, die an einem Beobachtungspunkt gemessen oder berechnet wurde. Dabei kann
ein Beobachtungspunkt mehrere Merkmale besitzen. Merkmale werden als \textit{abhängige Variablen} bezeichnet, da
sie abhängig von der Position des Beobachtungspunktes im Beobachtungsraum sind.
Im Beispiel aus Abbildung \ref{fig:beispiel} ist das der Farbton eines Rechtecks im Kreis.
\item[Ausprägung]
Die Ausprägung beschreibt den eigentlichen Wert, den ein Merkmal annehmen kann. Dieser Wert hat einen
Wertebereich und kann ein Skalar, Vektor oder Tensor sein.\footnote{In einem dreidimensionalen Beobachtungsraum
kann der Beobachtungspunkt auch als Vektor angesehen werden. Im Falle einer Ausprägung als Vektor, liegt damit
an der Position des Beobachtungspunktes im Beobachtungsraum ein weiterer Vektor vor. Ein Tensor ist ein mathematisches
Objekt, dass als mehrdimensionale Matrix abgebildet werden kann.}
In Abbildung \ref{fig:beispiel} ist beispielsweise im amerikanischen Kulturkreis (A) für Liebe (53) die Farbe
Rot ablesbar. Der dazugehörige Wertebereich der Farben wird im oberen linken Bereich dargestellt.
\end{description}
Die Begriffe Beobachtungsraum, Beobachtungspunkt, Merkmal und Ausprägung dienen zur Klassifikation von Daten
und werden als Metadaten bezeichnet.

\section{Klassifikation von Daten}
\label{sec:KlassifikationDaten}

Die Klassifikation von Daten wird sehr unterschiedlich durchgeführt.
\citep{Schumann} weisen auf eine uneinheitliche Begriffswahl in unterschiedlichen
Publikationen hin.
Um eine für diese Arbeit sinnvolle Einteilung zu finden, wird diese stark vereinfacht dargestellt und nach der Anzahl der abhängigen und
unabhängigen Variablen und nach dem Ursprung der Daten vorgenommen.

\subsection{Mehrdimensionale Daten}
Ein Beobachtungsraum kann beliebig viele, ganzzahlige und positive Dimensionen haben. Ist die Anzahl
dieser \textit{unabhängigen} Variablen größer Eins, spricht man von \textit{mehrdimensionalen Daten}. Das Beispiel
in Abbildung \ref{fig:beispiel} hat zwei Dimensionen und damit zwei unabhängige
Variablen (Kulturkreis und Begriff).

Eine Sonderform der mehrdimensionalen Daten sind die raumbezogenen Daten.
"Raumbezogene Daten liegen dann vor, wenn der Beobachtungsraum Ortskoordinaten enthält,
die ein 2- oder 3-dimensionales räumliches Bezugssystem definieren."\citep[S.\,220]{Schumann}
Beispielsweise bedeutet das, dass mindestens zwei und höchsten drei unabhängige Variablen des Datensatzes
ein Koordinatensystem beschreiben können. Diese Form der Informationsvisualisierung findet häufig
in Geoinformationssystemen (GIS) Anwendung.

In Bezug auf den Beobachtungsraum sind die zeitbezogenen Daten ein weiterer Spezialfall.
Dabei ist eine unabhängige Variable mit der physikalischen Größe Zeit assoziiert.
Dieser Bezug entspricht nicht immer den tatsächlichen zeitlichen Änderungen und macht
eine adäquate Skalierung der zeitbezogenen Dimension notwendig.
Beispielsweise kann bei einer Wetterstation die kontinuierliche Veränderung der Aussentemperatur
nur jede Stunde gemessen werden und liegt dadurch in diskreten Intervallen vor.
Diese Problematik muss in der Visualisierung beachtet werden.

\subsection{Multiparameterdaten}
Daten werden als \textit{Multiparameterdaten} bezeichnet, wenn die Anzahl der \textit{abhängigen} Variablen größer Eins ist
und der Beobachtungsraum nicht vernachlässigt werden kann. Das setzt komplexere
Informationsvisualisierungen voraus, da unabhängige und abhängige Variablen gemeinsam
dargestellt werden müssen. Die Unterscheidbarkeit zwischen diesen Klassen muss dabei
erhalten bleiben.
Ein Beispiel für einen Multiparameterdatensatz ist eine Liste mit Wetterstationen, die durch ihre
Koordinaten bestimmt sind. Zusätzlich dazu liegen für jede Wetterstation unterschiedliche
Daten für Temperatur, Luftdruck und Niederschlag vor.\footnote{Das Beispiel aus Abbildung
\ref{fig:beispiel} ist kein Multiparameterdatensatz, da nur der Farbton der Rechtecke als
abhängige Variable bezeichnet werden kann. Durch zusätzliche Informationen könnten die
zugrundeliegenden Daten aber zu einem Multiparameterdatensatz erweitert werden. Beispielsweise
könnte die Wichtigkeit der einzelnen Begriffe in einem Kulturkreis in der Größe der
Farbfläche dargestellt werden. So würde zum Beispiel der Begriff "`Religion"' (48) für
bestimmte Kulturkreise größer dargestellt werden. Andere Farbflächen erscheinen dagegen
kleiner.}

Eine Sonderform der Multiparameterdaten sind die multivariaten Daten. Dabei kann
der Beobachtungsraum vernachlässigt werden, da er keine Rolle bei der Weiterverarbeitung
der Daten spielt. Multivariate Daten können in mehrdimensionale Daten überführt werden,
wenn für jedes vorhandene Merkmal eine Dimension in einem neuen Beobachtungsraum
aufgespannt wird.\footnote{Vgl. \citep[S.\,172]{Schumann}}

\subsection{Abstrakte Daten}
Die wissenschaftlich-technischen Datenvisualisierung ist auf physikalische Daten fokussiert.
Das können Daten über die menschliche Anatomie, das Universum oder über Moleküle und Atome sein. Diese Daten
haben immer einen räumlichen Bezug. Visualisierungen von Abstraktionen des physikalischen Raums
sind möglich, trotzdem hat die zugrundeliegende Information eine geometrische Natur.\footnote{Vgl. \citep[S.\,6]{Card}}
Fehlt ein physikalischer Raumbezug oder ist er nicht sinnvoll, werden Daten als \textit{abstrakte Daten} bezeichnet.
Abstrakte Daten werden meist in rein digitalen und virtuellen Prozessen erzeugt. Als Beispiel
können Verbindungsstatistiken von Netzwerkbetreibern, die Struktur eines Dateisystems auf einer
Festplatte oder Texte und Quellcode von Programmen genannt werden.

Eine spezielle Form der abstrakten Daten sind strukturelle Beziehungen zwischen Datenobjekten.
Diese Daten beschreiben nicht Beobachtungspunkte und deren Merkmale, sondern die Beziehungen
zwischen diesen Punkten und ihren abhängigen und unabhängigen Variablen. Unterschieden wird dabei
zwischen hierarchischen Formen und Netzwerken. Beispiele sind die Relationen zwischen Dokumenten,
Medien und Personen in einem Netzwerk.\footnote{Vgl. \citep{Preim}}

Rein zeitbezogene Daten werden in dieser Arbeit den abstrakten Daten zugeordnet. Zwar ist die Zeit eine physikalische
Größe, kann aber nur sehr schwer dargestellt werden. Ein Börsenkurs ist bei näherer Betrachtung
abstrakt, da kein räumlicher Bezug stattfinden kann.
Die einfache Abbildung in einem Diagramm, bei dem die Zeit auf der X-Achse und der Wert einer Aktie auf der Y-Achse
abgebildet sind, sind nur erlernte Metaphern. Die "`Höhe"' des Aktienwertes stellt dabei keinesfalls eine räumliche
Höhe dar, sondern eine abstrakte Wertebeschreibung. Somit wird ganz im Zeichen der Informationsvisualisierung versucht,
einen fehlenden räumlichen Bezug zu konstruieren.

Die Informationsvisualisierung, wie sie in Kapitel \ref{cha:Informationsvisualisierung} beschrieben wird, benutzt
vorrangig \textit{abstrakte Multiparameterdaten} als Grundlage einer grafischen Darstellung.

\section{Datentypen}
\label{sec:Datentypen}
Datentypen beschreiben die eigentlichen Ausprägungen eines Merkmals und können zu einer zusätzlichen
Klassifikation beitragen. Das ist wichtig um erkennen zu können welche Verarbeitungschritte mit den Daten
möglich sind. Meist erfolgt eine Einteilung in drei Klassen. Während \citep{Bertin} von qualitativen,
geordneten und quantitativen Komponenten spricht, unterscheiden \citep{Preim} nominale, ordinale und
quantitative Datentypen.
In dieser Arbeit wird die neuere Einteilung aus \citep{Preim} beschrieben.
\begin{description}
\item[Nominale Datentypen]
beschreiben meist Namen von Datenobjekten. Ihr Abstand ist äquidistant, da vor einer eingehenden Analyse sich
keine Ausprägungen besonders nah oder entfernt voneinander zeigen. Die einzige mögliche Operation ist der Test auf
Gleichheit beziehungsweise Ungleichheit. Es gibt keine allgemeingültige, eindeutige Reihenfolge
nach der die Ausprägungen sortiert werden könnten. Dadurch kann nur eine Reihenfolge nach bestimmten Gesichtpunkten erfolgen,
das heißt eine künstlich erzeugte Ordnung eingebracht werden, zum Beispiel durch alphabetische Sortierung von Namen.
\item[Ordinale Datentypen]
haben die gleichen Eigenschaften wie nominale Typen.
Nur die Reihenfolge ist bei diesem Typ allgemeingültig festgelegt. Dadurch kann als zusätzlicher Operator die Richtung der
Ausprägung durch die Ordnungsrelation genutzt werden.
\item[Quantitative Datentypen] besitzen einen Wertebereich und gestatten die Durchführung von arithmetischen Operationen. Es existiert eine
Maßeinheit, mit der die Abstände zwischen einzelnen Ausprägungen angegeben werden können. Durch eine 
künstliche Einteilung in Intervalle kann dieser Typ in ordinale Datentypen übersetzt werden. Beispiel
dafür sind Temperaturwerte, die in kalt, warm und heiß unterteilt werden.
\end{description}
\section{Grafische Semiologie}
\label{sec:grafischeSemiologie}
Die grafische Semiologie ist ein in \citep{Bertin} erstmals beschriebenes System zur Klassifikation von grafischen Zeichen.
Es stammt ursprünglich aus der thematischen Kartographie.\footnote{"`Thematische Karten enthalten vorwiegend
Erscheinungen oder Vorkommnisse nicht topographischer Art welche jedoch mit der Erdoberfläche in Verbindung
stehen. Es handelt sich hierbei um Dinge, die georäumliche Lage, Verbreitung oder Bewegung besitzen, sowohl
um reale Dinge, als auch um Beziehungen, Funktionen, Hypothesen, geistige Vorstellungen, Möglichkeiten und
Projekte."'\citep{Gitta} } Dies ist ein Teilgebiet der Geographie, eines der ersten Anwendungsgebiete der
Informationsvisualisierung.
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/visuelleVariablen.pdf}
\caption{visuelle Variablen aus \citep[S.\,51]{Bertin}}
\label{fig:visuelleVariablen}
\end{figure}
Diese Theorie definiert ein "`Grundalphabet"' an grafischen Elementen, wobei zur Informationsübertragung
jedem einzelnen Zeichen eine bestimmte Bedeutung zugeordnet wird. \citep{Bertin} geht dabei von einem
monosemiotischen\footnote{"`Die Betrachtung einer Zeichenverbindung setzt die Kenntnis der Bedeutung jedes
einzelnen Zeichens voraus."'\citep[S.\,3]{Bertin}} System aus, das den rationalen Teil der Bilderwelt, die
grafische Darstellung, eindeutig beschreibt.
Da Menschen aber bestimmten grafischen Zeichen unterschiedliche Bedeutungen zuordnen, muss ein "`rationaler Moment"'
stattfinden, bei dem sich alle an der Kommunikation Beteiligten auf Bedeutungen einigen,
die bestimmte Zeichen in der grafischen Darstellung haben. Erst dann kann über die Verbindung der Zeichen untereinander dikstutiert
werden. Diese Verbindungen entsprechen der eigentlichen Information. Beispielsweise kann
durch die Position von grafischen Primitiven untereinander Aussagen über ihre eigentlichen Beziehungen getroffen werden.
Dabei spielen die Gestaltungsgesetze eine wichtige Rolle.
Mit der grafischen Semiologie können also Informationen in ein grafische Zeichensystem
transkribiert werden. Dieses System umfasst folgende acht Zeichen, die zur Kodierung von Daten in eine grafische Darstellung benutzt
werden können. Sie werden visuelle Variablen genannt und beschreiben die Eigenschaften geometrischer Primitive.
\begin{itemize}
\item Position auf der Ebene (angegeben durch x und y)
\item Größe (Fläche oder Länge)
\item Helligkeitswert
\item Musterung oder Textur
\item Farbe
\item Richtung oder Orientierung
\item Form des Elements
\end{itemize}
In Abbildung \ref{fig:visuelleVariablen} werden diese dargestellt.
Jede dieser Variablen hat spezifische Eigenschaften, die sie unterschiedlich gut oder schlecht
für spezielle Aufgaben eignen. Um für eine Aufgabe die geeignetste Variable zu bestimmen, schlägt
\citep{Bertin} mehrere Konstruktionsregeln vor.
Grundlegend beschreiben diese eine Vereinfachung der grafischen Darstellung.
Die Anzahl an visuellen Variablen, Merkmalen und Ausprägungen wird reduziert,
sodass die grafische Darstellung als Ganzes mit einem Minimum an Wahrnehmungsaufwand erfasst werden kann.
Dabei dürfen keine Informationen und Beziehungen zwischen diesen verloren gehen, um Fehlinterpretationen
zu vermeiden. Weitere Regeln sind stark abhängig von der Anzahl
der vorhandenen Dimensionen des Beobachtungsraumes, der Anzahl der Merkmale eines
Beobachtungspunktes\footnote{Vgl. Abschnitt \ref{sec:EigenschaftenDaten}} und der gewählten
grafischen Darstellung. Da für die komplexen graphischen Darstellungen einer 
Informationsvisualisierung meist mehrere visuelle Variablen gebraucht werden, sollte sich die Auswahl
an den Bearbeitungszielen\footnote{Vgl. Abschnitt \ref{sec:Ziele}} orientieren.
So sollten beispielsweise für wichtige, geordnete Variablen die Position in der Ebene verwendet werden,
während Variablen wie Farbe, Muster und Textur als weitere Möglichkeit genutzt werden können, um Informationen zu kodieren.
Erst wenn zusätzliche Variablen hinzugefügt werden, sollte eine Nebeneinanderstellung oder
Überlagerung in Betracht gezogen werden.
Durch die Anwendung der Konstruktionsregeln können die visuellen Variablen genutzt werden, um
die grafische Darstellung als Ziel der Informationsvisualisierung zu konstruieren.

\chapter{Informationsvisualisierung}
\label{cha:Informationsvisualisierung}
\section{Definition}
\label{sec:Definition}
Die Visualisierung ist im allgemeinen als eine "rechnergestützte, visuelle Präsentation von Daten, Informationen und Wissen
in einer für den Menschen adäquaten und für die jeweilige Anwendung in diesem Kontext sinnvollen Form
zu verstehen."\citep[S.\,3]{Schumann}
Die rein wissenschaftlich-technische Visualisierung arbeitet ausschließlich mit Ausgangsdaten,
die einen physikalischen Bezugsrahmen und somit einen konkreten Orts- und Zeitbezug haben. Diese Form der
Visualiserung wird auch Datenvisualisierung genannt.
Die Informationstheorie geht hauptsächlich von einem quantitativen Informationsbegriff aus.\footnote{Vgl. 
Abschnitt \ref{sec:DatenInfo}} Für die Visualisierung von Informationen sind aber
weiterführende, qualitative Fragen von Bedeutung:
\begin{itemize}
\item Was macht eine Information wichtig oder unwichtig in einem gegebenen Kontext?
\item Wie kann das Verständnis von großen Informationsmengen für Menschen vereinfacht werden?
\item Wie können Informationen visuell aufbereitet werden, um eine effizientere Problemlösung möglich zu machen?
\end{itemize}
Diese Fragen, die aufgrund eines wachsenden Spektrums an abstrakten Daten immer wichtiger werden,
versucht die Informationsvisualisierung zu beantworten.
\citep[S.\,434]{Preim} definieren Informationsvisualisierung folgendermaßen:
\begin{quote}
"`Informationsvisualisierung beschäftigt sich mit der Visualisierung vorrangig abstrakter Daten, wie
Multiparameterdaten(z.B. Medienobjekte mit verschiedenen Attributen), Hierarchien, Netzwerken, Text
oder Softwaresystemen, die sich alle auch über die Zeit verändern können."'
\end{quote}
Das Einsatzgebiet der Informationsvisualisierung ist im Gegensatz zur Datenvisualisierung nicht mehr
auf wissenschaftliche Bereiche beschränkt,
sondern wird auch als alternative Suchmethode in Datenbanken\footnote{Vgl. Visual Data Mining in \citep{Keim}},
als Wissensvermittlung in kulturellen Bereichen\footnote{Vgl. Abbildung \ref{fig:beispiel}} und zur Visualisierung von
sozialen Netzwerken und Fahrplänen von öffentlichen Verkehrsmitteln verwendet.
Insbesondere steht die Suche nach Beziehungen zwischen Datenobjekten im Vordergrund,
da Informationsräume größer, komplexer und vernetzter werden und im Gegensatz
zu physikalischen Daten nicht immer ein räumlicher Bezug existiert.
Eine Aufgabe der Informationsvisualiserung ist es, diesen Ortsbezug beim Betrachter wieder gedanklich
entstehen zu lassen, um den kognitiven Aufwand, der für das Verständnis der Daten nötig ist, zu minimieren.

Durch die Verschiebung der Daten aus dem wissenschaftlichen Kontext
in die Alltagskultur, ändert sich die Zielgruppe der Visualisierung. Durch das Internet
wird der Personenkreis stark vergrößert, der ein Interesse und Nutzen an Informationsvisualisierungen
hat, aber dem ein mathematischer, natur- oder ingeneurswissenschaftlicher Hintergrund
fehlt. Daraus entstehen weitere Anforderungen. So muss die Informationsvisualisierung vom Benutzer
schnell und einfach erfasst und ohne Vorkenntnisse verstanden werden können.
Außerdem muss sie eine "`angemessene und grafische Qualität haben, um über den
reinen Nutzwert hinaus auch Qualitäten in Bezug auf Nutzungsfreude und Unterhaltungswert [zu] besitzen"'\citep[S.\,438]{Preim}.
Dafür reichen einfache Datentabellen und Tabellenkalkulationsprogramme
nicht mehr aus, um notwendige alternative Darstellungsformen zu finden.

Die Grenzen zwischen den einzelnen Disziplinen sind fließend 
und eine genaue Beschreibung dieser steht noch aus. Die Informationsvisualisierung kann
auch wissenschaftlich betrieben werden, da sich Methoden und Verfahren stark ähneln.
Das Arbeitsfeld der Informationsvisualisierung, die Thema dieser Arbeit ist, adressiert damit
einen Spezialfall der Datenvisualisierung, der alle Anforderungen an Datenvisualisierung enthält
und mit zusätztlichen Anforderungen, wie Zielgruppe, Repräsentation und Medium, erweitert. Digitale
Techniken werden zur Erhebung, Speicherung, Weiterverarbeitung und Ausgabe genutzt.

\section{Verwandte Arbeitsfelder}
\label{sec:Arbeitsfelder}
Oft berühren Teilgebiete der Informationsvisualiserung verwandte Arbeitsfelder oder werden für die Problemlösung
in anderen Bereichen verwendet.
Nachfolgend werden Arbeitsgebiete beschrieben, die häufig mit der Informationsvisualisierung in Verbindung
gebracht oder verwechselt werden. Meist sind die diese nicht klar
voneinander trennbar oder eine genauere Abgrenzung ist noch Forschungsgegenstand. Die nachfolgende Liste beschreibt nur
eine Auswahl und erhebt keinen Anspruch auf Vollständigkeit.
\begin{description}
\item[Computergrafik]
Die Computergrafik ist ein Teil der Informatik und beschreibt die Ausgabe von zwei- und dreidimensionalen
Objekten als Raster oder Vektorgrafik. Informationsvisualisierung benutzt die Techniken der Computergrafik, ist aber kein Teil
dieses Gebietes.
\item[Statistik]
Die Statistik ist ein Verfahren für die "`hypothesengeleitete Auswertung von numerischen (quantitativen)
Daten"'\citep[S.\,23]{Statistik}. Durch die Verwendung quantitativer Daten, wird eine Verbindung zwischen
Empirie und Theorie geschaffen.  Dabei ist die Informationsvisualisierung, neben der Mathematik, das wichtigste
Werkzeug der Statistik. So wird der Visualisierungsprozess aus Abschnitt \ref{sec:Pipeline} besonders in
im Bereich der deskriptiven Statistik benutzt, um Erkenntnisse zu gewinnen und darzustellen.
Auch die Informationsvisualisierung als eigenständige Disziplin benutzt Techniken der Statistik um Daten aufzubereiten.
\item[Präsentations- und Prozessvisualisierung]
Häufig werden Präsentationsvisualisierung und Prozessvisualisierung als Visualisierung bezeichnet, sind
aber eigene Gebiete. In ihnen geht es auch um die Sichtbarmachung von Informationen, diese wurden aber nicht aus
großen Datenmengen gewonnen und sind daher auch ohne Softwareunterstützung herstellbar.
\item[Data Mining] ist der automatische Versuch, Datenmengen zu ordnen und mithilfe
von Algorithmen Erkenntnisse zu erhalten. Im Gegensatz dazu versucht die Informationsvisualisierung eine geeignete grafische Repräsentation
bereitzustellen, die dem Nutzer die Möglichkeit gibt, diese Erkenntnisse selbst zu finden. Für die Datengewinnung
ist die Informationsvisualisierung auf Techniken des Data Mining angewiesen. Es gibt Bestrebungen beide Gebiete 
im "Visual Data Mining"\footnote{Vgl. Daniel Keim} zu Verbinden um Synergien zu bilden.
\item[Interface- und Interactiondesign]
Diese Felder beschreiben die Gestaltung von Benutzeroberflächen. Damit arbeiten sie, wie die Visualisierung, an
der Schnittstelle zwischen Mensch und Maschine. Interfacedesign benutzt häufig Techniken der Visualisierung
um grafische Konzepte zu realisieren, da die Informationen primär visuell übertragen werden.
\item[Computational Design]
Dieser von \citep{BenFry} eingeführte Begriff beschreibt die Vereinigung vieler Disziplinen zu einem neuen
interdisziplinären Arbeitsfeld. Der Ansatz des Computational Designs ist es, die Informationsvisualisierung in einem größeren
Kontext zu betrachten und mit technischen Bereichen wie der Informatik und künstlerischen
Bereichen des Designs zu verbinden. Somit wird der Informationsvisualisierungsbegriff auf ein größeres Arbeitsfeld
bezogen.
\end{description}

\section{Bearbeitungsziele}
\label{sec:Ziele}
Grundsätzlich ist das Ziel einer Visualisierung die Analyse einer gegebenen Datenmenge zu unterstützen und diese
Ergebnisse effizient präsentieren zu können und damit Kommunikation zu ermöglichen und einen Erkenntnisgewinn zu schaffen.
Die Visualisierung kann nach \citep{Schumann} für die drei folgenden allgemeinen Stufen der Analyse eingesetzt werden:
\begin{description}
\item[Explorative Analyse]
beschreibt die Daten selbst als Ausgangspunkt der Forschung. Durch interaktive und ungerichtete Suche in den Daten
wird mithilfe der Informationsvisualisierung eine Hypothese entwickelt. Dazu muss eine geeignete weit gefasste und nicht
beschränkte Darstellung gefunden werden.
\item[Konfirmative Analyse]
Hier existieren bereits ein oder mehrere Hypothesen die mithilfe der Informationsvisualisierung überprüft werden sollen.
\item[Präsentation]
Ergebnisse aus der Analyse der Daten werden mithilfe der Informationsvisualisierung dargestellt, um sie für Dritte verständlich
zu machen und mit Ihnen über den Sachverhalt kommunizieren zu können.
Wichtig ist dabei eine ansprechende und ästhetische Darstellung, denn
ein guter Eindruck verstärkt den Willen sich mit einer Darstellung auseinanderzusetzen.
\end{description}

Um eine adäquate Informationsvisualisierung klassifizieren zu können, nennen \citep{Schumann} drei Eigenschaften.
Diese sind Effektivität, Expressivität und Angemessenheit.
\begin{description}
\item[Expressivität]
Die Visualisierung soll nur die in den Daten enthaltenen Informationen möglichst unverfälscht wiedergeben.
\item[Effektivität]
Die Darstellung muss zu den visuellen Fähigkeiten des Betrachters und den Eigenschaften des Ausgabegerätes
passen.
\item[Angemessenheit]
Ressourcen und Rechenaufwand und damit die Kosten einer Visualisierung sollen den Anforderungen entsprechen.
\end{description}
Die Expressivität und Effektivität entsprechen der einzigen Klassifikation aus \citep{Bertin}, die als Prägnanz bezeichnet wird.
Prägnanz wird von \citep[S.\,17]{Bertin} wie folgt definiert:
\begin{quote}
"`Wenn eine Konstruktion zur Beantwortung einer gestellten Frage unter sonst gleichen Voraussetzungen eine
kürzere Betrachtungszeit erfordert als eine andere Konstruktion, so bezeichne man diese als prägnanter in
Bezug auf die gestellte Frage."'
\end{quote}
Darüber hinaus ist es schwer allgemeingültige Aussagen zu treffen, wie ein komplexer Sachverhalt und dessen
Informationen am effizientesten zu visualisieren sind, da die Informationsvisualisierung stark anwendungsabhängig ist und
immer den Anforderungen der Daten und Zielgruppe, des Bearbeitungsziels, der Repräsentation und des Mediums entsprechen soll.

\section{Visualisierungsprozess}
\label{sec:Pipeline}
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/benfryprocess.pdf}
\caption{Der Prozess des Computational Designs nach \citep[S.\,13]{BenFry}, eigene Darstellung}
\label{fig:benfryprocess}
\end{figure}
Der Prozess der Visualisierung wird Visualisierungspipeline genannt. Diese beschreibt den Ablauf der einzelnen
Schritte, die für eine Informationsvisualisierung notwendig sind, um abstrakte Daten in geometrische Daten
zu übersetzen. In der Literatur gibt es keine einheitliche Beschreibung der Visualisierungspipeline, aber
die Darstellungen ähneln sich stark. Im folgenden soll der Ablauf der Informationsvisualisierung an einem Beispiel
beschrieben werden. In \citep{BenFry} wird der Prozess des Computational Designs beschrieben und in einen
größeren Kontext eingeordnet. Dadurch bietet sich die
Pipeline besonders gut an, um einen Überblick über alle Arbeitsschritte zu erhalten. In Abbildung \ref{fig:benfryprocess}
werden diese dargestellt.

Als Erstes wird die Beschaffung der Daten aus einer Datei oder einem Netzwerk
beschrieben (acquire). Danach finden erste Analysen statt, um die Struktur der Daten zu erkennen (parse).
Wichtige Informationen können beispielsweise Extremwerte oder Wertebereiche und andere Bereiche speziellen
Interesses sein.
Diese Bereiche werden herausgetrennt (filter) und auf ihnen Methoden der Datenanalyse angewendet,
die für die weitere Verarbeitung notwendig sind (mine). Im nächsten Schritt werden dann geeignete
grafische Repräsentationen\footnote{Vgl. Abschnitt \ref{sec:grafischeSemiologie}} gefunden, um die Daten
darzustellen (represent).\footnote{\citep{Schumann} erweitert diesen Punkt noch durch das Rendering, welches die eigentliche Rasterung
und Darstellung auf dem eigentlichen Ausgabemedium durchführt.}
Dieser Schritt wird auch \textit{Mapping} genannt und ist die Daten-zu-Geometrie-Abbildung\footnote{Vgl. \citep[S.\,16]{Schumann}}, bei der
die abstrakten Daten auf grafische Primitive übertragen werden.
Die grafische Darstellung wird dann iterativ durch die visuelle Analyse des Nutzers
verbessert, damit sie einfacher verständlich und ästhetisch ansprechend wird (refine). Als letzter
Schritt werden Interaktionsmöglichkeiten ergänzt, um dem Nutzer die Kontrolle über die
Ausgabe, aber auch über vorher stattfindende Stufen des Prozesses geben zu können (interact).

Der hier beschriebene Ablauf ist allen Visualisierungsprozessen immanent, muss aber nicht zwangsläufig
in der gegebenen Reihenfolge auftreten. Es gibt unterschiedliche Möglichkeiten, in die
Visualisierungspipeline einzugreifen und zwischen einzelnen Stufen hin und her
zuspringen.\footnote{In \citep{Schumann} Abschnitt 2.2 und 2.3 werden
unterschiedliche Verfahren beschrieben.}
Das Ergebnis all dieser Verfahren ist jedoch immer die grafische Darstellung, die im
folgenden Kapitel beschrieben wird.

\section{Grafische Darstellung}
\label{sec:Darstellungen}
\subsection{Begriff}
Die grafische Darstellung ist das Produkt einer Informationsvisualisierung mit deren Hilfe
die Ziele aus Abschnitt \ref{sec:Ziele} erfüllt werden können. Sie besteht
immer aus den in Abschnitt \ref{sec:grafischeSemiologie} genannten
visuellen Variablen.
Als allgemeinste Form der grafischen Darstellung beschreiben \citep{Schumann} das
Diagramm. Es "`ist eine graphische Repräsentation von Informationen mit Hilfe
graphischer Elemente"'\citep[S.\,126]{Schumann}. \citep{Bertin} spricht dagegen
ausschließlich vom Begriff der "`grafischen Darstellung"' und grenzt diesen von
der bildhaften Darstellung\footnote{Beispielsweise Fotos oder künstlerische Bilder}
ab, die nicht monosemiotisch ist. Diese wird weiter in Diagramme, Netze
und Karten unterteilt. \citep{Schumann} weist außerdem auf eine Doppeldeutigkeit
des deutschen Begriffes hin, denn im englischen gibt es "`diagram"' und "`chart"'.
In dieser Arbeit wird der Begriff
der grafischen Darstellung verwendet und schließt alle Präsentationen der
Informationsvisualisierung ein.

\subsection{Darstellungsformen}
\label{sec:Darstellungsformen}
Die grafische Darstellung hat verschiedene Darstellungsformen, die für unterschiedliche
Anwendungsfälle konzipiert wurden. Sie sind alle stark anwendungsabhängig und es müssen viele
Anforderungen beachtet werden, um die effizienteste Technik der grafischen Darstellung zu
finden.\footnote{Vgl. Abschnitt \ref{sec:Ziele}}
Die folgende Auflistung von Darstellungsformen orientiert sich an den Darstellungsformen für
Multiparameterdaten in \citep[S.\,213]{Schumann} und
wird ergänzt durch \citep{Preim} und eigene Beobachtungen. Sie erhebt keinen Anspruch auf
Vollständigkeit. Folgende Techniken sind möglich:
\begin{itemize}
\item einfach - Scatterplots, Histrogramme, Säulen- und Balkendiagramme, Punktdiagramme, Kreisdiagramme, Igelkurve, Isolinien
\item multiaxial - Kiviatgraph, parallele Koordinaten, Parahistogramme
\item ikonenbasiert - Stick-Figure-Ikonen, Farbikonen, Chernoff Ikonen, Data Jacks
\item pixelbasiert - einfach, raumfüllende Kurven, Zwei-Schritte-Technik, Recursive-Pattern-Technik
\item hierarchisch - dimensional Stacking, World-within-Worlds, Cone-Trees, Cluster Map, 
\item netzwerkbasiert - Venn-Diagramm, Tree Maps, Bubble Tree, ArcTree
\item geschichtet - Icicle Plots, Sunburst
\item hybrid - Mischtechniken bestehend aus anderen Techniken
\end{itemize}
Eine weitere Auflistung mit Beispielen findet sich in Anhang X, dort sind Beispiele
von mehreren Darstellungsformen abgebildet.

Für diese Arbeit sind vor allem die hybriden Techniken interessant, da diese versuchen
neue Sichtweisen ohne vorgefertigte Festlegungen zu schaffen. Um diese Darstellungsformen
umsetzen zu können, wird im nächsten Kapitel eine Software konzipiert.

\chapter{Konzept einer geeigneten Softwarelösung}
\label{cha:Software}
\section{Grundprinzip der Informationsvisualisierung}
\label{sec:Grundprinzip}
\subsection{Allgemeine Betrachtungen}
Die Übertragung von symbolischen Informationen auf geometrische Informationen kann als grundlegendes Prinzip der
Informationsvisualisierung bezeichnet werden. Dieser Schritt ist die ausführende Stufe, die als Mapping in der
Visualisierungspipeline bezeichnet wird. Bevor es zu diesem Schritt kommen kann, ist es wichtig
alle Ausgangsbedingungen zu beachten, die zu einer Informationsvisualisierung führen, die alle Bearbeitungsziele aus
Abschnitt \ref{sec:Ziele} erfüllt. Das bedeutet, dass alle Schritte vor dem Mapping wie zum Beispiel die Auswahl
aller Parameter nicht von einer Software erledigt werden können und stattdessen vom Nutzer in einem kreativen
Prozess gefunden werden müssen.

Nur die arbeitsintensive Aufgabe der Übertragung der einzelnen Ausprägungen auf die visuellen Variablen muss
dann noch vom Rechner übernommen werden, ohne das der Nutzer dabei im kreativen Gestaltungsprozess eingeschränkt
wird. Parameter können direkt verändert werden um die Ausgabe direkt zu steuern, während der
Rechner alle Änderungen sofort ausgibt. Es wird eine kreative Auseinandersetzung
mit Daten ermöglicht, die neue Formen der Informationsvisualisierung und damit neue Sichtweisen auf
die eigentlichen Probleme zulässt.

Wie in Kapitel \ref{cha:Grundlagen} und \ref{cha:Informationsvisualisierung} gezeigt, gibt es eine Vielzahl an
Daten und grafischen Darstellungsmöglichkeiten. Dazu kommen neue hybride Formen durch Mashups\footnote{"`Mashup (von
englisch to mash für vermischen) bezeichnet die Erstellung neuer Medieninhalte durch die nahtlose
(Re-)Kombination bereits bestehender Inhalte."'\citep{wiki_mashup}}. Es muss ein Ansatz gewählt
werden, bei dem die Verwendung von unterschiedlichsten Datensätzen und Darstellungsformen ermöglicht wird.
Die Software muss dazu möglichst universell sein um flexibel viele unterschiedliche Anwendungsfälle
bearbeiten zu können.

Dieser Ansatz soll mit einer Software auf einer niedrigeren Ebene der Informationsvisualisierung umgesetzt werden als
es bisherige Softwarelösungen wie beispielsweise Microsoft Excel getan haben. Statt grafische Darstellungen auszuwählen
die auf die Datensätze abgebildet werden, soll dem Benutzer erlaubt werden einzelne Variablen des gleichen abstrakten Datensatzes,
auf die visuellen Variablen einer Grafik zu übertragen. Die Software kann automatisch den Wertebereich auf atomare Elemente der
grafischen Darstellung abbilden. Somit können trotz dieses Low-Level-Ansatzes große Mengen an Datenpunkten
in kürzester Zeit dargestellt werden. Anders als bei aktuellen Softwarepaketen finden damit folgende Fragen
eine Beantwortung:
\begin{itemize}
\item Welche Darstellungsform eignet sich am besten für ein konkrete Aufgabe?
\item Gibt es Mischformen aus vorhandenen Darstellunsgformen mit denen ein Problem noch besser gelöst werden kann?
\item Gibt es neue unerforschte Ansätze für die Visualisierung?
\end{itemize}

\subsection{Einordnung in den Visualisierungsprozess}

Die im vorangegangenen Kapitel beschriebene Software soll in dieser Arbeit nur auf einen Teilbereich
des Visualisierungsprozesses konzentriert werden, um den grundlegenden Ansatz demonstrieren zu können. Dabei werden
einzelne Bereiche des Prozesses nicht beachtet, können aber durch den modularen Aufbau der Software
noch ergänzt werden.\footnote{Vgl. dazu Abschnitt \ref{sec:visPro} und \ref{sec:Ausblick}} In der
Einteilung nach \citep{BenFry} befindet sich der Aufgabenbereich der Software in den
Stufen \textit{present} und \textit{refine}. Diese werden um eine zusätzliche Bearbeitungsmöglichkeit ergänzt.
Der Prozess des Mappings kann stark beeinflusst werden, woraus ein iterativer Arbeitsprozess entsteht.
Bei jeder Interaktion des Benutzers wird automatisch und unmittelbar die
aktuelle Ausgabe verändert und der Nutzer kann visuell analysieren welche Verbindungen noch nötig sind
oder welche zusätzlichen Parameter einzelne Verbindungen noch brauchen, um eine sinnvolle grafische 
Darstellung zu erzeugen.
Somit können alle visuellen Variablen direkt beeinflusst und für das aktuelle Bearbeitungsziel angepasst
werden.
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/benfryprocess_marked.pdf}
\caption{Einordnung in den Prozess des Computational Designs nach \citep{BenFry}, eigene Darstellung}
\label{fig:benfryprocess_marked}
\end{figure}

\section{Rahmenbedingungen}
Für die Arbeit mit der Infomationsvisualisierung gelten einige Rahmenbedingungen, die vor der
Konzeption einer Software beachtet werden müssen.

Ein Großteil der Ausgabemöglichkeiten sind zweidimensional.\footnote{Es gibt immer wieder
Ansätze, die die 3D-Technik nutzen um Visualisierungen darzustellen. Diese Entwicklungen
müssen aber noch weiter erforscht werden um ihre Tauglichkeit zu prüfen.} Dabei kann
die Ausgabe digital auf einem Display oder als Druck einer grafischen Darstellung
erfolgen. Soll eine grafische Darstellung benutzt werden, in der mehr als 2 Variablen
für die Positionierung der Grafikprimitive im Raum verwendet werden, muss daher für die
Ausgabe eine Projektion vorgenommen werden. Die Projektion ist die mathematische
Realisierung des Modells der virtuellen Kamera. In \citep[S.\,26]{Computergrafik} werden die 
Eigenschaften dieser Kamera wie folgt beschrieben:
\begin{itemize}
\item die Position der Kamera ist gegeben durch die Koordinaten eines Punkts;
\item der Bildausschnitt ist rechtwinklig;
\item der Schärfebereich der Kamera ist unendlich groß.
\end{itemize}
Für diese virtuelle Kamera wird in der Computergrafik die Zentralprojektion verwendet.
Bei dieser wird jeder Punkt im Raum mit einem Projektionsstrahl (in Form einer Geraden)
auf eine Ebene abgebildet. Die Ebene kann beispielsweise ein Monitor sein. Alle 
Projektionsstrahlen schneiden sich in einem Punkt außerhalb dieser Ebene, dem sogenannten
Projektionszentrum. Abbildung XXX veranschaulicht dieses Prinzip. Die Parallelprojektion
findet als Sonderfall der Zentralprojektion ebenfalls Anwendung.\footnote{Bei der
Parallelprojektion liegt das Projektionszentrum unendlich weit entfernt. Somit verlaufen
die Projektionsstrahlen parallel. Vgl. \citep{wiki_projektion}} Der Nutzen der virtuellen
Kamera kann durch Nutzerinteraktion erhöht werden. Der Anwender kann somit Parameter der
virtuellen Kamera, wie beispielsweise Position und Zoom selbst beeinflussen um den Fokus
auf einzelne Teilbereiche der grafischen Darstellung zu setzen.\footnote{Vgl. Focus und
.... Techniken in \citep[S.\,1]{Schumann} und \citep[S.\,1]{Preim}}

Durch die Eigenschaften heutiger Ausgabegeräte müssen durch die Visualisierung erzeugte
Grafiken gerastert werden. Die Technik der Rasterung überführt die kontinuierlichen Werte
einer Projektion in diskrete Werte des Geräte-Koordinatensystems. Dabei werden Werte
gerundet und in die zweidimensionale Matrix\footnote{Auflösung der Ausgabe in Pixel oder DPI}
des Ausgabegerätes übernommen.

Mögliche Farbwerte der einzelnen Bildpunkte und damit die Farbräume der Ausgabegeräte
müssen beachtet werden. Die Ausgabe auf Computermonitoren erfolgt im RGB-Farbraum während
für Druckerzeugnisse unterschiedliche Farbräume möglich sind.

Die Rahmenbedingungen der Bildsynthese konnten in diesem Abschnitt nur grundlegend beschrieben
werden. Eine tiefgreifendere Beschreibung des Themas erfolgt in \citep{Computergrafik}.

Die Daten und deren durch Informationsvisualisierung erzeugte visuelle Repräsentationen sind immer
gebunden an ihr Speicher- und Ausgabeformat.
Zuerst müssen die Daten gesammelt und gespeichert werden. Dazu müssen adäquate
Formate gefunden werden, die die Software verarbeiten kann. Es gibt bereits
etablierte Ansätze große Datenmengen zu speichern und zu übertragen. Die Daten
werden dabei maschinenlesbar codiert. Etablierte Formate wie
CSV und XML kommen zum Einsatz. Daneben existieren noch weitere Formate mit spezifischen
Vor- und Nachteilen. JSON\footnote{JavaScript Object Notation} hat Ähnlichkeit mit XML,
ist aber besser vom Menschen lesbar. Im wissenschaftlichen Bereich findet
häufig das netCDF Format\footnote{Vgl. \citep{Schumann}}
Anwendung. Neben diesen sehr bekannten Formaten existieren noch viele weitere
Möglichkeiten Daten zu speichern.

Zur Speicherung der grafischen Darstellungen einer Informationsvisualisierung eignen sich bekannte
Formate wie JPEG, PNG, BMP, TIFF und viele andere. Dabei müssen formatspezifische
Eigenschaften wie beispielsweise die Kompression beachtet werden.

Für die Mensch-Maschine-Interaktion stehen meist nur Maus und Tastatur zur Verfügung.
Daneben gibt es neue Ansätze der Bewegungsteuerung mit Datenhandschuh und
Kamera-Tracking zur Bewegungs- und Gestenerkennung. Diese müssen aber noch weiter
erforscht werden, bevor ein effizienter Einsatz in der Informationsvisualisierung
möglich ist.

Aus Sicht des Anwenders spielt außerdem die Wahrnehmungs- und Auflösungsfähigkeit
des menschlichen Auges eine Rolle und welche Menge an visueller Information
im Gehirn verarbeitet werden kann.
Dieser und andere Aspekte werden dem Arbeitsfeld der Kognitionspsychologie und
Neurowissenschaften zugeordnet und ist daher kein Teil dieser Arbeit.

\section{Anforderungen}
\label{sec:Anforderungen}
Für die zu entwickelnde Software werden Anforderungen festgelegt, die
im folgenden beschrieben werden. Neben speziellen Anforderungen, die aus
dem Bereich der Informationsvisualisierung stammen, werden noch weitere
allgemeine Anforderungen an Benutzerführung und Performance gestellt.
\begin{description}
\item[Einfache Benutzerinteraktion]
Damit auch technisch unerfahrene Nutzer wie Journalisten oder private
Anwender schnell und einfach Ergebnisse erzielen können, kann die Software
durch visuelle Programmierung bedient werden. Da das Konzept der visuellen
Programmierung, das in Abschnitt \ref{sec:visPro} genauer beschrieben wird,
das Konzept der Software gut veranschaulicht, reicht ein grundlegendes
mathematisches Verständnis des Nutzers aus.
\item[Flexible Visualisierungsmöglichkeiten]
Um alle möglichen Darstellungsformen abbilden zu können, muss die 
Möglichkeit bestehen alle visuellen Variablen\footnote{Vgl.
\ref{sec:grafischeSemiologie}} und damit alle Darstellungsformen\footnote{Vgl.
\ref{sec:Darstellungsformen}} abbilden zu können. Der Nutzer darf dabei
in seiner Arbeit nicht durch Vorauswahl vorgefertigter Darstellungen
eingeschränkt werden.
\item[Flexible Ein- und Ausgabe]
Zur automatischen Dateneinspeisung in die Software sollen mehrere Möglichkeiten
bestehen, um in unterschiedliche Workflow-Prozesse eingebunden werden zu können.
Neben Dateiformaten wie XML, JSON und CSV ist eine Netzwerk- und
Datenbankanbindung sinnvoll.
\item[Performanz]
Der Benutzer kann alle Verbindungen und Parameter zwischen Datenobjekten und ihrer
visuellen Repräsentation direkt beeinflussen. Für eine direkte visuelle Analyse
durch den Nutzer, muss die Software die Möglichkeit bieten, sofort
nach Interaktion des Nutzers, die Veränderungen darzustellen. Dafür wird eine
ausreichende Performanz benötigt.
\item[Erweiterbarkeit]
Durch unterschiedliche Anforderungen in den verschiedenen Arbeitsbereichen ist
es nötig, die Software selbst erweitern zu können. Dafür soll eine Skriptsprache
implementiert werden, die es erlaubt, zur Laufzeit neue Funktionen hinzuzufügen.
Außerdem besteht die Möglichkeit durch eine Kapselung aller Funktionen
einfach eigene Module zu programmieren.
\item[Cross-Platform]
Damit die Software von vielen Nutzern einsatzbar ist, wird sie für die
drei großen Plattformen Linux, Apple OSX und Microsoft Windows entwickelt.
Dies wird durch die zugrundeliegende Bibliothek
openframeworks\footnote{Vgl. Abschnitt \ref{sec:Technologien}} gewährleistet.
\item[Frei und Offen]
Die Software wird unter einer freien Lizenz entwickelt und veröffentlicht
um eigene Erweiterungen von Nutzern zuzulassen. Durch die Wahl der Lizenz kann
die Entwicklung durch alle Interessenten vorangetrieben werden. Außerdem lässt
die Lizenz eine kommerzielle Erweiterung und Nutzung zu. Für private Anwender
ist die Software kostenlos verfügbar.
\end{description}

\section{Analyse bestehender Software}
\label{sec:bestehendeSoftware}
Durch das weite Arbeitsfeld der Informationsvisualisierung, das meist
fließend in andere Bereiche über geht, existiert eine große Anzahl an
Softwarelösungen und Programmierbibliotheken. Hier sollen exemplarisch
einzelne Anwendungen beschrieben werden, die verschiedene gefordete
Funktionen enthalten, diese aber nicht in einem Softwarepaket, das
speziell auf die Informationsvisualisierung zugeschnitten ist, zusammenfassen.
Eine Liste aller betrachteten Programme findet sich in Tabelle
\ref{tab:Softwareliste} im Anhang.
\begin{description}
\item[vvvv]
ist eine datenstromorientierte Enticklungsumgebung, die universell eingesetzt werden kann.
Mit ihr können unterschiedlichste audiovisuelle Medien gekoppelt und
verarbeitet werden. vvvv setzt auf visuelle Programmierung, ist aber
nicht spezialisiert auf Informationsvisualisierung und nicht für alle
Plattformen verfügbar.
\item[MeVisLab]
ist eine Software aus dem medizinischen Bereich, die durch visuelle
Programmierung bedient werden kann. MeVisLab ist eine fortgeschrittene
IDE\footnote{Integrated Development Environment} mit verschiedenen
Erweiterungsmöglichkeiten, ist aber spezialisiert auf die medizinische
Bildverarbeitung.
\item[d3.js]
ist eine Bibliothek die einen ähnlichen Ansatz wie in Kapitel \ref{cha:Software}
verfolgt. Sie ist in Javascript geschrieben und beschränkt sich dadurch auf
Webanwendungen. Der Nutzer muss Javascript programmieren können, um diese
Bibliothek nutzen zu können.
\item[NodeBox 2 Beta]
ist ein Programm um generative Grafiken zu erstellen. Es entspricht nahezu
allen beschriebenen Anforderungen. Durch die Programmierung ist es aber recht
langsam einzusetzen. Auch die Anbindung von unterschiedlichen Datenquellen
ist nicht gegeben.
\end{description}

\chapter{Umsetzung eines Prototyps}
\label{cha:Umsetzung}

In diesem Kapitel soll das Konzept prototypisch implementiert werden.
Dieser Prototyp wird \textit{Datasynth} genannt.
Um der Bearbeitungszeit dieser Arbeit gerecht zu werden, können nur grundlegende Funktionen
programmiert werden.  Die Implementierung in dieser Arbeit beschränkt sich auf eine
statische Ausgabe ohne Interaktionsmöglichkeiten, kann aber dahingehend erweitert werden.\footnote{Vgl. Abschnitt \ref{sec:Ausblick}}
Datasynth wird aus diesem Grund mit einer freien
Lizenz veröffentlicht, um eine Weiterentwicklung zu ermöglichen.


1. dokumentation der untersuchungsdurchführung (des Entwicklungsvorganges)
welche tools wurden wie angewendet, c++, of, git, boost, etc etc
2. darstellung der ergebnisse (verdeutlichung durch beispiele, erläuterung des erkenntnisfortschritts)
präsentation von viz mit der software?!

Einschränkungen durch Implementation






\section{Technologien}
\label{sec:Technologien}
Um Datasynth zu entwickeln werden verschiedene Softwaretechnologien verwendet.
Deren Einsatz wird nachfolgend kurz erläutert.
\begin{description}
\item[C++]

definition von C++ aus einem buch

Datasynth ist in C++ implementiert und nutzt daher die Vorteile
wie Performance.

\item[openFrameworks]
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/of.pdf}
\caption{Funktionsweise von openFrameworks aus \citep{of_wiki}}
\label{fig:of}
\end{figure}
ist ein in C++ geschriebenes Framework. Es soll durch seine
Einfachheit und Intuitivität den kreativen Prozess und das
Experimentieren mit Software unterstützen. openFrameworks
kapselt viele unterschiedliche Bibliotheken für die
computergestützte audio-visuelle Verarbeitung in eine gemeinsame,
konsistente und einfache Programmierschnittstelle. Beispielsweise
wird die Bibliothek openGL für Grafiken verwendet und die
Bibliothek rtAudio für die Ein- und Ausgabe von Audiosignalen.
Die Programmierschnittstelle von openFrameworks enthält
wenige Klassen mit wenigen Funktionen um dem Benutzer einen
einfachen Einstieg zu ermöglichen.\footnote{Vgl. \citep{of1} und \citep{of2}}
Weiterhin ist openFrameworks kompatibel zu den Plattformen
Linux, Mac OSX, Windows und erfüllt neben den genannten Vorteilen
eine weitere Anforderung aus Abschnitt \ref{sec:Anforderungen}.
Die Funktionsweise von openFrameworks wird in Abbildung
\ref{fig:of} verdeutlicht. 
Die Programmlogik, das Benutzerinterface und alle Ein- und
Ausgaben für den Benutzer wurden für Datasynth mit openFrameworks
realisiert.
\item[boost]
ist eine Sammlung von unterschiedlichen C++ Programmierbibliotheken.
Diese Bibliotheken sind portabel einsetzbar und steigern die
Produktivität beim Entwickeln einer Software, da sie unterschiedliche
Anwendungsbereiche von C++ erweitern und vereinfachen.
Einzelne Bibliotheken der Sammlung werden in neuen C++ Standard
übernommen, um C++ selbst zu verbessern.
Für Datasynth werden die Bibliotheken für Zeiger, Container
und generische Programmierung verwendet, um zur Laufzeit flexibel
auf Benutzereingaben reagieren zu können.
\item[GitHub]
ist eine Plattform für das gemeinsame Entwickeln von Software.\footnote{Vgl. http://www.github.com}
Sie basiert auf dem Versionverwaltungstool git, welches entwickelt wurde
um Änderungen an Quellcode aufzuzeichnen und diesen zwischen mehreren
Entwicklern teilen zu können. GitHub verbindet diese Funktionalität mit
einer Art sozialem Netzwerk, bei der verschiedene Nutzer kollaborativ
an einer Software arbeiten können. Datasynth ist auf Github verfügbar.\footnote{Vgl. http://www.github.com/benben/datasynth}
\end{description}
\section{Visuelle Programmierung}
\label{sec:visPro}
Um dem breiten Spektrum an Anforderungen gerecht zu werden,
wird Datasynth mit einem Konzept der visuellen Programmierung gesteuert.
\citep[S.\,XXX]{Henning} definieren visuelle Programmierung wie folgt:
\begin{quote}
"`Es handelt sich hierbei um ein in integrierten Entwicklungsumgebungen mit
grafischer Benutzeroberfläche verwendetes Hilfsmittel, bei welchem grafisch
dargestellte Programmblöcke durch gerichtete und qualifizierte Linien miteinander
verlinkt werden."'
\end{quote}
Der Benutzer schreibt also keinen Quellcode und benutzt dabei vorgefertigte
Funktionsnamen und Aufrufe in textueller Form, sondern zieht einzelne grafische
Elemente und verbindet diese.

Für Datasynth wurden einzelne Klassen definiert, die das Konzept der visuellen
Programmierung umsetzen. In der folgenden Auflistung werden die einzelnen
Elemente und ihre Funktionsweise beschrieben
\begin{description}
\item[Node]
\item[Pin]
\item[Connection]
\item[Spread]
\end{description}

Der Einsatz von visueller Programmierung als Bedienkonzept für Datasynth hat
mehrere Vorteile. Das Verbinden von Nodes, die als Datenquelle funktionieren, mit Nodes, die
zur Ausgabe von grafischen Primitiven dienen, greift das grundlegende
Prinzip der Informationsvisualisierung auf.\footnote{Vgl. Abschnitt \ref{sec:Grundprinzip}}
Weiterhin sind keine Programmierkenntnisse erforderlich um eine Informationsvisualisierung
vorzunehmen. Stattdessen reicht ein durchschnittliches mathematisches Verständnis.
Durch die universelle Form der Benutzerschnittstelle ist ein iteratives
Experimentieren möglich und somit kann Datasynth genutzt werden um schnell eine
Idee für die Informationsvisualisierung zu skizzieren.
Die komplexen internen Abläufe werden dabei hinter einem intuitiven und einfachen Interface
versteckt. Dadurch können "`context switches"'\footnote{Vgl. \citep[S.\,50]{Tufte}}
vermieden werden. Diese treten auf wenn zwischen unterschiedlichen Programmansichten gewechselt
werden muss. Datasynth zeigt den Bereich für die visuelle Programmierung und die Ausgabe
immer gleichzeitig. Auch das Verändern von Parametern, wirkt sich unmittelbar auf die Ausgabe
aus. Der Nutzer kann dadurch sofort erkennen, welchen Einfluss seine Benutzereingaben bewirken und
kann diese vergleichen und anpassen um schnell zum gewünschten Ergebnis zu kommen.
Abbildung \ref{fig:datasynth} stellt dieses Prinzip an einem Beispiel dar.
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/datasynth.pdf}
\caption{Ein Beispiel der Benutzeroberfläche von Datasynth. Die oberen zwei Fenster und
die unteren zwei Fenster stellen zwei unterschiedliche Stadien der Software dar.
Im oberen linken Fenster wird ein Kreis gezeichnet. Dieser hat einen Radius von 20 Pixel, da
die rechte obere Node einen Wert von 20 Pixel an den Pin für den Radius des Kreises übergibt.
Im unteren Stadium ändert sich der Wert dieser Node auf 125. Dadurch verändert sich unmittelbar
auch die Darstellung des Kreises, da der Radius mit dem Wert dieser Node verbunden ist.}
\label{fig:datasynth}
\end{figure}

\section{Wichtige Kernfunktionen}
\label{sec:Kernfunktionen}
In diesem Kapitel werden exemplarisch wichtige Abschnitte der Software anhand ihres Quelltextes
erläutert.
\lstinputlisting[language=C++]{code/factory.cpp}

\chapter{Auswertung}
\label{cha:Auswertung}
bewertung der ergebnisse vor dem hintergrund der hypothesen/problemstellung (Test des konstrukts und vergleich mit den Anforderungen
was kann die software liefern? wofür bildet sie nur die grundlage? was kann sie nicht?

2. ableiten von schlußfolgerungen
????
so eine software macht sinn, macht keinen sinn?
\section{Probleme bei der Entwicklung}
\label{sec:Probleme}
reflection/introspection von c++
universelle datentypen (schwierig in c++)
geeignete daten finden
mulit-window ausgabe (gelöst mit ofxFenster, da glut das nicht hergibt)
\section{Vorteile}
\label{sec:Vorteile}
durhc parameter kann der benutzer die Wertebereiche der Abbildungen direkt verändern
und kann somit auch ohne komplette kenntnis der daten live die beste "einstellung
der parameter" herauszufinden, anstatt vorher Metadaten kennen bzw studieren bzw anlegen zu müssen (min,max, ...)

mehrere viz können statisch in einer präsentation kombiniert werden. so kann ohne
benutzerinteraktion mehrere blickwinkel auf den datensatz ermöglicht werden

\section{Nachteile}
\label{sec:Nachteile}
benutzer hat alle freiheiten aber muss dadurch auch die grundregeln der viz beherrschen
und verstehen ( z.b. kreis radius/fläche, was eignet sich für was am besten)
gestaltungsregeln müssen vom nutzer angwendet werden um viz zu verstärken
Klärung der möglichen Fragen, use nach BERTIN (Theorie des graphischen Bildes)

erweiterbarkeit:
wenn eine gewisse funktionalität noch nicht als node vorliegt, kann diese hinzuprogrammiert
werden. verweis dabei auf die angedachten features zur erleichterung von nutzer entwicklungen
mit beispielsweise ruby

das statische:
fehlende nutzerinteraktion und dadurch fehlende interaktive kombination von viz techniken
(klick auf glyphe erzeugt eine genaue viz der werte dieses datenobjektes)

low-level-ansatz:
führt dazu, dass man immer vom urschleim anfangen muss um komplexe objekte zu erzeugen.
deshalb wichtiges feature: kapselbarkeit von mehreren nodes zu einer komplexen high-level-node
so könnte man z.b. eine Sunburst node kreiiren die dann zwar 10 anstöpselmöglichkeiten hat aber sonst nix weiter
man benutzt grafische primitive und manche komplexe viz hat sehr viele primitive in komplexen abhängigkeiten, also kapseln

\chapter{Zusammenfassung}
\label{cha:Zusammenfassung}
1. zusammenfassung der ergebnisse, lesson learned
???
2. optional: persönliche bemerkungen, hinweis auf weiteren forschungsbedarf, ausblick in dei zukunft
was kannnoch alles an der Software getan werden?

-> datasynth als Erkundungstool für daten, als datenleser (ist das nicht auch eine kompetenz
die man entwickeln sollte: daten lesen und verstehen zu können, also heisst es nicht auch heutzutage
und in zukunft immer mehr: daten verstehen heißt die welt verstehen)

einordnung der software mit vergleichen zu anderen apps (grundlage sind funktionalität, 
lso was kommt dabei raus) ist so ein ding zwischen statistiktool spss, 

\section{Fazit}
\label{sec:Fazit}
eignet sich die software?! JA NEEIN ?

gut aber durc hdas wesen der software entstehen neue probleme(siehe nachteile)
die beachtet werden müssen, dafür müssen lösungen her

\section{Ausblick}
\label{sec:Ausblick}
Da die software lediglich einen Prototypen darstellt ergeben sich mannigfalitge
Erweiterungsmöglichkeiten. Hier sollen einige weniger, dafür aber sehr wichtige
mögliche Erweiterungen genannt werden.

ruby
erweiterung auf andere bereiche des visualisierungsprozesses
kapselung von patches
  vielfältige möglichkeiten wie
    erweiterung und kapselung von verschiedenen viz templates als nodes (Isofläche Node oder Flow Ribbons)
    eigene erstellung von ikonen /vgl. schumann s. 197)
    (dazu erfüllt datasynth alle genannten anforderungen von sich aus (editor, binder, viewer)

v4p laden und speichern möglich! crazy!

erweiterung der ausgabemöglichkeiten (statt ausgabe auf bildschirm, ausgabe als
postscript, ausgabe als interaktive 3D HTML5 Anwendung (dazu wären navigations
und interaktionsmöglichkeiten notwendig (vgl. schumann s. 175), ...)

eng verbunden damit sind die möglichkeit allgemeine interaktionsmöglichkeiten
einzubauen um parameter für beispielsweise selektionsbedingungen auch von
end-anwendern der viz benutzbar zu machen

evaluationsmöglichkeit (wie kann ich schon in datasynth testen ob die ausgabe
geeignet ist) (muss erforscht werden)

automatische generierung von legenden/skalen(+einteilungen), muss erforscht
werden inwieweit das überhaupt machbar ist bei einem so universellen ansatz
oder ob es nicht doch besser ist, diese dinge der nachbearbeitung zu überlassen
(weil datasynth ja nur die massen-arbeit machen soll und nicht einzelne details am ende)

eventbasierte steuerung

threaded nodes

reiner export als abstrakte werte (koordinaten, höhe, breite, typ) in gängige 3D-Austausch-Formate

export von einzelnen teilbereichen (ebenen) zur graphischen weiterverarbeitung mit anderer software

\chapter{Anhang}
\section{Liste von bestehender Softwarelösungen}
todo: alle links zusammensuchen

Die nachfolgende Tabelle gibt eine unvollständige, aber umfassende
Liste an Softwarelösungen für die Visualisierung. Einige Anwendungen
sind auf Visualisierung großer Datenmengen spezialisiert, andere
berühren den Bereich nur mit einigen Funktionen.

\begin{tabular}{l|l}
\hline
Name & Webadresse \\
\hline
Pure Data & http://www.puredata.info/ \\
vvvv & http://www.vvvv.org/ \\
\label{tab:Softwareliste}
\end{tabular}
\section{Beispiel: Bevölkerungsdaten Stadt Leipzig}
viz mit streckenzügen (sternförmig, parallel), kreisen (matrix),

\bibliography{diplom}
\listoftables
\listoffigures
%\printnomenclature
\end{document}

