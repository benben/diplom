\documentclass[a4paper, 12pt, DIVcalc, onepage, pdftex, headsepline, footsepline]{scrreprt}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{setspace}
\onehalfspacing

\usepackage[ngerman]{babel}
\usepackage{natbib}
\usepackage{url} %correct url display in cites

\usepackage[locale=DE]{siunitx}

\pagestyle{headings}

\typearea[current]{calc}

%add hyphenation later

\begin{document}
\title{Visuell programmierbarer Non-Standard-Informationsvisualisierer}
\author{Benjamin Knofe}
\subject{Diplomarbeit}
\publishers{Hochschule für Technik, Wirtschaft und Kultur Leipzig}
\dedication{Dank an \\ Pyry Jahkola, Philip Whitfield}
\maketitle
\tableofcontents

\chapter{Einleitung}
\label{cha:Einleitung}
Die Menge an digital gespeicherten Daten nimmt stetig zu. In 2011 werden laut einer neuen
Studie\footnote{Vgl. \citep{EMC}} voraussichtlich 1,8 Zettabyte\footnote{1 Zettabyte = \num{1d21}
Byte = 1.000.000.000.000 Gigabyte} an Daten erzeugt und kopiert. In nahezu allen Bereichen unseren
täglichen Lebens werden Daten erhoben, gemessen und gespeichert. Dazu zählen vor allem die Bereiche
der Wissenschaft, Wirtschaft und Kultur. Auch die Politik und Verwaltung unserer Gesellschaft
verfolgt eine neue Strategie im Umgang mit Daten. So haben Städte wie beispielsweise Leipzig eine 
API oder Staaten wie Großbritannien verfolgen ein Konzept für e-Government mit dem
Open-Data-Gedanken, um Daten frei verfügbar zu machen. Um diesen Entwicklungen Rechnung zu tragen,
müssen neue Strategien entwickelt werden, die diese Daten für die jeweiligen menschlichen Adressaten
sinnvoll extrahieren, aufzuarbeiten und darzustellen. Aus diesem Grund haben sich in den letzen 50
Jahren verschiedene Forschungsfelder, wie Statistik, Data Mining, Computergrafik als Teilgebiet der
Informatik und Computational Design entwickelt. Ein Forschungsgebiet welches Thema dieser Arbeit
sein soll, verbindet all diese Gebiete um den aktuellen Entwicklungen unserer digitalen Welt
Rechnung zu tragen: die Visualisierung. In diesem Forschungsgebiet wird die Frage geklärt wie immer
abstraktere und komplexer werdende Daten in einem für den Menschen adäquaten Weise aufbereitet und
dargestellt werden können, um die gewünschten Informationen in Form von Mustern, Wiederholungen und
Anomalien identifizieren zu können. Dabei zeichnet sich eine Entwicklung ab aus einem rein
wissenschaftlichen Kontext hin zu einem populären Bereich um alltägliche Probleme lösen zu können.
Auch wenn jede Fornm der Visualisierung konkrete Ziele hat, mit denen sehr spezielle Probleme gelöst
werden, addressieren diese nicht mehr nur Experten und Wissenschaftler. Auch alltägliche Anwendungen
wie soziale Netzwerke, der Einkauf Online oder im Supermarkt, die Suche nach Informationen im
Internet oder in der Bibliothelk können mit Visualisierung als Teil des User Interface unterstüzt
werden und müssen somit auch für ungeübte Anwender verständlich und benutzbar sein. Dabei sollte
die Visualisierung ansprechend sein und damit eine angenehme und ästhtisch ansprechende Benutzung
gewährlsieten zu können aber gleichzeitig auch intuitiv sein, um ohne Vorkenntnisse nutzen aus
dieser Form der Mensch-Maschine-Interaktion ziehen zu können. So kann die tägliche Arbeit
unterstützt werden, damit es Gelegenheitsanwendern leicht gemacht wird, Informationen und
Wissen noch besser mit anderen teilen zu können. Somit liegt es an den Tools, die den menschen
unterstützen und die möglichkeit geben, diese daten für ihre jeweiligen zwecke nutzen zu können.
dabei gibt es eine vielzahl von unterschiedlichen problemen und fragestellungen die gelöst werden
müssen.

\section{Problemstellung}
Die Visualisierung als Arbeitsfeld ist eine hochkomplexe, hochspezialisierte Wissenschaft bei der
mathematische, informationstechnische und gestalterische Grenzen beachtet und in Einklang gebracht
werden müssen. Da die Entwicklung unserer Informationsgesellschaft viel schneller voranschreitet als
die Entwicklung neuer tools und damit das verständnis der eigentlichen Adressaten (die menschen, für
die diese daten erhoben wurden) müssen neue Wege gefunden werden, dieses Problem zu lösen. So können
immer komplexere Datenstrukturen nicht mehr mit aktuell vorhandenen klassischen Softwarelösungen wie 
beispielsweise Tabellenkalkulationssoftware
einfach dargstellt werden. Stattdessen wird ein neuer tiefergehendender Ansatz und die dazugehörige
Software gebraucht um das Wesen der Daten, die Information, wieder begreifbar zu machen.
Es entstehen Softwarelösungen die auf Teilbereiche der Visualisierung wie beispielsweise der Medizin,
Biotechnologie oder der Geoinformationssysteme spezialisiert sind. Diese Anwendungen sind nur von
Wissenschaftlern oder spezialisierten Experten verwendbar und erfordern ein hohes Maß an Vorwissen
und Zeit.
Andere Benutzer entwickeln eigene Workflows um eine Visualisierung umzusetzen.
Dabei wird auf Tools zurückgegriffen die aus verwandten Bereichen, wie beisüpielsweise der
Grafiksoftware stammen.
Dadurch erhöht sich der Arbeitsaufwand und die Qualität leidet. Bis heute existiert keine
Softwarelösung die eine universelle Möglichkeit bietet alle Formen und Anwendungsbereiche von
Visualisierung zu adressieren um eine jeweils für die Anwendung und den Adressatenkreis adäquates
Ergebnis zu liefern.
In dieser Arbeit soll ein Lösungsversuch geliefert werden, der auf einen grundlegenden und
abstrakteren Ansatz der Visualisierung abzielt, als es bisherige Softwarelösungen getan haben.
Ergänzt wird dieser durch die Implementation eines Prototypen, der den Ansatz beispielhaft
implementiert.
Diese Software kann mithilfe von visueller Programmierung\footnote{Vgl. Kapitel X} gesteuert werden,
welches eines möglichst breites Spektrum an Benutzern zulässt. 

\section{Aufbau der Arbeit}
Um einen Lösungansatz für das Problem der einfachen und universellen Visualisierung zu finden, wird
in dieser Arbeit eine Reihenfolge von Schritten durchgeführt die eine Implementation eines
Prototypen zum Ziel haben.

In Kapitel \ref{cha:Grundlagen} im Abschnitt \ref{sec:DatenInfo} werden die Begriffe Daten und
Informationen definiert und im Kontext
der Visualisierung beschrieben. Dabei wird anhand des aktuellen Forschungsstandes gezeigt, dass diese
zwei Begriffe nicht immer abgrenzbar von einander sind und es in Bezug auf das jeweilige Arbeitsfeld
unterschiedliche Interpretationen möglich sind. Nun kann im Abschnitt \ref{sec:EigenschaftenDaten} auf die
unterschiedlichen Eigenschaften von Daten eingegangen werden. Dies gilt als Kriterienkatalog anhand
dessen die Daten in Abschnitt \ref{sec:KlassifikationDaten} klassifiziert werden können.
Im folgenden Abschnitt \ref{sec:Datentypen} werden die verschiedenen Datentypen behandelt, die Inhalt
von Daten sein können.
Ein System zur Beschreibung von grafischen Variablen als Zeichen in einem Zeichensystem zur Erstellung von
graphischen Darstellungen wird in Abschnitt \ref{sec:graphischeSemiologie} beschrieben.

Nachdem die Ausgangsbedingungen definiert sind wird in Kapitel \ref{cha:Informationsvisualisierung} die
Informationsvisualisierung beschrieben. Abschnitt \ref{sec:Definition} definiert den Begriff
der Informationsvisualisierung und nennt die Besonderheiten dieser im Vergleich zu technisch-wissenschaftlichen
Datenvisualisierung. Danach folgt im Abschnitt \ref{sec:Abgrenzung} eine Abgrenzung zu teils-verwandten
Arbeitsfeldern und zu Bereichen, die die Visualisierung als Werkzeug verwenden. Was das Ziel einer guten
Visualisierung? Wie kann man das messen? Und was macht eine gute Visualisierung aus? Diese Fragen werden
im Abschnitt \ref{sec:Ziele} geklärt. Im folgenden Abschnitt \ref{sec:Pipeline} wird der eigentliche Arbeitsablauf
einer Visualisierung anhand verschiedener Einteilungsmöglichkeiten beschrieben um danach in Abschnitt
\ref{sec:Grundprinzip} gesondert auf den Teil des "Mappings" eingegangen wird. Im nächsten Abschnitt
\ref{sec:Darstellungen} werden einige Visualisierungsbeispiele gezeigt.

Das Kapitel \ref{cha:Software} beschreibt nun die Konzeption einer Visualisierungssoftware.
Dabei werden in Abschnitt \ref{sec:Anforderungen} die aus den vorherigen Kapiteln resultierenden Anforderungen
beschrieben und dann in Abschnitt \ref{sec:Grenzen} mögliche Grenzen beschrieben. Als nächstes
werden in Abschnitt \ref{sec:bestehendeSoftware} beispielhaft vorhandene Softwarelösungen auf die Anforderungen geprüft.

Im Kapitel \ref{cha:Umsetzung} wird die Implementation eines Prototyps beschrieben. Dabei wird in Abschnitt
\ref{sec:Technologien} auf die verwendeten grundlegenden Technologien eingegangen. Danach wird in Abschnitt
\ref{sec:visPro} das Konzept des benutzten User Interfaces beschrieben und Gründe für diese Entscheidung genannt.
Als letzter Punkt dieses Kapitels wird in Abschnitt \ref{sec:Kernfunktionen} beispielhaft Kernfunktionen
der Software mit dazugehörigen Quelltext gezeigt und erläutert.

Das vorletzte Kapitel \ref{cha:Auswertung} nennt in Abschnitt \ref{sec:Probleme} die Probleme, die während
der Entwicklung aufgetreten sind und wertet die Vorteile (Abschnitt \ref{sec:Vorteile}) und Nachteile
(Abschnitt \ref{sec:Nachteile}) aus.

Das Kapitel \ref{cha:Zusammenfassung} schließt die Arbeit mit einem Fazit in Abschnitt \ref{sec:Fazit} und
einem Ausblick in Abschnitt \ref{sec:Ausblick} ab.

\chapter{Grundlagen}
\label{cha:Grundlagen}
In diesem Teil der Arbeit wird auf die grundlegenden Begriffe eingegangen die einen Zugang
zum Arbeitsfeld der Visualisierung voraussetzen.
\section{Begriffsdefinition Daten und Information}
\label{sec:DatenInfo}
Daten werden in \cite{Gabler} für den Bereich der Informatik als
\begin{quote}
zum Zweck der Verarbeitung zusammengefasste Zeichen, die aufgrund bekannter oder unterstellter Abmachungen
Informationen (d.h. Angaben über Sachverhalte und Vorgänge) darstellen
\end{quote}
beschrieben.
Betrachtung dieser Arbeit sind alle digital gespeicherten Daten.
Diese liegen in einer standardisierten Form vor und können für die elektrische Weiterverarbeitung
und Kommunikation genutzt werden. Dabei sind diese Daten formalisierte Repäsentationen einer
oder mehrerer Informationen. Daten können dabei aus der realen Welt stammen, beispielsweise erhoben durch
die Messung einer physikalischen Größe oder durch Speicherung digital erzeugter Daten, wie
beispielsweise Nutzungsprofile von Webseitenbesuchern.
Der Anwender dieser Daten ist daher nicht direkt an den Daten als solche interessiert, sondern
an den Informationen, die er mit verschiedenen Techniken aus diesen Daten gewinnen kann.

Der Begriff der Information ist schwer einzugrenzen und wird in unterschiedlichen Wissenschaften
in verschiedensten Weisen ausgelegt. Zur Zeit wird im philosophischen Bereich der Erkenntnistheorie versucht
einen allgemeingültigen Informationsbegriff zu bilden. Trotzdem kann noch lange nicht von einer
einheitlichen Theorie der Information gesprochen werden und es beschäftigen sich viele verschiedene
Gebiete wie die Informatik, Informationstheorie, Nachrichtentechnik und andere mit diesem
Begriff.\footnote{Vgl. \citep{wiki_info}} In \citep[S.\,3]{Hoeher} wird der Begriff wie folgt beschrieben:
\begin{quote}
Die Informationstheorie definiert Information als eine quantitativ bestimmbare Wissenzunahme durch
die Übermittlung von Zeichen in einem Kommunikationssystem.
\end{quote}
Information ist also ein Mittel der Kommunikation, die beim Empfänger einen Erkenntnisgewinn auslöst,
sofern dieser den Informationsinhalt entschlüsseln kann. Dafür müssen sich Sender und Empfänger
auf ein Zeichensystem\footnote{blablabla semiotik vgl. http://de.wikipedia.org/wiki/Semiotik} einigen.
In Bezug auf die grapische Darstellungen wird in \citep{Bertin} die Information als  transkribierbarer
Inhalt eines Gedankens definiert, das heißt die Information ist der Teil der Daten, die in einer
Visualisierung dargestellt werden kann. Die Visualisierung als solche hat die Aufgabe, diese Information
für den Menschen zu aufzudecken und in verständlicher Form aufzubereiten. Es wird eine Transformation
der Information aus den reinen Daten, die zwar diese Informationen enthalten, aber für den menschlichen
Betrachter nicht erfassbar sind, in ein leicht verständliches und intuitives Zeichensystem überführt.

Ausgangspunkt dieser Arbeit bilden Informationen die digital verarbeitbar und speicherbar sind.

\section{Eigenschaften von Daten}
\label{sec:EigenschaftenDaten}
In diesem Kapitel wird der Inhalt der Daten und die damit zu extrahierenden Informationen eingegrenzt.
Damit gelten Daten als Ausgangspunkt für die Konzeption einer Visualisierung. Die speziellen
Eigenschaften von DAten sind maßgeblich für weitere Schritte der Visualisierung (siehe auch Pipeline).
Die Kenntnis der Beschaffenheit der Daten ist unabdingbar.
\cite{Schumann} beschreibt ein Modell der Eigenschaften von Daten. Somit hat jeder Datensatz (als Menge von
Daten) folgende Eigenschaften nach denen er klassifiziert werden kann.
\begin{description}
\item[Beobachtungsraum]
Der Beobachtungsraum beschreibt den Raum in dem Daten erhoben werden. Dieser Raum kann ein
dreidimensionaler Raum sein, kann aber auch abstrakt beschrieben werden und nur eine einzige oder
mehr als drei Dimensionen enthalten. Alle Dimensionen die den Beobachtunsgraum aufspannen,
können als unabhängige Variablen(fußnote: kurze erklärung zu running clock / epoch-based) angesehen werden.
\item[Beobachtungspunkt]
Ein Beobachtungspunkt beschreibt Punkte im Beobachtungsraum an denen Daten vorhanden sind. Die Anzahl und Verteilung
dieser Punkte ist unabhängig von der Beschaffenheit des Beobachtungsraumes. Beobachtunsgpunkte haben einen
Wirkungskreis, der die "räumliche" Gültigkeit der Werte beschreibt. Dieser kann punktuell, lokal oder global sein.
\item[Merkmal]
Das Merkmal ist eine Größe die an einem Beobachtungspunkt gemessen oder berechnet wurde. Dabei können
einem Beobachtungspunkt mehrere Merkmale zugeordnet werden. Merkmale gelten dabei als abhängige Variablen.
\item[Ausprägung]
Die Ausprägung beschreibt den Wertebereich und damit alle Werte, die ein Merkmal annehmen kann.
Dabei sind die Datentypen Skalar, Vektor und Tensor möglich. (fußnote mit kurzer erklärung was das is)
\end{description}
Alle diese Eigenschaften können als Metadaten bezeichnet werden und genutzt werden um Daten zu klassifizieren.

\section{Klassifikation von Daten}
\label{sec:KlassifikationDaten}
Für die Klassifikation von Daten gibt es keine einheitlichen Begriffe. \citep{Schumann} unterteilt die Daten
in Varianz und Dimensionalität, während \citep{Preim} ausschließlich von Dimensionen spricht.
In dieser Arbeit werden die Begriffe nach \citep{Schumann} verwendet und mit den Begriffen aus \citep{Preim}
erweitert.
\begin{description}
\item[Multivariate Daten]
Bei multivariaten Daten existiert kein direkter Beobachtungsraum oder dieser kann vernachlässigt werden, da er
keine Rolle für die Weiterverarbeitung der Daten spielt. Sonderformen der multivariaten Daten sind die univariaten,
bivariaten und trivariaten Daten. (mehr beschreibung?!)
\item[Mehrdimensionale Daten]
Bei mehrdimensionalen Daten wird lediglich der Beobachtungsraum beschrieben. Dabei werden die abhängigen Variablen
vernachlässigt und nur die Anzahl der Dimensionen des Beobachtungsraumes beschreibt die Art der Daten.
Multivariate Daten können in multidimensionale Daten überführt werden.
\item[Multiparameterdaten]
sind Daten, die mindestens 2 Merkmale (abhängige Variablen) pro Beobachtungspunkt besitzen. Die Dimensionalität
(größer zwei oder ???), Anordnung und Wirkunsgkreis der Beobachtungspunkte sind beliebig.
Beispielsweise gilt eine SQL-Tabelle mit einer Spalte mit einer Ordnungsnummer und 3 Spalten bereits
als mutlivariater und mehrdimensionaler Datensatz.
Bei der Visualiserung von abhängigen und unabhängigen Variablen in einer Darstellung, sollte darauf geachtet
werden, dass die Unterscheidbarkeit der beiden Klassen gegeben bleibt.\footnote{Da Multiparameterdaten
allgemein sehr schwierig zu visualisieren sind schlägt \citep{Schumann} ein dreistufiges Vorgehen vor:
Focusing zur Auswahl der Daten, Bildgenerierung zur Erzeugung von visueller Repräsentationen, Linking
zur Verknüpfung von Teilsichten zu einer Gesamtansicht.}

bei schumann nochma direkt ins buch gucken!

\item[Raumbezogene Daten]
"Raumbezogene Daten liegen dann vor, wenn der Beobachtungsraum Ortskoordinaten enthält,
die ein 2- oder 3-dimensionales räumliches Bezugssystem definieren."\citep[S.\,219]{Schumann}
Das bedeutet das mindestens zwei und höchsten drei unabhängige Variablen des Datensatzes beispielsweise
ein Koordinatensystem beschreiben. Dieser Raumbezug kann direkt und indirekt erfolgen ist für
den normalen Anwender aber unverzichtbar.\footnote{dazu bitte kapitel XX von schumann lesen s.221}
Ein eindimensionaler Beobachtungsraum ist möglich. Dabei erfolgt die Abbildung zum Beispiel einer
Ordnungsnummer auf einer Linie. Außerdem kommt dem Geltungsbereich bei raumbezogenen Daten eine
besonder Bedeutung zu, da dieser hier auf garkeinen Fall vernachlässigt werden darf,
um Fehlinterpretationen zu vermeiden.
Eine spezielle Form der raumbezogenen Daten sind die Volumendaten, bei denen Beobachtunsgpunkte mit
genau einem skalaren Wert über ein regelmäßiges dreidimensionales Gitter verteilt sind.
\item[Zeitbezogene Daten]
Bie zeitbezogenen Daten kann mindestens eine unabhängige Variable in einen zeitlichen Kontext eingeordnet werden.
Der Zeitbezug kann dabei statisch (fester Zeitpunkt oder Intervall), quasistatisch (mehrere diskrete Zeitpunkte)
oder dynamisch (Zeitreihen) sein. Damit kann die Visualisierung als Unterstützung zur
Zeitreihenanalyse gesehen werden.
Als klassisches Beispiel gelten Börsen- oder Wetterdaten.
\item[Abstrakte Daten]
Bilden eine Sonderform der Daten, da weder ein raum noch ein zeitbezug möglich und sinnvoll ist. Oft dienen diese
Daten als Grundlage der Informationsviz (siehe das kapitel dazu) und stammen aus dem digitalen umfeld(?)
Als Beispiel können Aktienkurse, Verbindungsstatistiken von Netzwerkbetreibern und Relationen zwischen
Dokumenten, Medien und Personen genannt werden.\footnote{Vgl. \citep{Preim}} Als Beispiel für nicht-abstrakte
Daten gelten beispielsweise Wettermessungen an Wetterstationen oder Daten, die bei physikalischen Experimenten
gesammelt wurden. Abstrakte Dimensionen wie Namen von Städten oder Personen sollten als diese gekennzeichnet
werden und erkenn- und unterscheidbar sein. Zum Beispiel bietet sich eine Abbildung auf der X-Achse einer
Darstellung dafür an.
\item[Strukturelle Beziehungen zwischen Datenobjekten]
Diese Daten beschreiben nicht direkte Beobachtungspunkte und Merkmalsausprägungen sondern die Beziehung zwischen
abhängigen Variablen untereinander, unabhängigen Variablen untereinander oder zwischen abhängigen und unabhängigen
Variablen.
Unterschieden wird dabei noch zwischen hierarchischen Formen und Netzwerken. 
\end{description}

\section{Datentypen}
\label{sec:Datentypen}
Datentypen beschreiben die eigentlichen Ausprägungen eines Merkmals und können zu einer zusätzlichen
Klassifikation beitragen. Das ist wichtig um erkennen zu können welche Verarbeitungschritte mit den Datenwerten
möglich sind. Meist erfolgt eine Einteilung in drei Klassen. Während \citep{Bertin} von qualitativen,
geordneten und quantitativen Komponenten spricht, unterscheiden \citep{Preim} nominale, ordinale und
quantitative Datentypen. (Wo ist das bei Schumann?)
In dieser Arbeit werden die neueren Begriffe aus \citep{Preim} verwendet.
\begin{description}
\item{Nominale Datentypen}
beschreiben meist Namen von Datenobjekten. Ihr Abstand ist äquidistant, da vor einer eingehenden Analyse sich
keine Ausprägungen besonders nah oder entfernt stehen. Die einzige mögliche Operation ist der Test auf
Gleichheit beziehungsweise Ungleichheit. Es gibt keine allgemeingültige, eindeutige Reihenfolge
nach der sortiert werden könnte. Dadurch kann nur eine Reihenfolge nach bestimmten Gesichtpunkten erfolgen,
das heißt eine Ordnung eingebracht werden, zum Beispiel durch alphabetische Sortierung von Namen.
\item{Ordinale Datentypen}
haben die gleichen Voraussetzungen wie nominale Typen, außer für die Reihenfolge.
Diese ist bei diesem Typ allgemeingültig festgelegt. Als zusätzlicher Operator kann die Richtung der
Ausprägung durch die Ordnungsrelation genannt werden.
beispiel bei bertin glaub ich!
\item{Quantitative Datentypen}
besitzen einen Wertebereich und gestatten die Durchfühung von arithmetischen Operationen. Es existiert eine
Maßeinheit mit der die Abstände zwischen einzelnen Ausprägungen angegeben werden können. Durch eine 
künstliche Einteilung in Intervalle kann dieser Typ in ordinale Datentypen übersetzt werden. Als Beispiel
dafür können Temperaturwerte beschrieben werden, die in kalt, warm und heiß unterteilt werden.
\end{description}
\section{graphische Semiologie}
\label{sec:graphischeSemiologie}
Die graphische Semiologie ist ein in \cite{Bertin} erstmals beschriebenes System zur Klassifikation von graphischen Zeichen.
Dabei wird versucht die grapische Darstellung auf ein "Grundalphabet" an graphischen Elementen zu reduzieren, wobei
jedem einzelnen Zeichen eine bestimmte Bedeutung zugeordnet wird. \citep{Bertin} spricht dabei von einem
monosemiotischen System aus, das den rationalen Teil der Bilderwelt, also der Diagramme
als graphische Darstellung eindeutig beschreibt.
Da Menschen aber bestimmten grafischen Zeichen unterschiedliche Bedeutungen zuordnen, muss ein "rationaler Moment" (VGL BERTIN)
stattfinden, bei dem sich alle an der Kommunikation Beteiligte auf Bedeutungen einigen die bestimmte Zeichen
haben. ERst dann kann über die Verbindung der Zeichen untereinander dikstutiert werden, was wiederrum der
Information entspricht.
Die graphische Semiologie ist also ein Zeichensystem mithilfe dessen Information in das graphische Zeichensystem
transkribiert werden kann.
Das graphische System umfasst folgende Zeichen die visuelle Variablen genannt werden.

*Position auf der Ebene (angegeben durch x und y)
*Größe
*Helligkeitswert
*Musterung oder Textur
*Farbe
*Richtung oder Orientierung
*Form des Elements

(hier das bild von bertin wo alle viz variablen dargestellt werden)

klärung und definition aller graphischen grundlagen
graphische semiologie?
was macht eine grafik eigentlich aus.....?

Diagramm?

graphische Semiologie
BERTIN spricht von grapischer Semiologie, also von einem genau festgelegten und endlichen Zeichensystem für die graphische Repräsentation von Information.
Information bedeutet dabei siehe BERtin 13 Somit fasst Bertin den Informationsbegriff etwas allgemeiner und fasst damit Daten ein. (stimmt das?)

8 visuelle Variablen nach Bertin ((eine Anforderung an datasynth: muss alle diese abbilden können)):

\chapter{Informationsvisualisierung}
\label{cha:Informationsvisualisierung}
\section{Definition}
\label{sec:Definition}
Die Visualisierung im allgemeinen ist eine "rechnergestützte, visuelle Präsentation von Daten, Informationen und Wissen
in einer für den Menschen adäquaten und für die jeweilige Anwendung in diesem Kontext sinnvollen Form
zu verstehen."\citep[S.\,3]{Schumann}
Dabei wird die rein wissenschaftlich-technische Visualisierung beschrieben, die ausschließlich mit Ausgangsdaten arbeitet,
die einen physikalischen Bezugsrahmen und somit einen konkreten Orts- und Zeitbezug haben. Diese Form der
Visualiserung wird auch Datenvisualisierung genannt.
Da die Informationsdefinition bis jetzt nur quantitativ durchgeführt wurde\footnote{Vgl. Shannon}, stellen sich 
Fragen wie "Wie wichtig ist eine gegebene Information in einem gegegebenen Kontext?"\citep[S.\,341]{Schumann}
oder "Wie kann Menschen geholfen werden, diese Datenfülle zu überblicken, zu verstehen und Einsichten und Erkenntnisse
darüber zu gewinnen?"\citep[S.\,435]{Preim}.
Die Informationsvisualisierung als spezielle Form der Datenvisualisierung versucht Antworten auf solche
Fragen zu finden, die durch ein größeres Spektrum an unterschiedlichen Daten entstehen.
In \citep[S.\,434]{Preim} wird Informationsvisualisierung wie folgt definiert:
\begin{quote}
Informationsvisualisierung beschäftigt sich mit der Visualisierung vorrangig abstrakter Daten, wie
Multiparameterdaten(z.B. Medienobjekte mit verschiedenen Attributen), Hierarchien, Netzwerken, Text
oder Softwaresystemen, die sich alle auch über die Zeit verändern können.
\end{quote}
Das Einsatzgebiet ist nicht mehr nur auf wissenschaftliche Bereiche beschränkt,
sondern wird auch als alternative Suchmethode in Datenbanken\footnote{Vgl. Visual Data Mining KEIM},
als Wissensvermittlung in kulturellen Bereichen\footnote{Farben von Maccandless} und zur Visualisierung von
sozialen Netzwerken verwendet.
Insbesondere die Suche nach Beziehungen zwischen Datenobjekten steht dabei im Vordergrund,
da Informationsräume größer, komplexer und vernetzter werden und damit im Gegensatz
zu physikalischen Daten ein "mentales Bild"\footnote{Vgl. ???????????????????} fehlt.
Es besteht also keine Möglichkeit für räumliche Metaphern um einen Ortsbezug herzustellen.
Somit adressiert das Arbeitsfeld der Informationsvisualisierung, die Thema dieser Arbeit ist,
einen Spezialfall der Datenvisualisierung, der alle Anforderungen an Datenvisualisierung enthält
und mit zusätztlichen Anforderungen, wie Zielgruppe, Repräsentation und Medium, erweitert.
Der Begriff Visualisierung steht damit synonym für Informationsvisualisierung.
Durch die Verschiebung der Inhalte der Datengrundlage aus dem wissenschaftlichen Kontext
in die Alltagskultur, ändern sich auch die Zielgruppe der Visualisierung. Durch das Internet
wird der Personenkreis stark vergrößert, der ein Interesse und Nutzen an Visualisierungen
haben kann, aber keinen mathematischen, natur- oder ingeneurswissenschaftlichen Hintergrund
hat. Damit entstehen weitere Anforderungen. So muss die Visualisierung vom Benutzer
schnell und einfach erfasst und ohne Vorkenntnisse verstanden werden können.
Außerdem muss sie eine "angemessene und grafische Qualität haben, um über den
reinen Nutzwert hinaus auch Qualitäten in Bezug auf Nutzungsfreude und Unterhaltungswert besitzen".\citep[S.\,438]{Preim}
Dafür reichen einfache Datentabellen und Tabellenkalkulationsprogramme wie beispielsweise Microsoft Excel
nicht mehr aus, um notwendige alternative Darstellungsformen zu finden.

Trotzdem muss erwähnt werden, dass die Grenzen zwischen den einzelnen Disziplinen fließend sind
und eine genaue Beschreibung dieser noch aussteht. Informationsvisualisierung kann durchaus
auch wissenschaftlich betrieben werden, da sich die Methoden und verfahren stark ähneln.

\section{Abgrenzung}
\label{sec:Abgrenzung}
Oft berühren Teilgebiete der Informationsvisualiserung verwandte Arbeitsfelder oder werden für die Problemlösung
in anderen Bereichen verwendet. Dieser Umstand macht für diese Arbeit eine klare Abgrenzung notwendig.



Computergrafik
Präsentationvisualisierung
Data Mining
Interfacedesign
Computational Design

Zusätzlich zu diesen Bereichen können noch weitere Bereiche mit untergeordneter Bedeutung gefunden werden.

einordnung an der einteilung von ben fry


Data Mining ist der automatische Versuch, Datenmengen zu ordnen und Erkenntnisse darüber mithilfe von Algorithmen zu finden (DEF? ZIZAT?)
Visualisierung versucht dabei eine geeignete grafische Repräsentation zu finden, die dem Nutzer selbst die Möglichkeit gibt,
diese Erklenntnisse zu finden.

verwandte Arbeitsfelder

viz ist auch ein teil des UI da visuelle repräsentation die primäre quelle der informationsübertragung ist, ob in text, bild oder grafiken.

Häufig sind die Grenzen der einzelnen Arbeitsbereiche nicht klar voneinander getrennt. Verwandte Arbeitsfelder sind (Visual) Data Mining, ....
Weiterhin ist die Visualisierung im allgemeinen ein Teil anderer Arbeitsbereiche. Zum Beispiel spielt die Vizualisierung im Interface Design eine ebenso wichtige Rolle wie im Data Mining.

Abgrenzung zu anderen Bereichen (vielleicht eigener gliederungspunkt) -> data mining.....
Abgrenzung nach innen (ben fry)

\section{Ziele}
\label{sec:Ziele}
was muss eine gute viz können?! (effektivität, expressivität, ...)

unterhaltungswert des graphen und ästhetik spielen eine rolle, denn man muss was gerne anschauen wollen damit man sich überhuapt damit auseinandersetzt
warum braucht man das? welche probleme werden damit gelöst?
welche anforderungen? (in welchen bereichen des täglichen lebens, der wirtschaft)

Welches Problem gibt es?
Warum?
Andere Lösungsansätze?
begrifflichkeit klären und sagen man verwendet ab jetzt nur noch viz stellvertretend für info/data-/sci-viz

sehr spezifische und stark anwendungs und erkenntnis gewinn abhängige anforderungen an visualisierung. 
es ist schwer allgemeingültige aussagen zu treffen wie eine Information am besten visualisiert werden kann und somit muss eine Anwendung einen möglichst generischen ansatz bieten damit der benutzer ohne einschränkung seine spezielle aufgabe die er mit der viz lösen will lösen kann.

erkenntnisgewinn und aufgabe die ich lösen möchte. also eine viz hat ja immer ein konkretes problem was der uafgabe zugrunde liegt und mit viz gelöst werden soll. (das nochmal genau klassifizieren)

welche viz eignet sich am besten für meine konkrete aufgabe?
gibt es mischformen von bis jetzt gefundenen viz mit denen ich meine aufgabe noch besser lösen kann?
gibt es neue ansätze für viz die bis jetzt noch nicht beschrieben sind. (unterstützung der forschung nach neuen formen der viz)

Was ist das Interaktionsziel? (Begriff klären)

diese arbeit bezieht sich auf informationsvisualisierung als sonderfall der datenvisualisietrung. damit werden alle dinge der datavz beachtet und zusätzlich alle sonderfälle der infoviz beachtet

wissenschaftlich, technisch, .... anwendungsgebiete?!
\section{Visualisierungspipeline}
\label{sec:Pipeline}
es gibt mehrere aber ähnlich beschreibungen des ablaufs einer visualisierung.
ben fry und schumann  und preim
\section{Grundprinzip}
\label{sec:Grundprinzip}
dieser schritt wird in der literatur als selbstverständlich angesehen. dagegen bedeuten die regeln wie man unterschiedliceh datentypen und in welcher form darstellt um das beste ergebnis auf eine bestimmte frage zu erhalten sind viel komplexer.
deshalb soll eine software entwickelt werden, die diese triviale aber für einen menschen sehr arbeitsintensive arbeit übernimmt, ohne dabei irgendwelchen einschränkugen zu unterliegen.

ein schritt in der viz pipeline

entwicklung einer kleinen "theorie"
wie können die grundprinzipien der viz auf eine software überrtragen werden?
welche vorteile/nachteile hat das?
welche probleme werden damit gelöst? (keine festlegung mehr auf balken.....)
welche neuen erkenntnisse können damit entstehen? (neue sichtweisen auf daten werden entdeckt, was wiederrum neue sichtweisen des eigentlichen problems aufzeigt)
zugriff und einfluß und übersicht auf alle parameter der geometrie und deren attribute....
dadurch: direkter einfluß aber auch direktes verständis der einzelnen elemente

grafische Transkription (BERTIN)

Auflsitung und kurze Beschreibungen aller möglichen Abbildungen (siehe Schumann S. 126)

als universellen in jeder viz theorie vorkommenden schritt

MAPPING

Verbindung von Variablen der Information mit Variablen der Grafik.
dabei müssen die besonderheiten und merkmale der Komponenten der INFO (siehe bertin) klar sein und müssen auf adäquate visuelle Variablen angewendet werden.
trotz einer nahezu unendlichen auswahl an möglichkeiten zur konstruktion einer grafik sollten ein paar regeln beachtet werden (qualitative klassen nicht auf quantitative variablen usw.)


verschiedene Darstellungsformen
sind alle stark anwendungsabhängig und es muss für jede anforderung festgelegt werden (siehe das kapitel wo steht welche probleme man lösen kann (siehe schumann mit den 3 dingen einer viz, das letzte war kommunikation))
Preim/Dachselt ergänzen zu den von schumann genannten noch die viz von relationen als eigenständige klassifizierung von daten

hier die "datentypen" aufzählen

\section{graphische Darstellungen}
\label{sec:Darstellungen}
Die graphische Darstellung besteht aus graphischen Variablen.

hier ein paar wichtige vertreter der viz formen erklären und zeigen

doch wie können nun die unterschiedlichen Klassen von Daten auf die unterschiedlichen graphischen Variablen und damit
auf die unterschiedlichen graphischen Darstellungen angewendet werden um eine Visualisierung durchzuführen. das sehen
sehen sie im nächsten kapitel.

\chapter{Konzept einer geeigneten Softwarelösung}
\label{cha:Software}
um einen mgölcihst großen bereich aller öglichen viz formen abdecken zu können, wird daher ein ansatz gewählt, der dem benutzer erlaubt die atomaren elemente einer grafik automatisiert designen zu können. somit werden große mengen an datenpunkten in kürzester zeit darstellbar und weiterverarbeitbar.
beispielhafte implementierung “datasynth”
anforderung an so eine software (beispiel1: journalist, beispiel2: privat/künstler)
-> datasynth als Erkundungstool für daten, als datenleser (ist das nicht auch eine kompetenz die man entwickeln sollte: daten lesen und verstehen zu können, also heisst es nicht auch heutzutage und in zukunft immer mehr: daten verstehen heißt die welt verstehen)

Warum visuelle Programmierung? DEFINITION! und nochmal WARUM?
weil es dem zugrundeliegenden prinzip des MAPPING der viz entspricht

statt custom tools etc und immer wieder neu programmieren.....jetzt ein tool

komplexität hinter einem einfachen interface verstecken (klavier aus memo’s talk in london)

einordnung der software mit vergleichen zu anderen apps (grundlage sind funktionalität, also was kommt dabei raus) ist so ein ding zwischen statistiktool spss, 

iterativer prozess der exploration wird unterstützt (vgl. mantra visueller informationssuche) (vgl. preim/dachselt, s 443 ganz unten)

um den vielseitigen anforderungen an eine visualisierung gerecht zu werden, soll daher eine softwar entwickelt werden, die auf einem Level ansetzt den jeder Visualisierungsprozess durchlaufen muss: das Mapping bzw graphische Semiologie. Somit kann der gesamte Bereich der Visualisierungsmöglichkeiten theoretisch abgedeckt werden.

man kann jede visualisierung in ihre grundlegenden graphischen elemente zerlegen.
was sind die grundlegenden graphischen elemente? (herausfinden! vielleicht in bertin!)
\section{Anforderungen}
\label{sec:Anforderungen}
möglichkeit alle datentypen abbilden bzw verarbeiten zu können
bearbeitungsziele sollen schnell und unkompliziert erfüllt werden können

möglichkeit alle informationstypen zu viz0

1. konkretisierung der eigenen problemstellung
software erstellen, was muss sie können, wofür soll sie da sein
also warum z.b. visuelles programmieren usw.
2. entwicklung von hypothesen (oder definition von anforderungen)
was muss die software leisten können?
3. ausführliche beschreibung Untersuchungsmethodik und Vorgehensweise
????

weil mit dem Grundprinzip der Abbildung gearbeitet wird, müssen alle Möglichkeiten dieser in der Software zur Verfügung stehen

keine vorgabe eines bestimmten system sondern die möglichkeit direkt mit grapischen primitiven und ihren attributen wie farb, etc. arbeiten zu können

möglichst viel Parametrisiert um Wertebereiche direkt anpassen zu können

cross-platformness

freie Lizenz

rails als beispiel für MIT Lizenz

\section{Grenzen der Software}
\label{sec:Grenzen}
\subsection{technische Grenzen}
pixel (bildschirm)
farbe (rgb)
\subsection{theoretische Grenzen}
Wird eine grafische Darstellung benutzt, in der mehr als 2 Variablen für die Positionierung der Grafikprimitve
im Raum verwendet werden, muss für die Ausgabe auf dem Monitor oder als Druckerzeugnis eine Projektion
vorgenommen werden.

interaktions- und navigationstechniken nötig
Die Implementierung in dieser Arbeit beschränkt sich auf eine statische Ausgabe ohne Interaktionsmöglichkeiten,
kann aber dahingehend erweitert werden.\footnote{Vgl. Abschnitt \ref{sec:Ausblick}}

\subsection{biologische Grenzen}
wahrnehmungs- und auflösungsfähigkeit des menschen
verständnis (wieviel kann ein mensch mit einmal überblicken)
\subsection{Grenzen durch Implementation}
künstliche Grenzen weil ja nur Prototyp entwickelt wird.
statisch, 2D vollständigkeit wird durch dateninput festgelegt (vgl. schumann 6.2.1, s. 175)

\section{Analyse bestehender Software}
\label{sec:bestehendeSoftware}
diskussion bisheriger lösungsansätze
vorstellen aller software die es bis jetzt gibt, siehe oben
evtl. (SWOT-)Analyse und damit aufzeigen der schwächen der anderen software

es gibt eine vielzahl unterschiedlichster programme und programmbibliotheken die genutzt werden können um daten zu visualisieren.
aus den verschiedenen bereichen: statistik, grafik, ...
es wird hier nur auf eine auswahl eingegangen, die elemente enthalten, die in datasynth sein sollten
vvvv
pd - Pure Data
prefuse
graphviz
...
\chapter{Umsetzung eines Prototyps}
\label{cha:Umsetzung}
1. dokumentation der untersuchungsdurchführung (des Entwicklungsvorganges)
welche tools wurden wie angewendet, c++, of, git, boost, etc etc
2. darstellung der ergebnisse (verdeutlichung durch beispiele, erläuterung des erkenntnisfortschritts)
präsentation von viz mit der software?!
\section{Technologien}
\label{sec:Technologien}
C++
openFrameworks
boost
\section{visuelle programmierung}
\label{sec:visPro}
rapid prototyping / keine programmierkenntnisse erforderlich, ein durchschnittliches mathematisches verständnis reicht
theoretische konzeption
erklärung der einzelnen teile wie nodes etc doch erst bei implementierung?

soll unterstützend sein bei der arbeit mit dem eigentlichen thema und das wesen der problemlösung verdeutlichen

context switches vermeiden (siehe tufte 50) und die gleiche visuelle representation für das problem zeigen.
dadurch das (bei ausreichendem displayplatz) alle elemente des UI und die aktuelle Ausgabe angezeigt werden können, ist der nutzer nicht durch "context switches" abgelenkt und kann sich auf die data viz konzentrieren.
das gilt auch für das verändern von parametern, da im selben augenblick, wie parameter vom nutzer geändert werden, ändern sich auch die ausgabe.
damit kann der nutzer einerseits sofort erkennen was der parameter eigentlich macht und augenblicklich vergleichen und anpassen für seine präferierte lösung
\subsection{Spread}
\subsection{Node}
\subsection{Pin}
\subsection{Connection}
\section{wichtige Kernfunktionen}
\label{sec:Kernfunktionen}
auszüge aus quelltext mit erklärung
\chapter{Auswertung}
\label{cha:Auswertung}
bewertung der ergebnisse vor dem hintergrund der hypothesen/problemstellung (Test des konstrukts und vergleich mit den Anforderungen
was kann die software liefern? wofür bildet sie nur die grundlage? was kann sie nicht?

2. ableiten von schlußfolgerungen
????
so eine software macht sinn, macht keinen sinn?
\section{Probleme bei der Entwicklung}
\label{sec:Probleme}
reflection/introspection von c++
universelle datentypen (schwierig in c++)
geeignete daten finden
mulit-window ausgabe (gelöst mit ofxFenster, da glut das nicht hergibt)
\section{Vorteile}
\label{sec:Vorteile}
durhc parameter kann der benutzer die Wertebereiche der Abbildungen direkt verändern und kann somit auch ohne komplette kenntnis der daten live die beste "einstellung der parameter" herauszufinden, anstatt vorher Metadaten kennen bzw studieren bzw anlegen zu müssen (min,max, ...)

mehrere viz können statisch in einer präsentation kombiniert werden. so kann ohne benutzerinteraktion mehrere blickwinkel auf den datensatz ermöglicht werden

\section{Nachteile}
\label{sec:Nachteile}
benutzer hat alle freiheiten aber muss dadurch auch die grundregeln der viz beherrschen und verstehen ( z.b. kreis radius/fläche, was eignet sich für was am besten)
gestaltungsregeln müssen vom nutzer angwendet werden um viz zu verstärken
Klärung der möglichen Fragen, use nach BERTIN (Theorie des graphischen Bildes)

erweiterbarkeit:
wenn eine gewisse funktionalität noch nicht als node vorliegt, kann diese hinzuprogrammiert werden. verweis dabei auf die angedachten features zur erleichterung von nutzer entwicklungen mit beispielsweise ruby

das statische:
fehlende nutzerinteraktion und dadurch fehlende interaktive kombination von viz techniken (klick auf glyphe erzeugt eine genaue viz der werte dieses datenobjektes)

low-level-ansatz:
führt dazu, dass man immer vom urschleim anfangen muss um komplexe objekte zu erzeugen. deshalb wichtiges feature: kapselbarkeit von mehreren nodes zu einer komplexen high-level-node
so könnte man z.b. eine Sunburst node kreiiren die dann zwar 10 anstöpselmöglichkeiten hat aber sonst nix weiter
man benutzt grafische primitive und manche komplexe viz hat sehr viele primitive in komplexen abhängigkeiten, also kapseln

\chapter{Zusammenfassung}
\label{cha:Zusammenfassung}
1. zusammenfassung der ergebnisse, lesson learned
???
2. optional: persönliche bemerkungen, hinweis auf weiteren forschungsbedarf, ausblick in dei zukunft
was kannnoch alles an der Software getan werden?
\section{Fazit}
\label{sec:Fazit}
eignet sich die software?! JA NEEIN ?
\section{Ausblick}
\label{sec:Ausblick}
Da die software lediglich einen Prototypen darstellt ergeben sich mannigfalitge Erweiterungsmöglichkeiten. Hier sollen einige weniger, dafür aber sehr wichtige mögliche Erweiterungen genannt werden.

ruby
erweiterung auf andere bereiche des visualisierungsprozesses
kapselung von patches
  vielfältige möglichkeiten wie
    erweiterung und kapselung von verschiedenen viz templates als nodes (Isofläche Node oder Flow Ribbons)
    eigene erstellung von ikonen /vgl. schumann s. 197)
    (dazu erfüllt datasynth alle genannten anforderungen von sich aus (editor, binder, viewer)

v4p laden und speichern möglich! crazy!

erweiterung der ausgabemöglichkeiten (statt ausgabe auf bildschirm, ausgabe als postscript, ausgabe als interaktive 3D HTML5 Anwendung (dazu wären navigations und interaktionsmöglichkeiten notwendig (vgl. schumann s. 175), ...)

eng verbunden damit sind die möglichkeit allgemeine interaktionsmöglichkeiten einzubauen um parameter für beispielsweise selektionsbedingungen auch von end-anwendern der viz benutzbar zu machen

evaluationsmöglichkeit (wie kann ich schon in datasynth testen ob die ausgabe geeignet ist) (muss erforscht werden)

automatische generierung von legenden/skalen(+einteilungen), muss erforscht werden inwieweit das überhaupt machbar ist bei einem so universellen ansatz oder ob es nicht doch besser ist, diese dinge der nachbearbeitung zu überlassen (weil datasynth ja nur die massen-arbeit machen soll und nicht einzelne details am ende)

eventbasierte steuerung

threaded nodes

reiner export als abstrakte werte (koordinaten, höhe, breite, typ) in gängige 3D-Austausch-Formate

export von einzelnen teilbereichen (ebenen) zur graphischen weiterverarbeitung mit anderer software

\bibliographystyle{natdin}
\bibliography{diplom}
\listoftables
\listoffigures
%\printnomenclature
\chapter{Anhang}
\section{Beispiel: Bevölkerungsdaten Stadt Leipzig}
viz mit streckenzügen (sternförmig, parallel), kreisen (matrix),
\end{document}

