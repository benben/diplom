\documentclass[a4paper, 
               12pt,
               DIV=calc,
               version=first,
               pdftex,
               headsepline,
               footsepline,
               bibtotocnumbered,
               liststotocnumbered]{scrreprt}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{setspace}
\onehalfspacing

\usepackage[ngerman]{babel}
\usepackage{natbib}
\bibliographystyle{dinat}
\usepackage{url} %correct url display in cites

\usepackage[locale=DE]{siunitx}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
\usepackage{tabularx}

\definecolor{light-gray}{gray}{0.95}

\lstset{%
basicstyle=\scriptsize,
backgroundcolor=\color{light-gray}
}
\setkomafont{captionlabel}{\small\bfseries}
\setkomafont{caption}{\small}

\pagestyle{headings}

\typearea[current]{calc}

%add hyphenation later

\begin{document}
\title{Konzeption und prototypische Realisierung einer Software für die Informationsvisualisierung}
\author{Benjamin Knofe}
\subject{Diplomarbeit}
\publishers{Hochschule für Technik, Wirtschaft und Kultur Leipzig}
\dedication{Danke\\für Kritik, Kommentare, Diskussionen, Code und Hilfe\\
(in alphabetischer Reihenfolge)\\
Christina Sanko, Pyry Jahkola, Ted Mosby, Sarah Walter,
Stephan Keller, Professor Dr.-Ing. Robert Müller, Philip Whitfield, Johannes Knofe, René Zschoch, Moritz Kreutzer, Theresia Becher}
\maketitle
\tableofcontents

\chapter{Einleitung}
\label{cha:Einleitung}
Die Menge an digital gespeicherten Daten nimmt stetig zu. Im Jahr 2011 werden laut einer neuen
Studie\footnote{Vgl. \citep{EMC}} voraussichtlich 1,8 Zettabyte\footnote{1 Zettabyte = \num{1d21}
Byte = 1.000.000.000.000 Gigabyte} an Daten erzeugt und kopiert. In nahezu allen Bereichen unseres
täglichen Lebens werden Daten erhoben, gemessen und gespeichert. Neben der Wissenschaft, Wirtschaft
und Kultur verfolgen öffentliche Bereiche der Politik und Verwaltung eine neue Strategie im Umgang
mit Daten. So haben Städte wie beispielsweise Leipzig eine öffentliche Datenschnittstelle.
Staaten, wie Großbritannien, verfolgen ein ganzheitliches Konzept des e-Government. Aufgrund dieser
aktuellen Entwicklungen ist es notwendig, neue Strategien zu entwickeln, die diese Daten
für die jeweiligen Zielgruppen sinnvoll extrahieren, aufarbeiten und darstellen. Aus diesem
Grund wurden in verschiedenen Forschungsfeldern, wie beispielsweise Statistik, Data Mining,
Computergrafik und Informatik spezielle Lösungsansätze entwickelt.
Die Informationsvisualisierung verbindet Bereiche dieser Disziplinen in einem eigenständigen
Forschungsgebiet.
In diesem wird die Frage geklärt, wie immer abstrakter und komplexer werdende Daten
in einer für den Menschen adäquaten Weise aufbereitet und dargestellt werden können. 
Informationen in Form von Mustern, Wiederholungen und Anomalien sind dadurch leichter auffindbar und erlauben
Rückschlüsse auf den eigentlichen Forschungsgegenstand. Ursprünglich wurden Visualisierungstechniken nur im
naturwissenschaftlichen Kontext angewendet.
Im Gegensatz dazu hat sich die Informationsvisualisierung zu einem populären Arbeitsfeld entwickelt. Sie versucht ein breites
Spektrum an Problemen zu lösen und ist nicht mehr nur ein Werkzeug von Experten und Wissenschaftlern.
Alltägliche Anwendungen
im Bereich der sozialen Netzwerke, beim Onlineshopping und bei der Suche nach Informationen
im Internet können mit der Informationsvisualisierung verbessert
werden. Sie unterstützt die Gestaltung von Benutzerschnittstellen, um diese verständlicher und intuitiv einsetzbar zu machen.
Damit wird es vor allem Gelegenheitsanwendern leicht gemacht, Informationen und
Wissen noch besser mit Anderen zu kommunizieren und teilen. Das erfordert (digitale) Werkzeuge,
die den Benutzer unterstützen und ihm die Möglichkeit geben, Daten für Problemlösungen nutzen zu können.
Um die Informationsvisualisierung erfolgreich einzusetzen, muss eine Vielzahl von Fragstellungen
beantwortet und gelöst werden.
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/beispiel.pdf}
\caption{Beispiel einer Informationsvisualisierung aus \citep[S.\,76]{McCandless}}
\label{fig:beispiel}
\end{figure}
\section{Problemstellung}
Abbildung \ref{fig:beispiel} zeigt beispielhaft eine Informationsvisualisierung, in der die
unterschiedliche Bedeutung von Farben in verschiedenen
Kulturkreisen visualisiert wird. Die einzelnen Ringe der kreisförmigen Darstellung bilden zehn
unterschiedliche Kulturkreise ab. Der Kreis ist unterteilt in 84 Begriffe.
Der Farbton der Rechtecke stellt dar, welche Farbe einem Begriff von Menschen einer bestimmten Kultur zugeordnet wird.
Sie wurde von David McCandless mit einem Vektorgrafikprogramm erstellt, um
eine tiefgreifende Auseinandersetzung zwischen ihm (als menschlichen Betrachter) und den Informationen
zu ermöglichen und Entscheidungen über das Design direkt treffen zu können.\footnote{Vgl. \citep{infoblog}} Der Nachteil dieser
Arbeitsweise ist eine zeitaufwändige manuelle Transkription aller Datenwerte in eine grafische
Darstellung. Bei der Visualisierung von komplexeren Zusammenhängen und größeren Datenmengen würde dieser 
Nachteil noch verstärkt werden und es teilweise unmöglich machen, eine Visualisierung durchzuführen.

In dieser Arbeit wird untersucht, ob es möglich und sinnvoll ist, diesen Prozess  zu automatisieren,
ohne Einschränkungen für den Anwender festlegen zu müssen.
Eine Software muss dafür einen universellen Ansatz verfolgen, um ein breites Spektrum an
unterschiedlichsten Bearbeitungsfällen abdecken zu können. 
Aktuelle Softwarestandards wie beispielsweise Tabellenkalkulationsprogramme oder Programmierbibliotheken
können das nur teilweise leisten oder beschränken sich auf spezielle Anwendungsgebiete.
Meist kann dabei, für die Transkription von Daten zu einer grafischen Darstellung nur
aus einer begrenzten Auswahl an Voreinstellungen gewählt werden.

Um eine universelle Software zu konzipieren, die dem Benutzer eine größtmögliche
Gestaltungsfreiheit einräumt, sind folgende Vorüberlegungen notwendig:
\begin{itemize}
\item{Welche Art von Daten gibt es und wie können diese klassifiziert werden?}
\item{Welche Möglichkeiten der grafischen Darstellung gibt es und wie können diese eingesetzt werden?}
\item{Wie können Daten sinnvoll in eine grafische Darstellung transkribiert werden?}
\end{itemize}
Diese Vorüberlegungen fordern ein Softwarekonzept, das den Anwender besonders bei der 
arbeitsintensiven Transkription
von Daten in eine grafische Darstellung unterstützt.
Um eine iterative und kreative Benutzung zu ermöglichen, muss der arbeitsintensive Vorgang
der Transkription großer Datenmengen in eine grafische Darstellung
automatisch und unmittelbar erfolgen.

Die Konzeption einer auf diese Aspekte spezialisierte Software ist Gegenstand dieser Arbeit.
\section{Aufbau der Arbeit}
Um einen Lösungansatz für das Problem einer universellen Informationsvisualisierung
zu finden, werden in dieser Arbeit Schritte durchgeführt, die die Konzeption einer Software zum Ziel haben.
Diese Software wird prototypisch implementiert.

In Kapitel \ref{cha:Grundlagen} werden die grundlegenden Begriffe beschrieben, die für
das Arbeitsfeld der Informationsvisualisierung wichtig sind. Es werden die Begriffe
\textit{Daten} und \textit{Informationen} definiert und eine Klassifikation von Daten vorgenommen.
Nachfolgend wird ein System zur Beschreibung der Grundelemente einer grafischen Darstellung
eingeführt. 

In Kapitel \ref{cha:Informationsvisualisierung} wird der Begriff der Informationsvisualisierung
definiert und von verwandten Arbeitsfeldern abgegrenzt. Danach werden die Bearbeitungsziele
der Informationsvisualisierung und die Einteilung des Arbeitsprozesses
beschrieben. Im letzten Abschnitt dieses Kapitels wird die grafische Darstellung als Produkt
der Informationsvisualisierung charakterisiert.

In Kapitel \ref{cha:Software} wird eine Software konzipiert.
Der Aufgabenbereich der Software wird durch Anforderungen definiert. Der nächste Abschnitt beschreibt
die visuelle Programmierung als Bedienkonzept. Die Benutzung der Software wird anhand einer
Prozesskette dargestellt. Im letzten Abschnitt dieses Kapitels wird auf bestehende Softwarelösungen
eingegangen.

Kapitel \ref{cha:Umsetzung} dokumentiert die Umsetzung des Prototyps. Neben den verwendeten
Technologien werden Teile der Software beschrieben und erläutert welche Funktionen diese haben.
Am Ende des Kapitels wird auf Probleme bei der Entwicklung eingegangen.

In Kapitel \ref{cha:Auswertung} erfolgt die Auswertung des Prototyps. Dieser wird anhand der zuvor
aufgestellten Anforderungen evaluiert.

In Kapitel \ref{cha:Zusammenfassung} werden die Ergebnisse dieser Arbeit aufgezeigt und ein
Ausblick auf mögliche weiterführende Forschungsarbeit gegeben.

\chapter{Grundlagen}
\label{cha:Grundlagen}
Dieser Teil der Arbeit beschreibt die grundlegenden Begriffe, die einen Zugang
zum Arbeitsfeld der Informationsvisualisierung ermöglichen.
\section{Daten und Information}
\label{sec:DatenInfo}
Daten werden als "`zum Zweck der Verarbeitung zusammengefasste Zeichen,
die aufgrund bekannter oder unterstellter Abmachungen
Informationen (d.h. Angaben über Sachverhalte und Vorgänge) darstellen"'\footnote{\citep{Gabler}}, beschrieben.
Als Gegenstand dieser Arbeit werden digital gespeicherte Daten betrachtet.
Diese liegen in einer standardisierten Form vor und können für die elektronische Weiterverarbeitung
und Kommunikation genutzt werden. Diese Daten sind dabei formalisierte Repräsentationen einer
oder mehrerer Informationen, die übermittelt werden sollen.
Daten können dabei aus der realen Welt stammen, beispielsweise erhoben durch
die Messung einer physikalischen Größe, oder sie wurden digital erzeugt, beispielsweise durch
computergestützte Simulationen oder durch die Nutzung von Telekommunikationstechnik.
Der Anwender ist an den Informationen und dem aus ihnen resultierenden Erkenntnisgewinn interessiert, die er mit verschiedenen
Techniken aus diesen Daten gewinnen kann.

Der Begriff der Information ist schwer einzugrenzen und wird in unterschiedlichen Wissenschaften
in verschiedenen Formen ausgelegt. Der philosophische Bereich der Erkenntnistheorie versucht,
einen allgemeingültigen Informationsbegriff zu definieren. Trotzdem kann noch nicht von einer
einheitlichen Theorie der Information gesprochen werden. Es beschäftigen sich viele verschiedene
Gebiete wie die Informatik, Informationstheorie, Nachrichtentechnik und andere mit diesem
Begriff.\footnote{Vgl. \citep{wiki_info}} In \cite{Hoeher} wird die Information wie folgt beschrieben:
\begin{quote}
"`Die Informationstheorie definiert Information als eine quantitativ bestimmbare Wissenzunahme durch
die Übermittlung von Zeichen in einem Kommunikationssystem."'\footnote{\citep[S.\,3]{Hoeher}}
\end{quote}
Information ist das Ergebnis der Kommunikation, das beim Empfänger einen Erkenntnisgewinn auslöst,
sofern dieser den Informationsinhalt entschlüsseln kann. Dafür müssen sich Sender und Empfänger
auf ein Zeichensystem einigen.
In Bezug auf grafische Darstellungen wird in \cite{Bertin} die Information als der transkribierbare
Inhalt eines Gedankens definiert. Das heißt die Information ist der Teil der Daten, die in einer
Informationsvisualisierung dargestellt werden kann. Die Informationsvisualisierung als solche hat die
Aufgabe, diese Information für den Menschen aufzudecken und in verständlicher Form aufzubereiten.
Die reinen Daten, die zwar diese Informationen enthalten,
aber für den menschlichen Betrachter nicht erfassbar sind, werden in ein grafisches
Zeichensystem transformiert. Dieses grafische System erlaubt dem Menschen eine natürliche, visuelle und
damit effektivere Analyse.

\section{Eigenschaften von Daten}
\label{sec:EigenschaftenDaten}
In diesem Kapitel werden die Eigenschaften von Daten beschrieben. Sie bestimmen, wie die eigentlichen Informationen
in den Daten codiert sind.
Digitale Daten gelten als Ausgangspunkt für die Konzeption einer Informationsvisualisierung. Die speziellen
Eigenschaften von Daten sind maßgeblich für weitere Schritte der Informationsvisualisierung.\footnote{Vgl. 
Abschnitt \ref{sec:Pipeline}}
Die Kenntnis der Beschaffenheit der Daten ist somit Voraussetzung für alle nachfolgenden Schritte.
\cite{Schumann} beschreiben ein Modell der Eigenschaften von Daten. Jeder Datensatz\footnote{Menge von Daten}
hat folgende Eigenschaften, nach denen er klassifiziert werden kann:
\begin{description}
\item[Beobachtungsraum]
Der Beobachtungsraum beschreibt den Raum, in dem Daten erhoben werden. Dieser Raum kann ein
dreidimensionaler Raum sein, kann aber auch abstrakt beschrieben werden und nur eine einzige oder
mehr als drei Dimensionen besitzen. Alle Dimensionen des Beobachtungsraumes werden als \textit{unabhängige
Variablen} bezeichnet, da sie vor der Datenerhebung festgelegt werden und als beschreibende Begriffe für
den zu visualisierenden Sachverhalt gelten.\footnote{\citep[S.\,24]{Bertin} bezeichnet die unabhängigen
Variablen als Invariante und definiert: "`Die Invariante ist der vollständige und in bezug [sic] auf alle vorgegebenen
Begriffe invariable Kennzeichnungsbegriff."'} Im Beispiel aus Abbildung \ref{fig:beispiel} können die
gewählten Kulturkreise und die verschiedenen Begriffe als unabhängigen Variablen bezeichnet werden.
\item[Beobachtungspunkt]
Ein Beobachtungspunkt beschreibt eine Position im Beobachtungsraum an dem Daten vorhanden sind. Die Anzahl und die Verteilung
der Beobachtungspunkte sind unabhängig von der Beschaffenheit des Beobachtungsraumes. Beobachtungspunkte haben einen
Wirkungskreis, der die "`räumliche"' Gültigkeit der Werte beschreibt. Dieser kann punktuell, lokal oder global sein.
Im Beispiel aus Abbildung \ref{fig:beispiel} sind alle farbigen Rechtecke im Kreis Beobachtungspunkte, denn an
diesen konnte ein zugehöriger Farbwert recherchiert werden.
\item[Merkmal]
Das Merkmal ist eine Größe, die an einem Beobachtungspunkt gemessen oder berechnet wird. Dabei kann
ein Beobachtungspunkt mehrere Merkmale besitzen. Merkmale werden als \textit{abhängige Variablen} bezeichnet, da
sie von der Position des Beobachtungspunktes im Beobachtungsraum abhängig sind.
Im Beispiel aus Abbildung \ref{fig:beispiel} ist der Farbton eines Rechtecks im Kreis ein Merkmal.
\item[Ausprägung]
Die Ausprägung beschreibt den eigentlichen Wert, den ein Merkmal annehmen kann. Dieser Wert hat einen
Wertebereich und kann ein Skalar oder Vektor sein.\footnote{In einem dreidimensionalen Beobachtungsraum
kann der Beobachtungspunkt auch als Vektor angesehen werden. Im Falle einer Ausprägung als Vektor, liegt damit
an der Position des Beobachtungspunktes im Beobachtungsraum ein weiterer Vektor vor.}
In Abbildung \ref{fig:beispiel} ist beispielsweise im amerikanischen Kulturkreis (A) für Liebe (53) die Farbe
Rot ablesbar. Der dazugehörige Wertebereich der Farben wird im oberen linken Bereich dargestellt.
\end{description}
Die Begriffe Beobachtungsraum, Beobachtungspunkt, Merkmal und Ausprägung dienen zur Klassifikation von Daten
und werden als Metadaten bezeichnet.

\section{Klassifikation von Daten}
\label{sec:KlassifikationDaten}

Die Klassifikation von Daten wird sehr unterschiedlich durchgeführt.
\cite{Schumann} weisen auf eine uneinheitliche Begriffswahl in unterschiedlichen
Publikationen hin.
Hier wird eine vereinfachte Einteilung dargestellt. Diese wird nach der Anzahl der abhängigen und
unabhängigen Variablen und nach dem Ursprung der Daten vorgenommen.

\subsection{Mehrdimensionale Daten}
Ein Beobachtungsraum hat eine endliche Anzahl an Dimensionen. Ist die Anzahl
dieser \textit{unabhängigen} Variablen größer Eins, wird von \textit{mehrdimensionalen Daten} gesprochen. Das Beispiel
in Abbildung \ref{fig:beispiel} hat zwei unabhängige
Variablen (Kulturkreis und Begriff) und damit zwei Dimensionen.

Eine Sonderform der mehrdimensionalen Daten sind die raumbezogenen Daten.
"`Raumbezogene Daten liegen dann vor, wenn der Beobachtungsraum Ortskoordinaten enthält,
die ein 2- oder 3-dimensionales räumliches Bezugssystem definieren."'\footnote{\citep[S.\,220]{Schumann}}
Beispielsweise bedeutet das, dass mindestens zwei und maximal drei unabhängige Variablen des Datensatzes
ein Koordinatensystem beschreiben können. Diese Form der Informationsvisualisierung findet häufig
in Geoinformationssystemen Anwendung.

In Bezug auf den Beobachtungsraum sind die zeitbezogenen Daten ein weiterer Spezialfall.
Dabei ist eine unabhängige Variable mit der physikalischen Größe Zeit assoziiert.
Dieser Bezug entspricht nicht immer den tatsächlichen zeitlichen Änderungen und macht
eine adäquate Skalierung der zeitbezogenen Dimension notwendig.
Beispielsweise besteht die Möglichkeit, bei einer Wetterstation die kontinuierliche Veränderung der Außentemperatur
nur einmal pro Stunde zu messen. Dadurch liegen die Messwerte in diskreten Intervallen vor.
Diese Problematik muss in der Visualisierung beachtet werden.

\subsection{Multiparameterdaten}
Daten werden als \textit{Multiparameterdaten} bezeichnet, wenn die Anzahl der \textit{abhängigen} Variablen größer Eins ist
und der Beobachtungsraum nicht vernachlässigt werden kann. Das setzt komplexere
Informationsvisualisierungen voraus, da unabhängige und abhängige Variablen gemeinsam
dargestellt werden müssen. Die Unterscheidbarkeit zwischen diesen Klassen muss dabei
erhalten bleiben.
Ein Beispiel für einen Multiparameterdatensatz ist eine Liste mit Wetterstationen, die durch ihre
Koordinaten bestimmt sind. Zusätzlich dazu liegen für jede Wetterstation unterschiedliche
Daten für Temperatur, Luftdruck und Niederschlag vor.\footnote{Das Beispiel aus Abbildung
\ref{fig:beispiel} ist kein Multiparameterdatensatz, da nur der Farbton der Rechtecke als
abhängige Variable bezeichnet werden kann. Durch zusätzliche Informationen könnten die
zugrundeliegenden Daten aber zu einem Multiparameterdatensatz erweitert werden. Beispielsweise
könnte die Wichtigkeit der einzelnen Begriffe in einem Kulturkreis in der Größe der
Farbfläche dargestellt werden. So würde zum Beispiel der Begriff "`Religion"' (48) für
bestimmte Kulturkreise größer dargestellt werden. Andere Farbflächen erschienen dagegen
kleiner.}

Eine Sonderform der Multiparameterdaten sind die multivariaten Daten. Dabei kann
der Beobachtungsraum vernachlässigt werden, da er keine Rolle bei der Weiterverarbeitung
der Daten spielt. Multivariate Daten können in mehrdimensionale Daten überführt werden,
wenn für jedes vorhandene Merkmal eine Dimension in einem neuen Beobachtungsraum
aufgespannt wird.\footnote{Vgl. \citep[S.\,172]{Schumann}} Ein Datensatz der alle
Antworten von befragten Personen einer anonym geführten Umfrage enthält, ist ein Beispiel
für Multiparameterdaten. Die einzelnen Fragen sind die abhängigen Variablen und
die Antworten der Befragten sind deren Ausprägungen. Unabhängige Variablen wie beispielsweise
Alter, Wohnort und Geschlecht der Person fehlen dagegen.

\subsection{Abstrakte Daten}
Die wissenschaftlich-technische Datenvisualisierung ist auf naturwissenschaftliche Daten fokussiert.
Das können Daten über die menschliche Anatomie, das Universum oder über Moleküle und Atome sein. Diese Daten
haben einen räumlichen Bezug. Visualisierungen von Abstraktionen des physikalischen Raumes
sind möglich. Trotzdem hat die zugrunde liegende Information eine geometrische Natur.\footnote{Vgl. \citep[S.\,6]{Card}}
Fehlt ein naturwissenschaftlicher Raumbezug oder ist er nicht sinnvoll, werden Daten als \textit{abstrakte Daten} bezeichnet.
Zwischen dem Beobachtungsraum dieser Art von Daten und unserer realen dreidimensionalen Umgebung und unserem zeitlichen Empfinden
besteht kein oder nur ein sehr schwacher Zusammenhang.
Abstrakte Daten werden meist in rein digitalen und virtuellen Prozessen erzeugt. Als Beispiel
können die Datei- und Ordnerstrukturen eines Betriebssystems oder Texte und Quellcode von Programmen genannt werden.

Eine spezielle Form der abstrakten Daten sind strukturelle Beziehungen zwischen Datenobjekten.
Diese Daten beschreiben nicht Beobachtungspunkte und deren Merkmale, sondern die Beziehungen
zwischen diesen Punkten und ihren abhängigen und unabhängigen Variablen. Unterschieden wird dabei
zwischen hierarchischen Formen und Netzwerken. Beispiele sind die Relationen zwischen Dokumenten,
Medien und Personen in einem Netzwerk.\footnote{Vgl. \citep{Preim}}

Rein zeitbezogene Daten werden in dieser Arbeit den abstrakten Daten zugeordnet. Ein Börsenkurs ist bei näherer Betrachtung
abstrakt, da kein räumlicher Bezug stattfindet.
Die einfache Abbildung in einem Diagramm, bei dem die Zeit auf der Abszissenachse und der Wert einer Aktie auf der Ordinatenachse
abgebildet sind, sind nur erlernte Metaphern. Die "`Höhe"' des Aktienwertes stellt dabei keinesfalls eine räumliche
Höhe dar, sondern eine abstrakte Wertebeschreibung.

Die Informationsvisualisierung, wie sie in Kapitel \ref{cha:Informationsvisualisierung} beschrieben wird, benutzt
vorrangig \textit{abstrakte Multiparameterdaten} als Grundlage einer grafischen Darstellung.

\section{Datentypen}
\label{sec:Datentypen}
Datentypen beschreiben die eigentlichen Ausprägungen eines Merkmals und können zu einer zusätzlichen
Klassifikation beitragen. Das ist wichtig um erkennen zu können welche Verarbeitungschritte mit den Daten
möglich sind. Meist erfolgt eine Einteilung in drei Klassen. Während \cite{Bertin} von qualitativen,
geordneten und quantitativen Komponenten spricht, unterscheiden \cite{Preim} nominale, ordinale und
quantitative Datentypen.
Hier wird die neuere Einteilung von \cite{Preim} erläutert.
\begin{description}
\item[Nominale Datentypen]
Meist werden Namen und Bezeichnungen von Datenobjekten als nominale Datentypen klassifiziert.
Ihr Abstand ist äquidistant, da sich vor einer eingehenden Analyse
keine Ausprägungen besonders nah oder entfernt voneinander zeigen. Die einzige mögliche Operation ist der Test auf
Gleichheit beziehungsweise Ungleichheit. Es gibt keine allgemeingültige, eindeutige Reihenfolge
nach der die Ausprägungen sortiert werden könnten. Dadurch kann nur eine Reihenfolge nach bestimmten Gesichtpunkten erfolgen.
Das heißt eine künstlich erzeugte Ordnung wird eingebracht, zum Beispiel durch alphabetische Sortierung von Namen.
In Abbildung \ref{fig:beispiel} haben die Farben, Kulturkreise und Begriffe einen nominalen Datentyp.
\item[Ordinale Datentypen]
haben die gleichen Eigenschaften wie nominale Typen.
Zusätzlich dazu ist die Reihenfolge allgemeingültig festgelegt. Dadurch kann als zusätzlicher Operator für Vergleiche die Richtung der
Ausprägung genutzt werden. Diese ist durch eine Ordnungsrelation bestimmt. Ein Beispiel für ordinale Daten sind Temperaturwerte,
die in drei Klassen "`kalt"', "`warm"' und "`heiß"' unterteilt werden. Neben der Unterscheidung zwischen den drei
Klassen kann eindeutig bestimmt werden, dass auf die Klasse "`kalt"' die Klasse "`warm"' und dann die Klasse
"`heiß"' folgt. 
\item[Quantitative Datentypen] besitzen einen Wertebereich und gestatten die Durchführung von arithmetischen Operationen.
Es existiert dabei eine Maßeinheit, mit der die Abstände zwischen einzelnen Ausprägungen angegeben werden können. Durch eine 
künstliche Einteilung in Intervalle kann dieser Typ in ordinale Datentypen übersetzt werden.
Ein Beispiel ist eine Temperaturmessung, bei der die Zahlenwerte in der Einheit Grad Celcius gespeichert werden.
\end{description}
\section{Grafische Semiologie}
\label{sec:grafischeSemiologie}
Die grafische Semiologie ist ein von \cite{Bertin} erstmals beschriebenes System zur Klassifikation von grafischen Zeichen.
Es stammt ursprünglich aus der thematischen Kartographie.\footnote{"`Thematische Karten enthalten vorwiegend
Erscheinungen oder Vorkommnisse nicht topographischer Art, welche jedoch mit der Erdoberfläche in Verbindung
stehen. Es handelt sich hierbei um Dinge, die georäumliche Lage, Verbreitung oder Bewegung besitzen, sowohl
um reale Dinge, als auch um Beziehungen, Funktionen, Hypothesen, geistige Vorstellungen, Möglichkeiten und
Projekte."'\citep{Gitta} } Dies ist ein Teilgebiet der Geographie und eines der ersten Anwendungsgebiete der
Informationsvisualisierung.
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/visuelleVariablen.pdf}
\caption{Visuelle Variablen aus \citep[S.\,51]{Bertin} Legende: 2D = Position in der Ebene, FO = Form, GR = Größe,
HW = Helligkeitswert, MU = Musterung/Textur, FA = Farbe, RI = Richtung}
\label{fig:visuelleVariablen}
\end{figure}
Diese Theorie definiert ein "`Grundalphabet"' an grafischen Elementen, wobei zur Informationsübertragung
jedem einzelnen Zeichen eine bestimmte Bedeutung zugeordnet wird. \cite{Bertin} geht dabei von einem
monosemiotischen\footnote{"`Die Betrachtung einer Zeichenverbindung setzt die Kenntnis der Bedeutung jedes
einzelnen Zeichens voraus."'\citep[S.\,3]{Bertin}} System aus, das den rationalen Teil der Bilderwelt, die
grafische Darstellung, eindeutig beschreibt.
Da Menschen aber bestimmten grafischen Zeichen unterschiedliche Bedeutungen zuordnen, muss ein "`rationales Moment"'
stattfinden, bei dem sich alle an der Kommunikation Beteiligten auf Bedeutungen einigen,
die bestimmte Zeichen in der grafischen Darstellung haben. Erst dann kann über die Verbindung der Zeichen untereinander diskutiert
werden. Diese Verbindungen entsprechen der eigentlichen Information. Beispielsweise können
durch die Position von grafischen Primitiven untereinander Aussagen über ihre eigentlichen Beziehungen getroffen werden.
Dabei spielen die Gestaltungsgesetze eine wichtige Rolle.
Mit der grafischen Semiologie können also Informationen in ein grafisches Zeichensystem
transkribiert werden. Dieses System umfasst folgende acht Zeichen, die zur Kodierung von Daten in eine grafische Darstellung benutzt
werden können. Sie werden visuelle Variablen genannt und beschreiben die Eigenschaften geometrischer Primitive.
\begin{itemize}
\item Position auf der Ebene (zwei visuelle Variablen x und y)
\item Größe (Fläche oder Länge)
\item Helligkeitswert
\item Musterung oder Textur
\item Farbe
\item Richtung oder Orientierung
\item Form des Elements
\end{itemize}
In Abbildung \ref{fig:visuelleVariablen} werden diese dargestellt. Im Initialbeispiel in Abbildung
\ref{fig:beispiel} werden die visuellen Variablen der Position, Farbe und Richtung verwendet,
um die Information in den kreisförmig angeordneten farbigen Rechtecken darzustellen.

Jede dieser Variablen hat spezifische Eigenschaften, wodurch sie sich unterschiedlich gut oder schlecht
für spezielle Aufgaben eignen. Um für eine Aufgabe die geeignetste Variable zu bestimmen, schlägt
\cite{Bertin} mehrere Konstruktionsregeln vor.
Grundlegend beschreiben diese eine Vereinfachung der grafischen Darstellung.
Die Anzahl an visuellen Variablen, Merkmalen und Ausprägungen wird reduziert,
sodass die grafische Darstellung als Ganzes mit einem Minimum an Wahrnehmungsaufwand erfasst werden kann.
Dabei dürfen keine Informationen und Beziehungen zwischen diesen verloren gehen, um Fehlinterpretationen
zu vermeiden. Weitere Regeln sind stark abhängig von der Anzahl
der vorhandenen Dimensionen des Beobachtungsraumes, der Anzahl der Merkmale eines
Beobachtungspunktes\footnote{Vgl. Abschnitt \ref{sec:EigenschaftenDaten}} und der gewählten
grafischen Darstellung. Da für die komplexen graphischen Darstellungen einer 
Informationsvisualisierung meist mehrere visuelle Variablen eignen, kann eine Auswahl
durch den Abgleich mit den Bearbeitungszielen\footnote{Vgl. Abschnitt \ref{sec:Ziele}} erfolgen.
Beispielsweise eignen sich für wichtige, geordnete Variablen die Position in der Ebene,
während Variablen wie Farbe, Muster und Textur als Möglichkeit genutzt werden können, um Zusatzinformationen zu kodieren.
Erst wenn weitere Variablen hinzugefügt werden, muss eine Nebeneinanderstellung oder
Überlagerung in Betracht gezogen werden.
Die Konstruktionsregeln und die visuellen Variablen werden genutzt, um
die grafische Darstellung als Ziel der Informationsvisualisierung zu erstellen.

\chapter{Informationsvisualisierung}
\label{cha:Informationsvisualisierung}
\section{Definition}
\label{sec:Definition}
Die Visualisierung ist im Allgemeinen als eine "`rechnergestützte, visuelle Präsentation von Daten, Informationen und Wissen
in einer für den Menschen adäquaten und für die jeweilige Anwendung in diesem Kontext sinnvollen Form
zu verstehen."'\footnote{\citep[S.\,3]{Schumann}}
Sie nutzt das Vermögen des menschlichen Gehirns durch visuelle Reize große Mengen an Information
intuitiv erfassen und verarbeiten zu können. Dabei werden die natürlichen Fähigkeiten des Menschen,
wie beispielsweise die Muster- und Farberkennung, genutzt, um ohne besondere Vorkenntnisse Entscheidungen über
einen Sachverhalt treffen zu können. Zum Beispiel kann jeder Mensch zwischen zwei Objekten entscheiden,
welches das größere oder hellere Objekt ist, solange die visuellen Unterschiede ausreichend groß sind.\footnote{
Eine Ausnahme bilden Menschen mit einer Sehbehinderung. Um eine Visualisierung für diese Menschen
nutzbar zu machen, gelten besondere Anforderungen, die nicht Teil dieser Arbeit sind.}

Die wissenschaftlich-technische Visualisierung ist eine Sonderform der Visualisierung. Sie arbeitet ausschließlich mit Ausgangsdaten,
die einen natur- oder ingeneurswissenschaftlichen Bezugsrahmen und somit einen konkreten Ortsbezug haben. Diese Form der
Visualiserung wird auch Datenvisualisierung genannt. Dabei wird von einem, durch die Informationstheorie
geprägten, quantitativen Informationsbegriff ausgegangen.\footnote{Vgl. 
Abschnitt \ref{sec:DatenInfo}}

Für die Visualisierung von Informationen sind weiterführende, qualitative Fragen von Bedeutung:
\begin{itemize}
\item Was macht eine Information in einem gegebenen Kontext wichtig oder unwichtig?
\item Wie kann das Verständnis von großen Informationsmengen für Menschen vereinfacht werden?
\item Wie können Informationen visuell aufbereitet werden, um eine effizientere Problemlösung zu ermöglichen?
\end{itemize}
Diese Fragen, die aufgrund eines wachsenden Spektrums an abstrakten Daten immer wichtiger werden,
versucht die Informationsvisualisierung zu beantworten.
\cite{Preim} definieren Informationsvisualisierung folgendermaßen:
\begin{quote}
"`Informationsvisualisierung beschäftigt sich mit der Visualisierung vorrangig abstrakter Daten, wie
Multiparameterdaten (z.B. Medienobjekte mit verschiedenen Attributen), Hierarchien, Netzwerken, Text
oder Softwaresystemen, die sich alle auch über die Zeit verändern können."'\footnote{\citep[S.\,434]{Preim}}
\end{quote}
Das Einsatzgebiet der Informationsvisualisierung ist im Gegensatz zur Datenvisualisierung nicht
auf wissenschaftliche Bereiche beschränkt,
sondern kann beispielsweise auch als alternative Suchmethode in Multimedia-Datenbanken\footnote{Vgl. Visual Data Mining in \citep{Keim}},
als Wissensvermittlung in kulturellen Bereichen\footnote{Vgl. Abbildung \ref{fig:beispiel}} und zur Visualisierung von
sozialen Netzwerken und Fahrplänen öffentlicher Verkehrsmittel verwendet werden.
Insbesondere steht die Suche nach Beziehungen zwischen Datenobjekten im Vordergrund,
da Informationsräume größer, komplexer und vernetzter werden. Im Gegensatz
zu naturwissenschaftlichen Daten existiert dabei nicht immer ein räumlicher Bezug.
Eine Aufgabe der Informationsvisualiserung ist es, diesen Ortsbezug beim Betrachter wieder herzustellen.
Dieser Ortsbezug wird bei abstrakten Daten künstlich erzeugt, da
Menschen es gewöhnt sind, in dreidimensionalen Räumen zu interagieren.
Somit können bewusste und unbewusste Verhaltensweisen aus der realen Welt genutzt werden, um den
kognitiven Aufwand, der für das Verständnis der Information nötig ist, zu minimieren.

Durch die Verschiebung der Daten aus dem wissenschaftlichen Kontext
in die Alltagskultur ändert sich die Zielgruppe der Visualisierung. Durch das Internet
wird der Personenkreis stark vergrößert, der ein Interesse und Nutzen an Informationsvisualisierungen
hat. Es enstehen weitere Anforderungen, da dieser Gruppe meist ein mathematischer, natur- oder ingenieurswissenschaftlicher Hintergrund
fehlt. So muss die Informationsvisualisierung vom Benutzer
schnell und einfach erfasst und ohne besondere Vorkenntnisse verstanden werden können.
Außerdem muss sie eine "`angemessene und grafische Qualität haben, um über den
reinen Nutzwert hinaus auch Qualitäten in Bezug auf Nutzungsfreude und Unterhaltungswert [zu] besitzen."'\footnote{\citep[S.\,438]{Preim}}
Es wird zunehmend schwieriger solche Darstellungsformen mit aktuellen Softwarestandards zu erstellen.

Die Grenzen zwischen den einzelnen Disziplinen der Visualisierung sind fließend. Die Informationsvisualisierung kann
auch wissenschaftlich betrieben werden, da sich Methoden und Verfahren stark ähneln.
Das Arbeitsfeld der Informationsvisualisierung, die Thema dieser Arbeit ist,
geht von einem Spezialfall der Datenvisualisierung aus. Dieser erweitert die Anforderungen an Datenvisualisierung mit
Betrachtungen über die Zielgruppe, die Repräsentation und das Medium. Dabei kommen digitale
Techniken zur Erhebung, Speicherung, Weiterverarbeitung und Ausgabe zum Einsatz.

\section{Verwandte Arbeitsfelder}
\label{sec:Arbeitsfelder}
Oft nutzt die Informationsvisualisierung Teilgebiete verwandter Arbeitsfelder oder sie wird für die Problemlösung
in anderen Bereichen verwendet.
Nachfolgend werden Arbeitsgebiete beschrieben, die häufig mit der Informationsvisualisierung in Verbindung
gebracht oder verwechselt werden. Eine klare Abgrenzung der Bereiche ist schwierig. Die nachfolgende Liste zeigt
eine Auswahl und erhebt keinen Anspruch auf Vollständigkeit.
\begin{description}
\item[Computergrafik]
Die Computergrafik ist ein Teil der Informatik und beschreibt die Ausgabe von zwei- und dreidimensionalen
Objekten als Raster oder Vektorgrafik. Die Informationsvisualisierung benutzt Techniken der Computergrafik, ist aber kein
Bestandteil dieses Gebietes.
\item[Statistik]
Die Statistik ist ein Verfahren für die "`hypothesengeleitete Auswertung von numerischen (quantitativen)
Daten"'\citep[S.\,23]{Statistik}. Durch die Verwendung quantitativer Daten wird eine Verbindung zwischen
Empirie und Theorie geschaffen.  Neben der Mathematik ist die Visualisierung das wichtigste
Werkzeug der Statistik. So wird der Visualisierungsprozess aus Abschnitt \ref{sec:Pipeline} besonders
im Bereich der deskriptiven Statistik benutzt, um Erkenntnisse zu gewinnen und darzustellen.
Auch die Informationsvisualisierung als eigenständige Disziplin benutzt Techniken der Statistik, um Daten aufzubereiten.
\item[Präsentations- und Prozessvisualisierung]
Häufig werden Präsentations- und Prozessvisualisierungen als Informationsvisualisierung bezeichnet, sind
aber eigenständige Gebiete. In ihnen geht es auch um das Sichtbarmachen von Informationen. Diese basieren aber nicht auf
großen Datenmengen und können auch ohne Softwareunterstützung erstellt werden. Bei der Visualisierung
von Prozessen muss die Zeit als besonderer Faktor berücksichtigt werden.
\item[Data Mining] ist der computergestützte automatisierte Versuch, Datenmengen zu ordnen und mithilfe
von Algorithmen Erkenntnisse zu erhalten. Im Gegensatz dazu versucht die Informationsvisualisierung eine geeignete
grafische Repräsentation
bereitzustellen, die dem Nutzer die Möglichkeit gibt, diese Erkenntnisse selbst zu finden. Für die Datengewinnung
ist die Informationsvisualisierung auf Techniken des Data Mining angewiesen. Es gibt Bestrebungen beide Gebiete 
im "`Visual Data Mining"'\footnote{Vgl. \citep{Keim}} zu Verbinden, um Synergien zu bilden.
\item[Interface- und Interactiondesign]
Diese Felder beschreiben die Gestaltung von Benutzeroberflächen. Damit arbeiten sie, wie die Visualisierung, an
der Schnittstelle zwischen Mensch und Maschine. Interfacedesign benutzt häufig Techniken der Visualisierung,
um grafische Konzepte zu realisieren, da die Informationen primär visuell übertragen werden.
\item[Computational Design]
Dieser von \cite{BenFry} eingeführte Begriff beschreibt die Vereinigung vieler Disziplinen zu einem neuen
interdisziplinären Arbeitsfeld. Der Ansatz des Computational Designs ist es, die Informationsvisualisierung in einem größeren
Kontext zu betrachten und dabei die technischen Bereiche der Informatik mit den künstlerischen
Bereichen des Designs zu verbinden. Der Prozess des Computational Designs wird in Abschnitt \ref{sec:Pipeline}
genutzt, um den Arbeitsprozess der Informationsvisualisierung zu beschreiben.
\end{description}

\section{Bearbeitungsziele}
\label{sec:Ziele}
Mit der Informationsvisualisierung wird die Analyse einer gegebenen Datenmenge unterstützt.
Es können Ergebnisse effizient präsentiert werden. Dadurch wird die Kommunikation vereinfacht,
um einen Erkenntnisgewinn bei allen Beteiligten zu schaffen.
Die Visualisierung kann nach \cite{Schumann} für die drei folgenden Stufen der Analyse eingesetzt werden:
\begin{description}
\item[Explorative Analyse]
Die explorative Analyse beschreibt die Eigenschaften von Daten als Ausgangspunkt der Forschung.
Durch eine interaktive und ungerichtete Suche in den Daten
kann die Hypothesengenerierung mithilfe der Informationsvisualisierung unterstützt werden. Dazu muss eine
geeignete weit gefasste und nicht beschränkte Darstellung gefunden werden. Diese Informationsvisualisierungen
können Ausgangspunkt für folgende Analysen sein. Das Initialbeispiel in Abbildung \ref{fig:beispiel} kann
genutzt werden um eine weiterführende Forschungsfrage zu entwickeln: Warum wird die Farbe Rot überdurchschnittlich
oft mit positiven Begriffen assoziiert?
\item[Konfirmative Analyse]
Hier existieren bereits eine oder mehrere Hypothesen, die mithilfe der Informationsvisualisierung überprüft werden sollen.
Dabei wird eine Datenmenge hinsichtlich eines speziellen Aspekts untersucht und ausgewertet.
\item[Präsentation]
Ergebnisse aus der Analyse der Daten werden mithilfe der Informationsvisualisierung dargestellt, um sie für Dritte verständlich
zu machen und mit ihnen über den Sachverhalt kommunizieren zu können.
Dabei ist eine ansprechende und ästhetische Darstellung wichtig, denn
ein ansprechendes Erscheinungsbild verstärkt den Willen, sich mit einer Darstellung auseinanderzusetzen.
\end{description}

Um eine adäquate Informationsvisualisierung klassifizieren zu können, nennen \cite{Schumann} drei Eigenschaften:
Effektivität, Expressivität und Angemessenheit. Diese Eigenschaften müssen bei der Konzeption einer
Informationsvisualisierungssoftware beachtet werden.
\begin{description}
\item[Expressivität]
Die Informationsvisualisierung soll nur die in den Daten enthaltenen Informationen zeigen.
Diese sollen dabei möglichst unverfälscht wiedergeben werden, um falsche Schlussfolgerungen bei dem Betrachter zu vermeiden.
\item[Effektivität]
Die Darstellung muss zu den visuellen Fähigkeiten des Betrachters und den Eigenschaften des Ausgabegerätes
passen.
\item[Angemessenheit]
Ressourcen und Rechenaufwand und damit die Kosten einer Visualisierung sollen den Anforderungen entsprechen.
\end{description}
\cite{Bertin} beschreibt dagegen nur den Begriff der Prägnanz als Qualitätsmaß.
Prägnanz wird definiert:
\begin{quote}
"`Wenn eine Konstruktion zur Beantwortung einer gestellten Frage unter sonst gleichen Voraussetzungen eine
kürzere Betrachtungszeit erfordert als eine andere Konstruktion, so bezeichne man diese als prägnanter in
Bezug auf die gestellte Frage."'\footnote{\citep[S.\,17]{Bertin}}
\end{quote}
Darüber hinaus fällt es schwer, allgemeingültige Aussagen zu treffen, wie ein komplexer Sachverhalt und dessen
Informationen am effizientesten zu visualisieren sind. Die Informationsvisualisierung ist stark anwendungsabhängig und soll
immer den Anforderungen der Daten, der Zielgruppe, des Bearbeitungsziels, der Repräsentation und des Mediums entsprechen.
Eine rein automatisierte Informationsvisualisierung kann nur sehr schwer alle diese Anforderungen berücksichtigen. Daher
sollten die Benutzer in allen Stufen des Visualisierungsprozesses eingreifen und gegebenenfalls Anpassungen vornehmen können. Eine Software
muss dazu geeignete Mittel zur Verfügung stellen.

\section{Visualisierungsprozess}
\label{sec:Pipeline}
Der Prozess der Visualisierung wird Visualisierungspipeline genannt.\footnote{Vgl. \citep[S.\,15]{Schumann}}
Diese Pipeline beschreibt den Ablauf aller
Schritte, die notwendig sind, um abstrakte Daten in visuelle Variablen
zu transkribieren, um eine grafische Darstellung zu erzeugen. In der Literatur gibt es keine einheitliche
Beschreibung der Visualisierungspipeline, jedoch ähneln sich die Darstellungen stark.
Im Folgenden soll der Ablauf der Informationsvisualisierung
beschrieben werden. Von \cite{BenFry} wird der Prozess in einen
größeren Kontext eingeordnet. Dadurch eignet sich diese
Visualisierungspipeline besonders gut, um einen Überblick über alle Arbeitsschritte zu erhalten.\footnote{Vgl. \ref{fig:benfryprocess}}
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/benfryprocess.pdf}
\caption{Der Prozess des Computational Designs aus \cite[S.\,13]{BenFry}}
\label{fig:benfryprocess}
\end{figure}
Als Erstes werden Daten aus einer Datei oder einem Netzwerk
beschafft (acquire). Danach finden erste Analysen statt, um die Struktur der Daten zu kennen (parse).
Wichtige Informationen können beispielsweise Extremwerte oder Wertebereiche und andere Bereiche speziellen
Interesses sein.
Diese Bereiche werden herausgetrennt (filter), um auf ihnen Methoden der Datenanalyse anwenden zu können,
die für die weitere Verarbeitung notwendig sind (mine). Im nächsten Schritt werden dann geeignete
grafische Repräsentationen\footnote{Vgl. Abschnitt \ref{sec:grafischeSemiologie}} gefunden, um die Daten
darzustellen (represent).\footnote{\cite{Schumann} erweitern diesen Punkt durch das Rendering, welches die eigentliche Rasterung
und Darstellung auf dem Ausgabemedium durchführt.}
Dieser Schritt wird auch als \textit{Mapping} bezeichnet und ist eine
Daten-zu-Geometrie-Abbildung\footnote{Vgl. \citep[S.\,16]{Schumann}}, bei der
die abstrakten Daten auf visuelle Variablen übertragen werden.
Die grafische Darstellung wird dann iterativ durch die visuelle Analyse des Nutzers
verbessert, damit sie einfacher verständlich und ästhetisch ansprechend wird und die Bearbeitungsziele erfüllt (refine). Als letzter
Schritt werden Interaktionsmöglichkeiten ergänzt, um dem Nutzer die Kontrolle über die
Ausgabe, aber auch über vorher stattfindende Stufen des Prozesses, geben zu können (interact).

Der hier beschriebene Ablauf ist allen Visualisierungsprozessen immanent, muss aber nicht zwangsläufig
in der gegebenen Reihenfolge auftreten. Es gibt unterschiedliche Möglichkeiten, in die
Visualisierungspipeline einzugreifen und zwischen den einzelnen Stufen zu wechseln.\footnote{In
\citep{Schumann} Abschnitt 2.2 und 2.3 werden unterschiedliche Verfahren beschrieben.}
Das Ergebnis dieser Verfahren ist jedoch immer die grafische Darstellung.

\section{Grafische Darstellung}
\label{sec:Darstellungen}
\subsection{Begriff}
Die grafische Darstellung ist das Ergebnis der Informationsvisualisierung. Sie besteht
aus den in Abschnitt \ref{sec:grafischeSemiologie} genannten
visuellen Variablen.
Als allgemeinste Form der grafischen Darstellung beschreiben \cite{Schumann} das
Diagramm. Es "`ist eine graphische [sic] Repräsentation von Informationen mit Hilfe
graphischer Elemente."'\footnote{\citep[S.\,126]{Schumann}} \cite{Bertin} spricht dagegen
vom Begriff der "`grafischen Darstellung"' und grenzt diesen von
der bildhaften Darstellung\footnote{In \cite{Bertin} werden Fotos oder künstlerische Bilder explizit ausgeschlossen.}
ab, die nicht monosemiotisch\footnote{Vgl. Abschnitt \ref{sec:grafischeSemiologie}} ist.
Diese Klassifikation wird weiter in Diagramme, Netze
und Karten unterteilt. \cite{Schumann} weisen außerdem auf eine Doppeldeutigkeit
des deutschen Begriffes "`Diagramm"' hin, denn in der englischen Sprache gibt es "`diagram"' und "`chart"'.
Dort beschreibt "`diagram"' die Darstellung nicht-quantitativer Beziehungen, während "`chart"' für die
allgemeine Form der grafischen Darstellung steht.\footnote{\citep[S.\,126]{Schumann}}
In dieser Arbeit wird der Begriff der \textit{grafischen Darstellung} verwendet und schließt
damit alle möglichen Darstellungsformen der Informationsvisualisierung ein.

\subsection{Darstellungsformen}
\label{sec:Darstellungsformen}
\begin{table}
\centering
\begin{tabular}{|l|p{10cm}|}
\hline
\textbf{Technik} & \textbf{exemplarische Darstellungsformen}\\
\hline
einfach & Scatterplots (1), Histrogramme (2),Kreisdiagramme (3), Isolinien (4)\\
\hline
multiaxial & Kiviatgraph (5), parallele Koordinaten (6)\\
\hline
ikonenbasiert & Stick-Figure-Ikonen (7),Chernoff Ikonen (8), Data Jacks (9)\\
\hline
pixelbasiert (10) &
einfach, raumfüllende Kurven,Zwei-Schritte-Technik, Recursive-Pattern-Technik\\
\hline
hierarchisch & dimensional Stacking (11), World-within-Worlds (12),Cone-Trees (13), Baumdiagramm (15)\\
\hline
netzwerkbasiert & Venn-Diagramm (14), Treemaps (17), Bubble Tree (16), ArcTree (20)\\
\hline
geschichtet & Icicle Plots (19), Sunburst (18)\\
\hline
hybrid & Mischtechniken bestehend aus anderen Techniken\\
\hline
\end{tabular}
\caption{Techniken der Darstellung}
\label{tab:darstellungsformen}
\end{table}

Die grafische Darstellung hat verschiedene Darstellungsformen, die für unterschiedliche
Anwendungsfälle konzipiert wurden. Sie sind alle stark anwendungsabhängig. Es müssen viele
Anforderungen beachtet werden, um die effizienteste Technik der grafischen Darstellung zu
finden.\footnote{Vgl. Abschnitt \ref{sec:Ziele}}
Die folgende Auflistung von Darstellungsformen orientiert sich an den Darstellungsformen für
Multiparameterdaten von \cite{Schumann} und
wird ergänzt durch \cite{Preim} und eigene Beobachtungen. Aufgrund der Vielzahl an unterschiedlichen
Darstellungsformen kann die Tabelle \ref{tab:darstellungsformen} nur einen beispielhaften Überblick geben. Die
Nummern hinter den einzelnen Darstellungsformen verweisen auf die Darstellungen in 
Abbildung \ref{fig:formen}.\footnote{Ein Beispiel für die Recursive-Pattern-Technik
findet sich im Anhang in Abschnitt \ref{sec:temperatures}, da pixelbasierte
Techniken nur sehr schwer schematisch dargestellt werden können.}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/formen.pdf}
\caption{Verschiedene Darstellungsformen, eigene Darstellung}
\label{fig:formen}
\end{figure}

Für diese Arbeit sind vor allem die hybriden Techniken interessant, da diese versuchen,
einzelne Vorteile anderer Darstellungsformen zu verbinden, um neue Sichtweisen zu erforschen.
Damit solche Informationsvisualisierungstechniken gefunden werden können, müssen
Softwarelösungen Einschränkungen bei der grafischen Darstellung vermeiden.

\chapter{Konzeption}
\label{cha:Software}
\section{Allgemeine Betrachtungen}
\label{sec:AllgemeineBetrachtungen}
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/benfryprocess_marked.pdf}
\caption{Einordnung in den Prozess des Computational Designs nach \citep{BenFry}, eigene Darstellung}
\label{fig:benfryprocess_marked}
\end{figure}
Die Übertragung von symbolischen Informationen auf geometrische Informationen ist das grundlegende Prinzip der
Informationsvisualisierung. In der Fassung von \cite{BenFry} wird diese Transkription in den
Stufen \textit{present} und \textit{refine} durchgeführt. Die Software muss also dem Benutzer die Möglichkeit geben,
diese Arbeitsschritte durchführen zu können. In Abbildung \ref{fig:benfryprocess_marked} ist dieser weitere iterative Schritt
abgebildet. Ist der Benutzer mit der grafischen Darstellung nicht zufrieden, so kann er Parameter anpassen. Dieser Ablauf
kann beliebig oft wiederholt werden, bis ein zufriedenstellendes Ergebnis vorliegt.
Die hohe Anzahl der Beobachtungspunkte eines Datensatzes macht eine vom Nutzer manuell durchgeführte Transkription
sehr aufwändig und zeitintensiv. Eine Unterstützung des Benutzers durch eine Software ist daher sinnvoll.
Dabei darf der Nutzer in seinem kreativen Gestaltungsprozess nicht eingeschränkt werden.

Wie in Kapitel \ref{cha:Grundlagen} und \ref{cha:Informationsvisualisierung} gezeigt wurde, gibt es eine Vielzahl an
Datenklassen und grafischen Darstellungsformen. Weiterhin entstehen neue hybride Formen durch Mashups\footnote{"`Mashup (von
englisch "`to mash"' für vermischen) bezeichnet die Erstellung neuer Medieninhalte durch die nahtlose
(Re-)Kombination bereits bestehender Inhalte."'\citep{wiki_mashup}}.
Die Software muss möglichst daher universell sein, um flexibel viele unterschiedliche Anwendungsfälle
bearbeiten zu können. Dabei dürfen die Bearbeitunsziele aus Abschnitt \ref{sec:Ziele} nicht
vernachlässigt werden.

\section{Anforderungen}
\label{sec:Anforderungen}
Für die zu entwickelnde Software werden Anforderungen festgelegt, die
im Folgenden beschrieben werden. Neben speziellen Anforderungen, die aus
dem Bereich der Informationsvisualisierung stammen, werden noch weitere
Anforderungen an Benutzerführung und Performance gestellt.
\begin{description}
\item[Einfache Benutzerinteraktion]
Damit auch technisch unerfahrene Nutzer schnell und einfach Ergebnisse erzielen können, kann die Software
mit visueller Programmierung gesteuert werden. Für die Bedienung der Software mithilfe der visuellen
Programmierung, die in Abschnitt \ref{sec:visPro} genauer beschrieben wird,
reicht ein grundlegendes mathematisches Verständnis des Nutzers aus.
Weiterhin veranschaulicht sie den eigentlichen Anwendungsbreich der Software.
\item[Flexible Visualisierungsmöglichkeiten]
Um möglichst viele Darstellungsformen abbilden zu können, muss die 
Möglichkeit bestehen, alle visuellen Variablen\footnote{Vgl. Abschnitt
\ref{sec:grafischeSemiologie}} und damit alle Darstellungsformen\footnote{Vgl. Abschnitt
\ref{sec:Darstellungsformen}} reproduzieren zu können. Der Nutzer darf dabei
in seiner Arbeit nicht durch vorgefertigte Darstellungsformen
eingeschränkt werden.
\item[Flexible Ein- und Ausgabe]
Zur automatischen Dateneinspeisung in die Software sollen mehrere Möglichkeiten
bestehen, um in unterschiedliche Workflows eingebunden werden zu können.
Neben Dateiformaten wie XML, JSON und CSV ist eine Netzwerk- und
Datenbankanbindung sinnvoll. Als Ausgabeformate können gängige Bildformate
verwendet werden.
\item[Performanz]
Der Benutzer kann alle Verbindungen und Parameter zwischen Datenobjekten und ihrer
visuellen Repräsentation direkt beeinflussen. Für eine direkte visuelle Analyse
durch den Nutzer muss die Software die Möglichkeit bieten, sofort
nach Interaktion des Nutzers die Veränderungen darzustellen. Dafür wird eine
ausreichende Performanz benötigt, um störende Ladezeiten zu vermeiden.
\item[Erweiterbarkeit]
Durch unterschiedliche Anforderungen in den verschiedenen Arbeitsbereichen ist
es nötig, die Software selbst erweitern zu können. Dafür soll eine Skriptsprache
implementiert werden, die es erlaubt, zur Laufzeit neue Funktionen hinzuzufügen.
Außerdem besteht, durch die Kapselung aller Funktionen, die Möglichkeit, dass der
Benutzer eigene Module programmiert.
\item[Plattformunabhängigkeit]
Die Software soll auf den drei großen Plattformen Linux, Mac OS X und Microsoft Windows
lauffähig sein. Durch die Entwicklung auf Basis von openframeworks\footnote{Vgl. Abschnitt \ref{sec:Technologien}}
wird diese Plattformunabhängigkeit gewährleistet.
\item[Frei und offen]
Die Software wird unter einer freien Lizenz entwickelt und veröffentlicht,
um eigene Erweiterungen von Nutzern möglich zu machen. Durch die Wahl der Lizenz kann
die Entwicklung durch alle Interessenten vorangetrieben werden. Außerdem lässt
die Lizenz eine kommerzielle Erweiterung und Nutzung zu. Für private Anwender
ist die Software kostenlos verfügbar.
\end{description}

\section{Visuelle Programmierung}
\label{sec:visPro}
Um dem breiten Spektrum an Anforderungen gerecht zu werden,
wird die Software mit einer Form der visuellen Programmierung gesteuert.
\cite{Henning} definieren visuelle Programmierung wie folgt:
\begin{quote}
"`Es handelt sich hierbei um ein in integrierten Entwicklungsumgebungen mit
grafischer Benutzeroberfläche verwendetes Hilfsmittel, bei welchem grafisch
dargestellte Programmblöcke durch gerichtete und qualifizierte Linien miteinander
verlinkt werden."'\footnote{\citep[S.\,56]{Henning}}
\end{quote}
\begin{figure}
\centering
\lstinputlisting{code/grundrechenarten.txt}
\caption{Pseudocode für eine textuelle Programmierung aller Grundrechenarten.}
\label{fig:textuell}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/datasynth_basic.pdf}
\caption{Die Grundrechenarten umgesetzt mit visueller Programmierung.}
\label{fig:datasynth_basic}
\end{figure}
Im Gegensatz zur textuellen Programmierung, bei der Buchstaben, Zeichen und Wörter
verwendet werden, um einen Quellcode zu schreiben, wird die Programmlogik bei ber
visuellen Programmierung durch grafische Elemente erstellt.
Statt vorgefertigte Funktionsnamen und Aufrufe zu schreiben, werden einzelne grafische
Elemente mit unterschiedlichen Aufgaben erzeugt und diese untereinander verbunden. Die visuelle Programmierung
wird fast ausschließlich mit der Maus durchgeführt.
Als Beispiel wird in Abbildung \ref{fig:textuell} eine textuelle Programmierung mit
Pseudocode gezeigt, die zwei Variablen mit den vier Grundrechenarten verbindet.
In Abbildung \ref{fig:datasynth_basic} wird die gleiche Berechnung
in visueller Programmierung umgesetzt.

Für die Software werden einzelne Klassen definiert, die in ihrer Summe das Konzept der visuellen
Programmierung bilden. In der folgenden Auflistung werden die einzelnen
Elemente und ihre Funktionsweise beschrieben.
\begin{description}
\item[Node]
Ein Node ist ein Knoten in dem Funktionalität gekapselt ist. Vergleichbar ist dieses
Element mit einer Funktion oder Methode in der textuellen Programmierung. Ein Node kann also
beliebig viele Parameter zur Eingabe haben. Als Ausgabe sind mehrere unterschiedliche Werte möglich.
Ein Node kann zwischen der Eingabe und der Ausgabe unterschiedlichste Berechnungen durchführen.
Diese können unter anderem arithmetischer oder logischer Natur sein. Ein Node kann beispielsweise
Zahlen miteinander multiplizieren oder bei einem bestimmten Grenzwert von true nach false
umschalten.
Alle Berechnungen in einem Node werden unabhängig von allen anderen vorhandenen Nodes durchgeführt.
\item[Pin]
Ein Pin beschreibt die unterschiedlichen Ein- und Ausgabewerte eines Node.
Es wird dabei zwischen Input- und Output-Pins unterschieden. Über die unterschiedlichen
Input-Pins können verschiedene Werte übergeben werden, die für eine Berechnung in dem Node notwendig sind.
Diese werden von dem Node verarbeitet und die Ergebnisse dieser Berechnung
über die Output-Pins ausgegeben.
Vergleichbar sind die Input-Pins mit den Parametern einer Funktion in der textuellen Programmierung.
Die Output-Pins können als Rückgabewerte einer Funktion verstanden werden.
\item[Connection]
Eine Connection ist die Verbindung zwischen zwei Pins. Dabei wird vom Benutzer ein Output-Pin einer
Node mit dem Inputpin einer anderen Node verbunden. Nur durch diese Verbindung können
Nodes miteinander kommunizieren und Werte austauschen. Eine Connection
ist mit einer Zuweisung oder gegenseitigen Funktionsaufrufen in der textuellen Programmierung vergleichbar.
\item[Spread]
Ein Spread ist eine Struktur, die in der Software als universeller Datentyp funktioniert.\footnote{Der
Begriff Spread wurde aus der Software vvvv übernommen. Vgl. Abschnitt \ref{sec:bestehendeSoftware}}
Eingabe- und Ausgabewerte von Nodes können nur Spreads sein. Ein Spread ist eine 
eindimensionale Liste von Werten. Diese Werte können unterschiedliche primtive Datentypen,
wie beispielsweise Gleitkommazahlen oder Zeichenketten, beinhalten. Im einfachsten Fall hat
die Liste eines Spreads nur ein einziges Element und ist demzufolge eine einfache Variable. In komplexeren
Anwendungen kann ein Spread eine große Anzahl an Elementen enthalten, die beispielsweise
aus einer Datentabelle stammen. Somit kann der Benutzer eine Reihe von Zahlen mit
einer Konstante multiplizieren, ohne die Anzahl der einzelnen Werte eines Spreads
beachten zu müssen. Die Software ist in der Lage, auch Spreads mit einer unterschiedlichen
Anzahl von Elementen miteinander zu verrechnen.
\end{description}

Der Einsatz von visueller Programmierung als Bedienkonzept hat
mehrere Vorteile. Das Verbinden von Nodes, die als Datenquelle funktionieren, mit Nodes, die
die visuellen Variablen repräsentieren, spiegelt das grundlegende
Prinzip der Informationsvisualisierung in der Benutzeroberfläche wieder. Für den Benutzer ist
es dadurch verständlicher welche Aufgabe die Software hat und wie mit ihr Probleme gelöst
werden können.
Mit der gewählten Benutzeroberfläche sind keine Programmierkenntnisse erforderlich, um eine Informationsvisualisierung
zu erstellen. Ein durchschnittliches mathematisches Verständnis des Benutzers reicht für einfache Aufgaben aus.
Das macht ein iteratives Experimentieren möglich. Der Benutzer kann die Software nutzen, um eine
Idee für die Informationsvisualisierung unkompliziert zu skizzieren.
Die komplexen internen Abläufe liegen dabei hinter einem intuitiven und einfachen Interface
verborgen. Dadurch können "`context switches"'\footnote{Vgl. \citep[S.\,50]{Tufte}}
vermieden werden. Diese treten auf, wenn der Benutzer zwischen unterschiedlichen Programmansichten wechseln
muss. Stattdessen wird der Bereich für die Benutzerinteraktion und die Ausgabe
immer gleichzeitig angezeigt. Der Nutzer erkennt dadurch sofort, welchen Einfluss seine Benutzereingaben bewirken. Er
kann diese vergleichen und anpassen um schnell zum gewünschten Ergebnis zu kommen.
In Abbildung \ref{fig:datasynth} wird dieses Prinzip an einem Beispiel dargestellt.
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/datasynth.pdf}
\caption{Ein Beispiel für eine Benutzeroberfläche der visuellen Programmierung. Zwischen der oberen Reihe
und der unteren Reihe von Fenstern hat eine Benutzerinteraktion stattgefunden.
Im oberen rechten Fenster wird ein Kreis gezeichnet. Dieser hat einen Radius von 20 Pixel, da
die rechte obere Node im linken Fenster einen Wert von 20 Pixel an den Pin für den Radius des Kreises übergibt.
In der unteren Reihe wurde der Wert auf 125 geändert. Dadurch verändert sich
auch die Darstellung unmittelbar, da der Radius des Kreises mit dem Wert dieser Node verbunden ist. Die Position
des Kreises ist in beiden Darstellungen bei 150 Pixel in der Höhe und Breite, da der obere linke Node den Wert 150 hat und mit
zwei Verbindungen die x- und y-Position des Kreises beschreibt.}
\label{fig:datasynth}
\end{figure}

\section{Prozesskette}
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/prozesskette.pdf}
\caption{Schematische Prozesskette der Software}
\label{fig:prozesskette}
\end{figure}
In der Prozesskette wird der generische Arbeitsablauf für die Benutzung
der Software beschrieben. Dieser ist unabhängig von den zu verarbeitenden Daten
und den gewählten Darstellungsformen. Die Prozesskette ist in vier
Arbeitsschritte unterteilt, die nacheinander abgearbeitet werden müssen,
um eine grafische Darstellung zu erzeugen.
Die einzelnen Schritte der Prozesskette werden in Abbildung \ref{fig:prozesskette} dargestellt und im
Folgenden beschrieben.
\subsection{Importieren von Datenquellen}
Der Benutzer erzeugt einen Node, der es möglich macht externe Datenquellen
in die Software zu laden. Unterschiedliche Nodes machen es möglich Datenquellen auf
dem Computer oder im Netzwerk importieren zu können. Dabei werden etablierte
Dateiformate wie XML, CSV, JSON und netCDF unterstützt. Wenn der Benutzer eine 
Datenquelle ausgewählt hat, erhält der Node automatisch Output-Pins.
Diese repäsentieren die ursprüngliche Datenstruktur der Datenquelle.
Die Datenquelle für das Beispiel aus Abbildung \ref{fig:beispiel} kann eine Tabelle sein,
bei der in der ersten Spalte alle Begriffe stehen und jede weitere Spalte die Farben
eines jeden Kulturkreises beschreibt. Bei zehn Kulturkreisen hat die Tabelle
elf Spalten und der Node besitzt dadurch elf Output-Pins. Die Spreads, die durch
die Output-Pins ausgegeben werden, können unterschiedlich
weiterverarbeitet werden.
Die Erzeugung mehrerer unterschiedlicher Nodes für die Einbindung von Daten macht ein
\textit{Mashup} unterschiedlicher Datenquellen möglich.
\subsection{Festlegung der visuellen Variablen}
Der Benutzer hat die Möglichkeit weitere Nodes anzulegen, die die visuellen
Variablen darstellen. Diese können unabhängig voneinander erzeugt und mit einem datengebenden
Node verbunden werden. Sie erzeugen beispielsweise grafische Formen wie Kreise oder Rechecke,
die in ihrer zum Beispiel in ihrer Position, Farbe und Richtung beeinflusst werden können.
Der Benutzer hat die Möglichkeit zwischen datengebenden Nodes und
Nodes, die eine grafische Ausgabe erzeugen, weitere Nodes einzufügen, um diese Verbindungen
parametrisieren zu können. Das macht unterschiedlichste Darstellunsgformen möglich.
Um das Beispiel aus Abbildung \ref{fig:beispiel} zu realisieren, muss der Benutzer einen
Node erzeugen, der Rechtecke zeichnet. Dieser Node hat Input-Pins um die Position
in der Ebene, die Größe, die Rotation und die Farbe festlegen zu können. Der Benutzer
verbindet dann die Output-Pins des datengebenden Nodes mit den Input-Pins dieser Node
und erzeugt damit eine grafische Darstellung der Daten.
\subsection{Evaluation der grafischen Darstellung}
Um die aktuelle grafische Darstellung überprüfen zu können, kann der Benutzer Nodes
erzeugen, die eine Vorschau ermöglichen. Ein Render-Node erzeugt ein weiteres
Fenster und zeigt die Ausgabe, die von den vorhandenen Nodes erzeugt wird, an.
Bei jeder Interaktion des Benutzers, die Parameter einzelner Nodes ändert,
wird automatisch und unmittelbar die aktuelle Ausgabe verändert.
Der Benutzer kann visuell analysieren, welche Verbindungen noch nötig sind
oder welche zusätzlichen Parameter einzelne Verbindungen noch benötigen, um eine sinnvolle grafische 
Darstellung zu erzeugen. Ist das Beispiel aus Abbildung \ref{fig:beispiel} mit den vorangegangen Schritten noch nicht
zufriedenstellend visualisiert, kann der Benutzer weitere Nodes und Connections
hinzufügen. So kann beispielsweise eine zusätzlicher Multiplikator-Node und ein
Variable-Node genutzt werden, um die Position aller Rechtecke anpassen zu können.
\subsection{Export der grafischen Darstellung}
Ist der Benutzer zufrieden mit der grafischen Darstellung, kann er weitere Nodes
erzeugen, die diese exportieren. Zur Speicherung von grafischen Darstellungen
eignen sich bekannte Bildformate wie JPEG, PNG, BMP oder TIFF. Eine Node, die andere Formate
für die Weiterverarbeitung unterstützt ist denkbar. Weitere Exportmöglichkeiten
sind Vektorgrafiken, 3D-Austauschformate oder interaktive HTML Seiten.

\section{Bestehende Softwarelösungen}
\label{sec:bestehendeSoftware}
Durch das weite Arbeitsfeld der Informationsvisualisierung, das meist
fließend in andere Bereiche übergeht, existiert eine große Anzahl an
Softwarelösungen und Programmierbibliotheken. Hier sollen exemplarisch
einzelne Anwendungen beschrieben werden, die verschiedene geforderte
Funktionen enthalten, diese aber nicht in einem Softwarepaket, das
speziell auf die Informationsvisualisierung zugeschnitten ist, zusammenfassen.
Eine Liste aller betrachteten Programme findet sich im Anhang in Abschnitt
\ref{sec:Softwareliste}.
\begin{description}
\item[vvvv]
ist eine datenstromorientierte Enticklungsumgebung, die universell eingesetzt werden kann.
Mit ihr können unterschiedlichste audiovisuelle Medien gekoppelt und
verarbeitet werden. vvvv wird durch visuelle Programmierung gesteuert, ist aber
nicht spezialisiert auf Informationsvisualisierung und nicht für alle
Plattformen verfügbar.
\item[MeVisLab]
ist eine Software aus dem medizinischen Bereich, die durch visuelle
Programmierung bedient werden kann. MeVisLab ist eine fortgeschrittene
IDE\footnote{Integrated Development Environment} mit verschiedenen
Erweiterungsmöglichkeiten, ist aber spezialisiert auf die medizinische
Bildverarbeitung.
\item[d3.js]
ist eine Bibliothek, die Teile einer HTML-Seite mit Daten verbinden kann.
Sie ist in Javascript geschrieben und beschränkt sich auf
Webanwendungen. Der Nutzer muss Javascript programmieren können, um diese
Bibliothek nutzen zu können.
\item[NodeBox 2 Beta]
ist ein Programm, um generative Grafiken zu erstellen. Es entspricht nahezu
allen beschriebenen Anforderungen. Für komplexere Aufgaben muss aber
die Programmiersprache Python erlernt werden. Auch die Anbindung von unterschiedlichen Datenquellen
ist nicht gegeben.
\end{description}

\chapter{Prototypische Realisierung}
\label{cha:Umsetzung}
In diesem Kapitel wird die in Kapitel \ref{cha:Software} beschriebene Konzeption prototypisch implementiert.
Dieser Prototyp trägt den Namen \textit{Datasynth}.
Aufgrund der begrenzten Arbeitszeit werden nur grundlegende Funktionen umgesetzt,
die notwendig sind, um das Prinzip der Software zu verdeutlichen.

\section{Technologien}
\label{sec:Technologien}
Um Datasynth zu entwickeln, werden verschiedene Technologien verwendet.
Im Folgenden wird ihr Einsatz bei der Entwicklung beschrieben.
\begin{description}
\item[C++]
ist eine objektorientierte Programmiersprache. Sie bietet
eine maschinennahe Möglichkeit, effiziente Programme zu entwickeln.
Datasynth nutzt durch openFrameworks und boost einige Vorteile
von C++. Dazu gehören eine höhere Geschwindigkeit beim Ausführen
und eine einfache Einbindung anderer Bibliotheken, wie 
beispielsweise OpenGL für Grafikoperationen. Außerdem
findet das Programmierparadigma der Objektorientierung
in den einzelnen Nodes von Datasynth Anwendung.
\item[openFrameworks]
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/of.pdf}
\caption{Funktionsweise von openFrameworks aus \citep{of_wiki}}
\label{fig:of}
\end{figure}
ist ein in C++ geschriebenes Framework. Es soll durch seine
Einfachheit und Intuitivität den kreativen Prozess und das
Experimentieren beim Programmieren unterstützen. openFrameworks
verbindet viele unterschiedliche Bibliotheken für die
computergestützte audio-visuelle Verarbeitung zu einer gemeinsamen,
konsistenten und einfachen Programmierschnittstelle. Beispielsweise
wird die Bibliothek openGL für Grafiken verwendet und die
Bibliothek FreeImage für das Importieren, Bearbeiten und Exportieren von Bilddateien.
openFrameworks erlaubt dem Programmierer eine schnelle und effiziente Arbeitsweise ohne
lange Einarbeitungszeiten und ist daher für die Implementation von Datasynth optimal geeignet.
Die Programmierschnittstelle von openFrameworks enthält
wenige Klassen mit wenigen Funktionen, um überschaubar zu bleiben.\footnote{Vgl. \citep{of1} und \citep{of2}}
Für spezielle Anforderungen kann auf die Befehle der zugrundeliegenden Bibliotheken
zurückgegriffen werden.
openFrameworks ist kompatibel zu den Plattformen
Linux, Mac OS X und Microsoft Windows.
Die Funktionsweise von openFrameworks wird in Abbildung
\ref{fig:of} verdeutlicht. 
Die Programmlogik, das Benutzerinterface und alle Ein- und
Ausgaben für den Benutzer wurden für Datasynth mit openFrameworks
realisiert.
\item[boost]
ist eine Sammlung von unterschiedlichen C++ Programmierbibliotheken.
Diese Bibliotheken sind portabel einsetzbar und steigern die
Produktivität bei der Entwicklung einer Software, da sie unterschiedliche
Anwendungsbereiche von C++ erweitern und vereinfachen.
Einzelne Bibliotheken der Sammlung wurden in den neuen C++ Standard
übernommen, um C++ selbst zu verbessern.
Für Datasynth werden die Bibliotheken für Zeiger, Container
und generische Programmierung verwendet, um die Entwicklung weiter zu vereinfachen.
\item[GitHub]
ist eine Internetplattform für das kollaborative Entwickeln einer Software.
Sie basiert auf dem Versionverwaltungstool git, welches entwickelt wurde,
um Änderungen an Quellcode aufzuzeichnen und diesen zwischen mehreren
Entwicklern teilen zu können. GitHub verbindet die Funktionalität von git mit
einem sozialen Netzwerk, bei der verschiedene Nutzer gemeinsam
an einer Software arbeiten können. Die Entwicklung von Datasynth kann online 
verfolgt werden.\footnote{Vgl. http://www.github.com/benben/datasynth}
\end{description}

\section{Wichtige Kernfunktionen}
\label{sec:Kernfunktionen}
In diesem Kapitel werden exemplarisch wichtige Abschnitte der Software anhand ihres Quelltextes
erläutert.
In Abbildung \ref{fig:factory} wird eine Struktur dargestellt, die die einzelnen
Nodes zur Laufzeit erstellt. In dieser Struktur ist eine Liste gespeichert, die Wertepaare
enthält. Ein Wertepaar besteht aus dem Namen eines Node als Zeichenkette und einer Funktion
zum Anlegen dieses Node.
Wenn der Benutzer einen Node erstellen will und im Menü auf einen entsprechenden Eintrag geklickt hat,
wird eine Zeichenkette übergeben. Wenn die Liste der Struktur eine solche Zeichenkette enthält, wird der
entsprechende Node erzeugt. So können vom Benutzer dynamisch zur Laufzeit
neue Nodes erzeugt werden. Die Struktur dient schließlich als eine Art Katalog, in dem alle
Nodes enthalten sind, die der Nutzer zur visuellen Programmierung verwenden kann.
\begin{figure}
\centering
\lstinputlisting[language=C++]{code/factory.cpp}
\caption{Erzeugung eines Node-Objektes aus einer Liste aller vorhandenen Nodes}
\label{fig:factory}
\end{figure}
In Abbildung \ref{fig:node} wird in Auszügen die Klassendefinition des BaseNode und
des Node für die Addition zweier Gleitkommazahlen als Beispiel dargestellt.
Ein Node ist eine einfache C++ Klasse, die alle Eigenschaften der Klasse BaseNode erbt.
Der Node für die Addition zweier Gleitkommazahlen überschreibt die process Methode der BaseNode, um die zwei
Inputpins zu addieren. Andere Klassen die von dem BaseNode erben, können die process
Methode mit ihrer eigenen Funktionalität überschreiben.
Das macht es möglich, alle Funktionen, die in einer C++ Methode implementiert werden können,
in einer Klasse als Node zu kapseln und für die visuelle Programmierung von Datasynth zu verwenden.
\begin{figure}
\centering
\lstinputlisting[language=C++]{code/node.cpp}
\caption{Klassendefinition der BaseNode und der Node für die Addition als Beispiel}
\label{fig:node}
\end{figure}
In Abbildung \ref{fig:core} werden einzelne Ausschnitte aus dem Hauptprogramm gezeigt.
In diesem Teil von Datasynth läuft die Hauptschleife ab, die alle Benutzereingaben behandelt,
das Aktualisieren und Berechnen aller Nodes durchführt und Nodes und Connections
hinzufügt oder löscht.
\begin{figure}
\centering
\lstinputlisting[language=C++]{code/core.cpp}
\caption{Erzeugung von Objekten einer Klasse bestimmt durch eine Zeichenkette.}
\label{fig:core}
\end{figure}

\section{Implementierte Funktionen}
\label{sec:ImplementierteNodes}
\begin{table}
\centering
\begin{tabular}{|l|p{10cm}|}
\hline
\textbf{Node} & \textbf{Funktion}\\
\hline
Add & Addiert zwei Spreads miteinander und gibt ein Spread als Summe dieser zurück.\\
\hline
Substract & Zieht vom Spread der am ersten Input-Pin anliegt, den Spread vom zweiten Input-Pin ab und gibt die Differenz als Spread aus.\\
\hline
Multiply & Multipliziert zwei Spreads und gibt das Produkt als Spread aus.\\
\hline
Divide & Teilt den Spread am ersten Input-Pin durch den Spread der am zweiten Input-Pin anliegt und gibt das Ergebnis als Spread aus.\\
\hline
Variable & Diesem Node kann der Benutzer einen skalaren Wert zuweisen. Damit wird am Output-Pin ein Spread mit einer einzigen
Variable erzeugt. Diese kann genutzt werden, um Berechnungen mit anderen Spreads durchzuführen.\\
\hline
CSVParser & Mit diesem Node hat der Benutzer die Möglichkeit, eine CSV-Datei zu importieren.
Die "`Spalten"' der Daten wird dabei als Spreads über die Output-Pins ausgegeben.\\
\hline
RGBColor & Erzeugt aus drei Input-Pins für die Farbkanäle Rot, Grün und Blau einen Spread mit Farbwerten. Dieser
kann von anderen Nodes benutzt werden, um ausgegebene grafische Elemente einzufärben.\\
\hline
Line & Dieser Node zeichnet eine Linie. Der Node hat fünf Input-Pins, die Anfangskoordinaten, Endkoordinaten und Farbe
der Linie bestimmen.\\
\hline
Circle & Dieser Node zeichnet einen Kreis. Der Kreis ist bestimmt durch Koordinaten, Radius und Farbe. Der Node
hat dafür drei Input-Pins.\\
\hline
Render & Dieser Node erzeugt ein weiteres Fenster, in dem der Benutzer die aktuelle Ausgabe überprüfen kann.
Wenn er mit der aktuellen Ausgabe zufrieden ist, kann er durch Tastendruck den Render-Node veranlassen, ein
hochauflösende Bilddatei zu erstellen.\\
\hline
\end{tabular}
\caption{Exemplarische Auflistung implementierter Nodes}
\label{tab:nodes}
\end{table}
In Tabelle \ref{tab:nodes} werden implementierte Nodes exemplarisch aufgeführt und ihre Funktion beschrieben.
Diese Nodes reichen bereits aus, um einfache Visualisierungen durchzuführen. Eine vollständige Liste aller
für Datasynth implementierten Nodes findet sich im Anhang in Abschnitt \ref{sec:alleNodes}.

\begin{table}
\centering
\begin{tabular}{|l|p{9cm}|}
\hline
\textbf{grafische Variable} & \textbf{Umsetzung mit Datasynth}\\
\hline
Position in der Ebene & Jeder Node hat Input-Pins für die x- und y-Koordinaten der darzustellenden grafischen Primitive wie
beispielsweise Kreise und Rechtecke.\\
\hline
Größe & Nodes haben die Möglichkeit, die Größe der auszugebenden Elemente anzupassen.
So kann beispielsweise bei der Verwendung des Circle-Node der Radius frei gewählt werden.\\
\hline
Helligkeitswert & Nodes haben die Möglichkeit eine Farbe anzunehmen. Durch die Farbe kann
auch der Helligkeitswert festgelegt werden.\\
\hline
Textur & Textur ist nicht implementiert.\\
\hline
Farbe & Es gibt Nodes, die aus drei Eingangswerten eine Farbe im RGB- oder HSV-Farbraum erzeugen. Mit diesen Nodes kann die Farbgebung
anderer Nodes beeinflusst werden.\\
\hline
Richtung & Objektrotation ist nicht implementiert.\\
\hline
Form & Es existieren unterschiedliche Nodes für unterschiedliche Formen, zum Beispiel Kreis, Rechteck, Punkt und Linie. Diese Nodes
können kombiniert werden, um komplexe Formen zu realisieren.\\
\hline
\end{tabular}
\caption{Visuelle Variablen und ihre Umsetzung in Datasynth}
\label{tab:vars}
\end{table}
Die Tabelle \ref{tab:vars} zeigt, wie die grafischen Variablen aus Abschnitt
\ref{sec:grafischeSemiologie} in Datasynth umgesetzt wurden. In dieser Tabelle werden ausschließlich
Nodes beschrieben, die eine Ausgabe erzeugen. Die visuellen Variablen Textur und Rotation
wurden aufgrund der begrenzten Bearbeitungszeit nicht implementiert.

\section{Beispielanwendung}
\label{sec:Beispielanwendung}
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/tabelle.pdf}
\caption{Ausgangsdaten in Tabellenform}
\label{fig:apitabelle}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/ausschnitt.pdf}
\caption{Ausschnitte aus der Benutzeroberfläche.
Oben links: CSVParser-Node importiert die Daten aus einer CSV-Datei.
Unten links: verschiedene Nodes zur Berechnung.
Oben rechts: Circle-Node erzeugt Kreise an den gegebenen Positionen.
Unten rechts: Render-Node erzeugt eine Ausgabe.}
\label{fig:guiausschnitt}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=\linewidth]{images/ausschnitt2.pdf}
\caption{Ausschnitt aus der grafischen Darstellung}
\label{fig:companyausschnitt}
\end{figure}
In diesem Kapitel wird mit Datasynth eine Informationsvisualisierung durchgeführt.
Die Ausgangsdaten aus Abbildung \ref{fig:apitabelle} wurden aus dem API.Leipzig Projekt\footnote{Vgl.
http://www.apileipzig.de/} gewonnen und in Tabellenform aufbereitet. Diese Tabelle wurde
als CSV-Datei exportiert.
In Abbildung \ref{fig:guiausschnitt} werden Ausschnitte aus der Benutzeroberfläche von
Datasynth gezeigt. Diese zeigen exemplarisch Nodes, die für die Informationsvisualisierung
benutzt werden. Zuerst wird die CSV-Datei mithilfe eines CSVParser-Node importiert. Danach
werden unterschiedliche Berechnungen durchgeführt um die Ausgabe des Circle-Nodes zu beeinflussen.
Ein Render-Node erzeugt die Ausgabe und ermöglicht eine Exportfunktion.
Eine komplette übersicht über die Benutzeroberfläche für diese Anwendung findet sich im Anhang
in Abschnitt \ref{sec:gui}.
In Abbildung \ref{fig:companyausschnitt} wird ein Ausschnitt aus der fertigen grafischen
Darstellung gezeigt. Die komplette Darstellung findet sich im Anhang in Abschnitt \ref{sec:companyclash}.

\section{Probleme}
\label{sec:Probleme}
Während der Realisierung von Datasynth traten einige Probleme auf, die im Folgenden
erläutert werden.

Da C++ eine sehr maschinennahe Sprache ist und auf Performance optimiert ist,
ist es schwierig Reflections und Introspections durchzuführen.
Es können während der Laufzeit keine Informationen
über die Beschaffenheit einer Klasse abgefragt werden.
Das können zum Beispiel die Ausgabe aller vorhandenen Methoden und Instanzvariablen eines Objektes sein.
Auch Eigenschaften einer Klasse können nicht dynamisch verändert werden. Beispielsweise
ist es nicht möglich, die process Methode einer Node zur Laufzeit zu überschreiben.
Um trotzdem flexibel Nodes zur Laufzeit erzeugen zu können, erben alle Nodes
von einer universellen Elternklasse. In einem Container werden dann ausschließlich Zeiger
auf die Objekte vom Typ der Elternklasse gespeichert. An den Speicherstellen
liegen dann die eigentlichen Objekte einer Node-Klasse. Das Hauptprogramm kann
über alle Elemente des Containers iterieren und somit alle vom Benutzer erzeugten
Nodes aufrufen.

Universelle Datentypcontainer sind in C++ nicht standardmäßig vorhanden.\footnote{Nullzeiger sind
möglich, erfordern aber eine unsichere und unflexbile Wiederherstellung des ursprünglichen Datentyps.} Um die Verbindungen
zwischen den einzelnen Nodes datentypagnostisch zu halten, wurde ein
eigener Datentyp Spread definiert.\footnote{Eine Definition des Spreads erfolgte im Abschnitt \ref{sec:visPro}}
Durch die Abstraktion in einen boost::variant Container ergibt sich eine einheitliche Möglichkeit, primitive Datentypen,
wie beispielsweise Gleitkommazahlen und Zeichenketten abzuspeichern. Vor der Verwendung in einer Node werden diese
Datentypen mit boost::get rekonstruiert. Der Vorteil gegenüber Nullzeigern ist, dass bei fehlgeschlagener
Wiederherstellung eine Fehlerbehandlung möglich ist.

openFrameworks unterstützt nicht das Erstellen und Verwenden mehrerer
unabhängiger Fenster. Deshalb musste
auf ein Add-on zurückgegriffen werden, welches die Fensterverwaltung
mit einem alternativen System austauscht.\footnote{openFrameworks verwendet standardmäßig GLUT
zur Fensterverwaltung. Das benutzte ofxFenster Add-on benutzt dagegen die neuere und
flexiblere Bibliothek GHOST aus dem Blender-Projekt.} Damit können auch nach dem Start des Programms
neue Fenster erzeugt werden, was beispielsweise für die Funktionalität des Render-Node wichtig ist.

\chapter{Evaluation}
\label{cha:Auswertung}
In diesem Kapitel wird Datasynth anhand der in Abschnitt \ref{sec:Anforderungen}
aufgestellten Anforderungen bewertet.

Durch die Bedienung von Datasynth mit visueller Programmierung muss keine
textuelle Programmiersprache erlernt werden. Stattdessen kann der Nutzer intuitiv
grafische Elemente auf der Oberfläche erzeugen und durch Verbindungen
eine Programmlogik erstellen. Das Ergebnis einer Berechnung oder die Ausgabe von
Grafiken erfolgt dabei unmittelbar in einem seperaten Fenster. Dort kann der Nutzer
ohne einen Zwischenschritt, wie beispielsweise Kompilierung oder Ausführung,
die grafische Darstellung sofort überprüfen und gegebenenfalls anpassen. Dadurch wird eine
\textit{einfachen Benutzerinteraktion} ermöglicht.

In Abschnitt \ref{sec:ImplementierteNodes} wurden Nodes aufgelistet,
die für die prototypische Realisierung entstanden sind. Damit können erste Informationsvisualisierungen\footnote{Vgl. Abschnitt
\ref{sec:temperatures} und \ref{sec:companyclash} im Anhang} durchgeführt werden.
Aufgrund der begrenzten Bearbeitungszeit konnten zwei visuelle
Variablen nicht implementiert werden. Der sehr komplexe Node für die Texturierung
und die Funktion der Rotation wurden nicht umgesetzt. Die fehlende Funktionalität kann aber
durch den modularen Aufbau von Datasynth nachträglich hinzugefügt werden.

Für die \textit{flexible Ein- und Ausgabe} wurde jeweils eine Möglichkeit implementiert, um die komplette
Prozesskette von Datasynth zu implementieren. Es existiert ein Node, der eine
CSV-Datei einliest und entsprechend der Anzahl der vorhanden
Spalten automatisch Output-Pins erzeugt, an denen die einzelnen Spalten als
Spreads ausgegeben werden. Für die Ausgabe als Bild existiert ein Render-Node.
Dieser erzeugt ein Ausgabefenster in variabler Größe und kann per Tastendruck
hochauflösende Bilddateien im PNG-Format exportieren.

Die \textit{Performanz} von Datasynth war bei allen durchgeführten Tests sehr gut. Das Grundsystem wurde so
programmiert, dass Nodes intern nur eine Berechnung durchführen, wenn die Werte
an den Input-Pins verändert werden. Somit werden komplexe Rechenaufgaben nur
durchgeführt, wenn der Nutzer Parameter anpasst. Die grafische Ausgabe
des Render-Node erfordert den größten Rechenaufwand, da die Ausgabe kontinuierlich
gezeichnet wird. Dieser Aufwand kann durch entsprechende Steuerung
reduziert werden.

Alle Nodes sind einfache C++ Klassen, die von einer Elternklasse
alle Variablen und Methoden erben, die für die Verwendung in Datasynth
nötig sind. Somit ist eine hohe \textit{Erweiterbarkeit} gegeben, da es möglich ist,
nahezu jede Funktionalität, die in einer C++ Klasse implementiert werden kann, auch
als Node in Datasynth benutzbar zu machen.

Durch die Verwendung von openFrameworks und boost als Basis der Entwicklung
ist es möglich, Datasynth auf allen Plattformen auszuführen, die von openFrameworks
unterstützt werden. Das sind Linux, Mac OS X, Microsoft Windows.
Dadurch ist Datasynth \textit{plattformunabhängig} einsetzbar.

Datasynth wird öffentlich auf der Plattform GitHub entwickelt.\footnote{Vgl.
Abschnitt \ref{sec:Technologien}} Als Lizenz wurde die MIT-Lizenz gewählt.
Diese ermöglicht jedem Benutzer eine offene, aber auch kommerzielle Weiterentwicklung.

Datasynth kann nahezu alle Anforderungen erfüllen. Im Anhang in Abschnitt
\ref{sec:companyclash} befindet sich eine Informationsvisualisierung, die mit
Datasynth realisiert wurde.

\chapter{Zusammenfassung}
\label{cha:Zusammenfassung}
\section{Fazit}
\label{sec:Fazit}
Die Konzeption und prototypische Realisierung einer Software für die
Informationsvisualisierung hat gezeigt, dass es sinnvoll ist,
ein auf dieses Gebiet zugeschnittenes Softwarekonzept zu entwickeln.

Die Anforderungen an eine Informationsvisualisierung sind stark
Anwendungdsabhängig und müssen die Struktur der zugrundeliegenden
Daten mit den Visuellen Variablen als System der Darstellung
in einklang bringen.


Durch die Vielzahl an unterschiedlichen Datenformen und grafischen
Darstellungen ist es sinnvoll ein universelles Node-System zu implementieren,
welches auf neue Anforderungen reagieren kann, indem einfach neue Nodes
implementiert und hinzugefügt werden, der kern der software kann dabei
unangetastet bleiben. diese möglichkeit kann dabei von allen
anwendern whrgenommen werden.

Die Steuerung der Software durch visuelle Programmierung gibt dem benutzer
die intuitive möglichkeitintuitiv ästhetisch ansprechende darstellungen
anzufertigen

die automatisierung des mapping prozesses ist möglich und sinnvoll.

eine grafische darstellung die vom umfang her dem initialbeispiel
aus abbildung \ref{fig:beispiel} entspricht ist möglich. die software
übernimmt den arbeitnur bei den

details für die beschriftung, skalen muss noch gearbeitet werden.

trotzdessen ist datasynth noch nicht bereit für den produktiven einsatz.
aufgrund der begrenzten bearbeitungszeit wurde nur eine einfache 
benutzeroberflächje implementiert. die benutzerführung sollte daher als
erstes verbessert werden
Die Einarbeitungszeit kann damit stark reduziert werden.

auch wenn datasynth noch kein fertiges produkt ist, kann es zum
besseren verständnis der immer wichtiger werdenden digitalen welt 
beitragen und bietet eine möglichkeit der wachsenden menge an
daten handhabbar zu machen.

datasynth vermeidet es grenzen oder vorgaben bei der gestaltung von
grafischen darstellungen zu machen aber dadurch behält der Benutzer alle Freiheiten bei der Gestaltung.
das fordert aber auch die Kenntnis und Anwendung der Grundregeln für die grafische Darstellungen und
allgemeine Gestaltungsregeln, da es keine Möglichkeit gibt Nutzer auf sowas hinzuweisen.
So muss der Benutzer selbst entscheiden, welche visuellen Variablen sich wie 
gut für eine bestimmte Aufgabe eignen. Ein geeignetes System zu finden, das dem
Benutzer Hilfestellungen zu dieser Thematik gibt, muss noch erforscht werden.

Werden aber die anfänglichen Probleme von Datasynth beseitigt und damit alle gestellten Anforderungen erfüllt, kann
diese zu einer erhöhten Produktiviät und einem vereinfachten Umgang mit
Daten genutzt werden. Davon profitieren vor allem unerfahrene Gelegenheitsanwender,
die die Informationsvisualisierung als Werkzeug für ihre jeweiligen Arbeitsfelder
einsetzen. Aber auch Experten erhalten damit eine einfache und schnelle Möglichkeit
erste Erkundungen der Datenmenge durchzuführen. Nicht zuletzt kann es Künstlern
die Möglichkeit geben, auf Basis von Daten ästhetisch ansprechende
Informationsvisualisierungen zu erschaffen. All das kann zum besseren
Verstehen und Verständnis der heutigen technisierten Welt beitragen.

\section{Ausblick}
\label{sec:Ausblick}
Da Datasynth einen Prototypen darstellt, ergeben sich vielfältige
Ansätze für Weiterentwicklungen. Einige Möglichkeiten bedingen weiterer 
Forschungsarbeit und können als Thesen betrachtet werden. Im Folgenden
werden vielversprechende Ansätze beschrieben.
\begin{description}
\item[Skriptsprache]
Es können universelle Nodes geschaffen werden, die vom Benutzer selbst mit einer höheren
Skriptsprache programmiert werden können. Fehlende Funktionalitäten
können damit vom Benutzer selbst implementiert werden.
Auch die Anwendung einer Skriptsprache in der eigentlichen Software ist von Vorteil, um die in
Abschnitt \ref{sec:Probleme} genannten Probleme zu umgehen. Dabei sollte nur
die rechenintensive Programmlogik in C++ weiterentwickelt werden.
\item[Gruppierung von Nodes]
Um schnell und effizient komplexe grafische Darstellungen generieren zu können,
ist eine Gruppierung von Nodes sinnvoll. Damit können Templates erzeugt werden,
die eine grafische Darstellungsform in einem Node kapseln. So sind einzelne Nodes
für Tortendiagramme oder Netzwerkstrukturen denkbar.
\item[Weitere Ausgabemöglichkeiten]
Zusätzlich zu der Ausgabe als statische Bilddatei sind weitere Ausgabeformate sinnvoll.
So können Nodes implementiert werden, die eine Ausgabe als Postscript oder
in 3D-Austauschformate ermöglichen. Um die grafische Weiterverarbeitung der erzeugten
Darstellungen effizienter zu machen, bietet sich eine Exportfunktion für einzelne Teilbereiche
an. Beispielsweise können aus einem erzeugten Bild einzelne Ebenen exportiert werden.
\item[Interaktionsmöglichkeiten]
Zusätzlich zu einer rein statischen Darstellung können mit Datasynth
Interaktionsmöglichkeiten erzeugt werden. Eine automatische
Ausgabe als interaktive HTML5-Website ist denkbar, bei der einzelne Elemente
anklickbar und durch Benutzerinteraktion veränderbar sind. Außerdem sind 
Zoomfunktionen sinnvoll, um dem Betrachter weitere Möglichkeiten zur
Erkundung der grafischen Darstellung zu geben.
\item[Evaluation]
Datasynth kann dem Nutzer behilflich sein, die richtige Form
der grafischen Darstellung zu finden und ihn mit adäquaten Mitteln darauf
hinweisen, welche Darstellungen sich für einen gegebenen Datensatz besonders gut eignen.
\end{description}
    
\chapter{Anhang}
\section{Liste von bestehenden Softwarelösungen}
\label{sec:Softwareliste}
\begin{tabular}{l|l}
\hline
Name & Webadresse \\
\hline
d3 & http://mbostock.github.com/d3/\\
Gephi & http://gephi.org/\\
GGobi & http://www.ggobi.org/\\
Graphviz & http://www.graphviz.org/\\
InfoVis Toolkit & http://ivtk.sourceforge.net/\\
MAX 6 & http://cycling74.com/\\
MeVisLab & http://mevislab.de/\\
N-Land & http://davis.wpi.edu/~matt/courses/nland/cgi93.html\\
NodeBox 2 Beta & http://beta.nodebox.net/\\
prefuse & http://prefuse.org/\\
Processing & http://processing.org/\\
protovis & http://mbostock.github.com/protovis/\\
Pure Data & http://www.puredata.info/\\
VTK & http://www.vtk.org/\\
vvvv & http://www.vvvv.org/\\
\hline
\end{tabular}

\section{Liste aller implementierten Nodes}
\label{sec:alleNodes}
\centering
\begin{tabular}{|l|p{10cm}|}
\hline
\textbf{Node} & \textbf{Funktion}\\
\hline
Add & Addiert zwei Spreads miteinander und gibt ein Spread als Summe dieser zurück.\\
\hline
Substract & Zieht vom Spread der am ersten Input-Pin anliegt, den Spread vom zweiten Input-Pin ab und gibt die Differenz als Spread aus.\\
\hline
Multiply & Multipliziert zwei Spreads und gibt das Produkt als Spread aus.\\
\hline
Divide & Teilt den Spread am ersten Input-Pin durch den Spread der am zweiten Input-Pin anliegt und gibt das Ergebnis als Spread aus.\\
\hline
Modulo & Berechnet den Modulo zweier Spreads und gibt den Rest als Spread aus.\\
\hline
GreaterThan & Vergleicht zwei Spreads miteinander. Wenn der Spread am ersten Input-Pin größer
als der am zweiten Input-Pin ist, wird 1 zurückgegeben.\\
\hline
LessThan & Vergleicht zwei Spreads miteinander. Wenn der Spread am ersten Input-Pin kleiner
als der am zweiten Input-Pin ist, wird 1 zurückgegeben.\\
\hline
Min & Gibt den kleinsten Wert eines Spreads zurück.\\
\hline
Max & Gibt den größten Wert eines Spreads zurück.\\
\hline
Map & Verschiebt die Werte eines Spreads von einem Wertebereich in einen anderen.\\
\hline
Unique & Entfernt alle Duplikate eines Wertes aus einem Spread.\\
\hline
\end{tabular}

\begin{table}
\centering
\begin{tabular}{|l|p{10cm}|}
\hline
\textbf{Node} & \textbf{Funktion}\\
\hline
OutBox & Zeigt den Inhalt eines Spreads für den Benutzer an. Dieser Node hat keine Funktion für den Programmablauf sondern
dient dem Nutzer zur Kontrolle von Spreads.\\
\hline
Variable & Diesem Node kann der Benutzer einen skalaren Wert zuweisen. Damit wird am Output-Pin ein Spread mit einer einzigen
Variable erzeugt. Diese kann genutzt werden, um Berechnungen mit anderen Spreads durchzuführen.\\
\hline
CSVParser & Mit diesem Node hat der Benutzer die Möglichkeit, eine CSV-Datei zu importieren.
Die "`Spalten"' der Daten wird dabei als Spreads über die Output-Pins ausgegeben.\\
\hline
RGBColor & Erzeugt aus drei Input-Pins für die Farbkanäle Rot, Grün und Blau einen Spread mit Farbwerten. Dieser
kann von anderen Nodes benutzt werden, um ausgegebene grafische Elemente einzufärben.\\
\hline
Text & Gibt dem Nutzer die Möglichkeit Text einzugeben und als Spread weiterzuverarbeiten.\\
\hline
String & Zeichnet einen einfachen Text in der Ausgabe. Die Ausgabe des Textes kann durch die Position und die Farbe beeinflusst werden.\\
\hline
Line & Dieser Node zeichnet eine Linie. Der Node hat fünf Input-Pins, die Anfangskoordinaten, Endkoordinaten und Farbe
der Linie bestimmen.\\
\hline
Circle & Dieser Node zeichnet einen Kreis. Der Kreis ist bestimmt durch Koordinaten, Radius und Farbe. Der Node
hat dafür drei Input-Pins.\\
\hline
Rectangle & Dieser Node zeichnet ein Rechteck. Das Rechteck ist bestimmt durch Koordinaten, Breite, Höhe und Farbe.\\
\hline
Render & Dieser Node erzeugt ein weiteres Fenster, in dem der Benutzer die aktuelle Ausgabe überprüfen kann.
Wenn er mit der aktuellen Ausgabe zufrieden ist, kann er durch Tastendruck den Render-Node veranlassen, ein
hochauflösende Bilddatei zu erstellen.\\
\hline
\end{tabular}
\caption{Alle in Datasynth implementieren Nodes}
\label{tab:alleNodes}
\end{table}


\section{Beispiel: Temperaturen einer Wetterstation}
\label{sec:temperatures}
\centering
\includegraphics[width=14cm, height=15cm]{images/temperatures.pdf}

\section{Beispiel: Benutzeroberfläche}
\label{sec:gui}
\centering
\includegraphics[height=15cm]{images/gui.pdf}

\section{Beispiel: Medienunternehmen in den Stadtteilen Leipzigs}
\label{sec:companyclash}
\centering
\includegraphics[height=14cm]{images/companyclash.pdf}

\bibliography{diplom}
\listoftables
\listoffigures
%\printnomenclature
\end{document}

