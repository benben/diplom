\documentclass[a4paper, 12pt, DIVcalc, onepage, pdftex, headsepline, footsepline]{scrreprt}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{setspace}
\onehalfspacing

\usepackage[ngerman]{babel}
\usepackage{natbib}
\usepackage{url} %correct url display in cites

\usepackage[locale=DE]{siunitx}

\pagestyle{headings}

\typearea[current]{calc}

%add hyphenation later

\begin{document}
\title{Visuell programmierbarer Non-Standard-Informationsvisualisierer}
\author{Benjamin Knofe}
\subject{Diplomarbeit}
\publishers{Hochschule für Technik, Wirtschaft und Kultur Leipzig}
\dedication{Dank an \\ Pyry Jahkola, Philip Whitfield}
\maketitle
\tableofcontents

\chapter{Einleitung}
\label{cha:Einleitung}
Die Menge an digital gespeicherten Daten nimmt stetig zu. In 2011 werden laut einer neuen
Studie\footnote{Vgl. \citep{EMC}} voraussichtlich 1,8 Zettabyte\footnote{1 Zettabyte = \num{1d21}
Byte = 1.000.000.000.000 Gigabyte} an Daten erzeugt und kopiert. In nahezu allen Bereichen unseren
täglichen Lebens werden Daten erhoben, gemessen und gespeichert. Dazu zählen vor allem die Bereiche
der Wissenschaft, Wirtschaft und Kultur. Auch die Politik und Verwaltung unserer Gesellschaft
verfolgt eine neue Strategie im Umgang mit Daten. So haben Städte wie beispielsweise Leipzig eine 
API oder Staaten wie Großbritannien verfolgen ein Konzept für e-Government mit dem
Open-Data-Gedanken, um Daten frei verfügbar zu machen. Um diesen Entwicklungen Rechnung zu tragen,
müssen neue Strategien entwickelt werden, die diese Daten für die jeweiligen menschlichen Adressaten
sinnvoll extrahieren, aufzuarbeiten und darzustellen. Aus diesem Grund haben sich in den letzen 50
Jahren verschiedene Forschungsfelder, wie Statistik, Data Mining, Computergrafik als Teilgebiet der
Informatik und Computational Design entwickelt. Ein Forschungsgebiet welches Thema dieser Arbeit
sein soll, verbindet all diese Gebiete um den aktuellen Entwicklungen unserer digitalen Welt
Rechnung zu tragen: die Visualisierung. In diesem Forschungsgebiet wird die Frage geklärt wie immer
abstraktere und komplexer werdende Daten in einem für den Menschen adäquaten Weise aufbereitet und
dargestellt werden können, um die gewünschten Informationen in Form von Mustern, Wiederholungen und
Anomalien identifizieren zu können. Dabei zeichnet sich eine Entwicklung ab aus einem rein
wissenschaftlichen Kontext hin zu einem populären Bereich um alltägliche Probleme lösen zu können.
Auch wenn jede Fornm der Visualisierung konkrete Ziele hat, mit denen sehr spezielle Probleme gelöst
werden, addressieren diese nicht mehr nur Experten und Wissenschaftler. Auch alltägliche Anwendungen
wie soziale Netzwerke, der Einkauf Online oder im Supermarkt, die Suche nach Informationen im
Internet oder in der Bibliothelk können mit Visualisierung als Teil des User Interface unterstüzt
werden und müssen somit auch für ungeübte Anwender verständlich und benutzbar sein. Dabei sollte
die Visualisierung ansprechend sein und damit eine angenehme und ästhtisch ansprechende Benutzung
gewährlsieten zu können aber gleichzeitig auch intuitiv sein, um ohne Vorkenntnisse nutzen aus
dieser Form der Mensch-Maschine-Interaktion ziehen zu können. So kann die tägliche Arbeit
unterstützt werden, damit es Gelegenheitsanwendern leicht gemacht wird, Informationen und
Wissen noch besser mit anderen teilen zu können. Somit liegt es an den Tools, die den menschen
unterstützen und die möglichkeit geben, diese daten für ihre jeweiligen zwecke nutzen zu können.
dabei gibt es eine vielzahl von unterschiedlichen problemen und fragestellungen die gelöst werden
müssen.

\section{Problemstellung}
Die Visualisierung als Arbeitsfeld ist eine hochkomplexe, hochspezialisierte Wissenschaft bei der
mathematische, informationstechnische und gestalterische Grenzen beachtet und in Einklang gebracht
werden müssen. Da die Entwicklung unserer Informationsgesellschaft viel schneller voranschreitet als
die Entwicklung neuer tools und damit das verständnis der eigentlichen Adressaten (die menschen, für
die diese daten erhoben wurden) müssen neue Wege gefunden werden, dieses Problem zu lösen. So können
immer komplexere Datenstrukturen nicht mehr mit aktuell vorhandenen klassischen Softwarelösungen wie 
beispielsweise Tabellenkalkulationssoftware
einfach dargstellt werden. Stattdessen wird ein neuer tiefergehendender Ansatz und die dazugehörige
Software gebraucht um das Wesen der Daten, die Information, wieder begreifbar zu machen.
Es entstehen Softwarelösungen die auf Teilbereiche der Visualisierung wie beispielsweise der Medizin,
Biotechnologie oder der Geoinformationssysteme spezialisiert sind. Diese Anwendungen sind nur von
Wissenschaftlern oder spezialisierten Experten verwendbar und erfordern ein hohes Maß an Vorwissen
und Zeit.
Andere Benutzer entwickeln eigene Workflows um eine Visualisierung umzusetzen.
Dabei wird auf Tools zurückgegriffen die aus verwandten Bereichen, wie beisüpielsweise der
Grafiksoftware stammen.
Dadurch erhöht sich der Arbeitsaufwand und die Qualität leidet. Bis heute existiert keine
Softwarelösung die eine universelle Möglichkeit bietet alle Formen und Anwendungsbereiche von
Visualisierung zu adressieren um eine jeweils für die Anwendung und den Adressatenkreis adäquates
Ergebnis zu liefern.
In dieser Arbeit soll ein Lösungsversuch geliefert werden, der auf einen grundlegenden und
abstrakteren Ansatz der Visualisierung abzielt, als es bisherige Softwarelösungen getan haben.
Ergänzt wird dieser durch die Implementation eines Prototypen, der den Ansatz beispielhaft
implementiert.
Diese Software kann mithilfe von visueller Programmierung\footnote{Vgl. Kapitel X} gesteuert werden,
welches eines möglichst breites Spektrum an Benutzern zulässt. 

\section{Aufbau der Arbeit}
Um einen Lösungansatz für das Problem der einfachen und universellen Visualisierung zu finden, wird
in dieser Arbeit eine Reihenfolge von Schritten durchgeführt die eine Implementation eines
Prototypen zum Ziel haben.

In Kapitel \ref{cha:Grundlagen} im Abschnitt \ref{sec:DatenInfo} werden die Begriffe Daten und
Informationen definiert und im Kontext
der Visualisierung beschrieben. Dabei wird anhand des aktuellen Forschungsstandes gezeigt, dass diese
zwei Begriffe nicht immer abgrenzbar von einander sind und es in Bezug auf das jeweilige Arbeitsfeld
unterschiedliche Interpretationen möglich sind. Nun kann im Abschnitt \ref{sec:EigenschaftenDaten} auf die
unterschiedlichen Eigenschaften von Daten eingegangen werden. Dies gilt als Kriterienkatalog anhand
dessen die Daten in Abschnitt \ref{sec:KlassifikationDaten} klassifiziert werden können.
Im folgenden Abschnitt \ref{sec:Datentypen} werden die verschiedenen Datentypen behandelt, die Inhalt
von Daten sein können.
Ein System zur Beschreibung von grafischen Variablen als Zeichen in einem Zeichensystem zur Erstellung von
graphischen Darstellungen wird in Abschnitt \ref{sec:graphischeSemiologie} beschrieben.

Nachdem die Ausgangsbedingungen definiert sind wird in Kapitel \ref{cha:Informationsvisualisierung} die
Informationsvisualisierung beschrieben. Abschnitt \ref{sec:Definition} definiert den Begriff
der Informationsvisualisierung und nennt die Besonderheiten dieser im Vergleich zu technisch-wissenschaftlichen
Datenvisualisierung. Danach folgt im Abschnitt \ref{sec:Arbeitsfelder} eine Beschreibung zu teils verwandten
Arbeitsfeldern und zu Bereichen, die die Visualisierung als Werkzeug verwenden. Was das Ziel einer guten
Visualisierung? Wie kann man das messen? Und was macht eine gute Visualisierung aus? Diese Fragen werden
im Abschnitt \ref{sec:Ziele} geklärt. Im folgenden Abschnitt \ref{sec:Pipeline} wird der eigentliche Arbeitsablauf
einer Visualisierung anhand verschiedener Einteilungsmöglichkeiten beschrieben um danach in Abschnitt
\ref{sec:Grundprinzip} gesondert auf den Teil des "Mappings" eingegangen wird. Im nächsten Abschnitt
\ref{sec:Darstellungen} werden einige Visualisierungsbeispiele gezeigt.

Das Kapitel \ref{cha:Software} beschreibt nun die Konzeption einer Visualisierungssoftware.
Dabei werden in Abschnitt \ref{sec:Anforderungen} die aus den vorherigen Kapiteln resultierenden Anforderungen
beschrieben und dann in Abschnitt \ref{sec:Einschr} mögliche Grenzen beschrieben. Als nächstes
werden in Abschnitt \ref{sec:bestehendeSoftware} beispielhaft vorhandene Softwarelösungen auf die Anforderungen geprüft.

Im Kapitel \ref{cha:Umsetzung} wird die Implementation eines Prototyps beschrieben. Dabei wird in Abschnitt
\ref{sec:Technologien} auf die verwendeten grundlegenden Technologien eingegangen. Danach wird in Abschnitt
\ref{sec:visPro} das Konzept des benutzten User Interfaces beschrieben und Gründe für diese Entscheidung genannt.
Als letzter Punkt dieses Kapitels wird in Abschnitt \ref{sec:Kernfunktionen} beispielhaft Kernfunktionen
der Software mit dazugehörigen Quelltext gezeigt und erläutert.

Das vorletzte Kapitel \ref{cha:Auswertung} nennt in Abschnitt \ref{sec:Probleme} die Probleme, die während
der Entwicklung aufgetreten sind und wertet die Vorteile (Abschnitt \ref{sec:Vorteile}) und Nachteile
(Abschnitt \ref{sec:Nachteile}) aus.

Das Kapitel \ref{cha:Zusammenfassung} schließt die Arbeit mit einem Fazit in Abschnitt \ref{sec:Fazit} und
einem Ausblick in Abschnitt \ref{sec:Ausblick} ab.

\chapter{Grundlagen}
\label{cha:Grundlagen}
In diesem Teil der Arbeit wird auf die grundlegenden Begriffe eingegangen die einen Zugang
zum Arbeitsfeld der Visualisierung voraussetzen.
\section{Daten und Information}
\label{sec:DatenInfo}
Daten werden in \cite{Gabler} für den Bereich der Informatik als
\begin{quote}
zum Zweck der Verarbeitung zusammengefasste Zeichen, die aufgrund bekannter oder unterstellter Abmachungen
Informationen (d.h. Angaben über Sachverhalte und Vorgänge) darstellen
\end{quote}
beschrieben.
Betrachtung dieser Arbeit sind alle digital gespeicherten Daten.
Diese liegen in einer standardisierten Form vor und können für die elektrische Weiterverarbeitung
und Kommunikation genutzt werden. Dabei sind diese Daten formalisierte Repäsentationen einer
oder mehrerer Informationen. Daten können dabei aus der realen Welt stammen, beispielsweise erhoben durch
die Messung einer physikalischen Größe oder durch Speicherung digital erzeugter Daten, wie
beispielsweise Nutzungsprofile von Webseitenbesuchern.
Der Anwender dieser Daten ist daher nicht direkt an den Daten als solche interessiert, sondern
an den Informationen, die er mit verschiedenen Techniken aus diesen Daten gewinnen kann.

Der Begriff der Information ist schwer einzugrenzen und wird in unterschiedlichen Wissenschaften
in verschiedensten Weisen ausgelegt. Zur Zeit wird im philosophischen Bereich der Erkenntnistheorie versucht
einen allgemeingültigen Informationsbegriff zu bilden. Trotzdem kann noch lange nicht von einer
einheitlichen Theorie der Information gesprochen werden und es beschäftigen sich viele verschiedene
Gebiete wie die Informatik, Informationstheorie, Nachrichtentechnik und andere mit diesem
Begriff.\footnote{Vgl. \citep{wiki_info}} In \citep[S.\,3]{Hoeher} wird der Begriff wie folgt beschrieben:
\begin{quote}
Die Informationstheorie definiert Information als eine quantitativ bestimmbare Wissenzunahme durch
die Übermittlung von Zeichen in einem Kommunikationssystem.
\end{quote}
Information ist also ein Mittel der Kommunikation, die beim Empfänger einen Erkenntnisgewinn auslöst,
sofern dieser den Informationsinhalt entschlüsseln kann. Dafür müssen sich Sender und Empfänger
auf ein Zeichensystem\footnote{blablabla semiotik vgl. http://de.wikipedia.org/wiki/Semiotik} einigen.
In Bezug auf die grapische Darstellungen wird in \citep{Bertin} die Information als  transkribierbarer
Inhalt eines Gedankens definiert, das heißt die Information ist der Teil der Daten, die in einer
Visualisierung dargestellt werden kann. Die Visualisierung als solche hat die Aufgabe, diese Information
für den Menschen zu aufzudecken und in verständlicher Form aufzubereiten. Es wird eine Transformation
der Information aus den reinen Daten, die zwar diese Informationen enthalten, aber für den menschlichen
Betrachter nicht erfassbar sind, in ein leicht verständliches und intuitives Zeichensystem überführt.

Ausgangspunkt dieser Arbeit bilden Informationen die digital verarbeitbar und speicherbar sind.

\section{Eigenschaften von Daten}
\label{sec:EigenschaftenDaten}
In diesem Kapitel wird der Inhalt der Daten und die damit zu extrahierenden Informationen eingegrenzt.
Damit gelten Daten als Ausgangspunkt für die Konzeption einer Visualisierung. Die speziellen
Eigenschaften von DAten sind maßgeblich für weitere Schritte der Visualisierung (siehe auch Pipeline).
Die Kenntnis der Beschaffenheit der Daten ist unabdingbar.
\cite{Schumann} beschreibt ein Modell der Eigenschaften von Daten. Somit hat jeder Datensatz (als Menge von
Daten) folgende Eigenschaften nach denen er klassifiziert werden kann.
\begin{description}
\item[Beobachtungsraum]
Der Beobachtungsraum beschreibt den Raum in dem Daten erhoben werden. Dieser Raum kann ein
dreidimensionaler Raum sein, kann aber auch abstrakt beschrieben werden und nur eine einzige oder
mehr als drei Dimensionen enthalten. Alle Dimensionen die den Beobachtunsgraum aufspannen,
können als unabhängige Variablen(fußnote: kurze erklärung zu running clock / epoch-based) angesehen werden.
\item[Beobachtungspunkt]
Ein Beobachtungspunkt beschreibt Punkte im Beobachtungsraum an denen Daten vorhanden sind. Die Anzahl und Verteilung
dieser Punkte ist unabhängig von der Beschaffenheit des Beobachtungsraumes. Beobachtunsgpunkte haben einen
Wirkungskreis, der die "räumliche" Gültigkeit der Werte beschreibt. Dieser kann punktuell, lokal oder global sein.
\item[Merkmal]
Das Merkmal ist eine Größe die an einem Beobachtungspunkt gemessen oder berechnet wurde. Dabei können
einem Beobachtungspunkt mehrere Merkmale zugeordnet werden. Merkmale gelten dabei als abhängige Variablen.
\item[Ausprägung]
Die Ausprägung beschreibt den Wertebereich und damit alle Werte, die ein Merkmal annehmen kann.
Dabei sind die Datentypen Skalar, Vektor und Tensor möglich. (fußnote mit kurzer erklärung was das is)
\end{description}
Alle diese Eigenschaften können als Metadaten bezeichnet werden und genutzt werden um Daten zu klassifizieren.

\section{Klassifikation von Daten}
\label{sec:KlassifikationDaten}
Für die Klassifikation von Daten gibt es keine einheitlichen Begriffe. \citep{Schumann} unterteilt die Daten
in Varianz und Dimensionalität, während \citep{Preim} ausschließlich von Dimensionen spricht.
In dieser Arbeit werden die Begriffe nach \citep{Schumann} verwendet und mit den Begriffen aus \citep{Preim}
erweitert.
\begin{description}
\item[Multivariate Daten]
Bei multivariaten Daten existiert kein direkter Beobachtungsraum oder dieser kann vernachlässigt werden, da er
keine Rolle für die Weiterverarbeitung der Daten spielt. Sonderformen der multivariaten Daten sind die univariaten,
bivariaten und trivariaten Daten. (mehr beschreibung?!)
\item[Mehrdimensionale Daten]
Bei mehrdimensionalen Daten wird lediglich der Beobachtungsraum beschrieben. Dabei werden die abhängigen Variablen
vernachlässigt und nur die Anzahl der Dimensionen des Beobachtungsraumes beschreibt die Art der Daten.
Multivariate Daten können in multidimensionale Daten überführt werden.
\item[Multiparameterdaten]
sind Daten, die mindestens 2 Merkmale (abhängige Variablen) pro Beobachtungspunkt besitzen. Die Dimensionalität
(größer zwei oder ???), Anordnung und Wirkunsgkreis der Beobachtungspunkte sind beliebig.
Beispielsweise gilt eine SQL-Tabelle mit einer Spalte mit einer Ordnungsnummer und 3 Spalten bereits
als mutlivariater und mehrdimensionaler Datensatz.
Bei der Visualiserung von abhängigen und unabhängigen Variablen in einer Darstellung, sollte darauf geachtet
werden, dass die Unterscheidbarkeit der beiden Klassen gegeben bleibt.\footnote{Da Multiparameterdaten
allgemein sehr schwierig zu visualisieren sind schlägt \citep{Schumann} ein dreistufiges Vorgehen vor:
Focusing zur Auswahl der Daten, Bildgenerierung zur Erzeugung von visueller Repräsentationen, Linking
zur Verknüpfung von Teilsichten zu einer Gesamtansicht.}

bei schumann nochma direkt ins buch gucken!

\item[Raumbezogene Daten]
"Raumbezogene Daten liegen dann vor, wenn der Beobachtungsraum Ortskoordinaten enthält,
die ein 2- oder 3-dimensionales räumliches Bezugssystem definieren."\citep[S.\,219]{Schumann}
Das bedeutet das mindestens zwei und höchsten drei unabhängige Variablen des Datensatzes beispielsweise
ein Koordinatensystem beschreiben. Dieser Raumbezug kann direkt und indirekt erfolgen ist für
den normalen Anwender aber unverzichtbar.\footnote{dazu bitte kapitel XX von schumann lesen s.221}
Ein eindimensionaler Beobachtungsraum ist möglich. Dabei erfolgt die Abbildung zum Beispiel einer
Ordnungsnummer auf einer Linie. Außerdem kommt dem Geltungsbereich bei raumbezogenen Daten eine
besonder Bedeutung zu, da dieser hier auf garkeinen Fall vernachlässigt werden darf,
um Fehlinterpretationen zu vermeiden.
Eine spezielle Form der raumbezogenen Daten sind die Volumendaten, bei denen Beobachtunsgpunkte mit
genau einem skalaren Wert über ein regelmäßiges dreidimensionales Gitter verteilt sind.
\item[Zeitbezogene Daten]
Bie zeitbezogenen Daten kann mindestens eine unabhängige Variable in einen zeitlichen Kontext eingeordnet werden.
Der Zeitbezug kann dabei statisch (fester Zeitpunkt oder Intervall), quasistatisch (mehrere diskrete Zeitpunkte)
oder dynamisch (Zeitreihen) sein. Damit kann die Visualisierung als Unterstützung zur
Zeitreihenanalyse gesehen werden.
Als klassisches Beispiel gelten Börsen- oder Wetterdaten.
\item[Abstrakte Daten]
Bilden eine Sonderform der Daten, da weder ein raum noch ein zeitbezug möglich und sinnvoll ist. Oft dienen diese
Daten als Grundlage der Informationsviz (siehe das kapitel dazu) und stammen aus dem digitalen umfeld(?)
Als Beispiel können Aktienkurse, Verbindungsstatistiken von Netzwerkbetreibern und Relationen zwischen
Dokumenten, Medien und Personen genannt werden.\footnote{Vgl. \citep{Preim}} Als Beispiel für nicht-abstrakte
Daten gelten beispielsweise Wettermessungen an Wetterstationen oder Daten, die bei physikalischen Experimenten
gesammelt wurden. Abstrakte Dimensionen wie Namen von Städten oder Personen sollten als diese gekennzeichnet
werden und erkenn- und unterscheidbar sein. Zum Beispiel bietet sich eine Abbildung auf der X-Achse einer
Darstellung dafür an.
\item[Strukturelle Beziehungen zwischen Datenobjekten]
Diese Daten beschreiben nicht direkte Beobachtungspunkte und Merkmalsausprägungen sondern die Beziehung zwischen
abhängigen Variablen untereinander, unabhängigen Variablen untereinander oder zwischen abhängigen und unabhängigen
Variablen.
Unterschieden wird dabei noch zwischen hierarchischen Formen und Netzwerken. 
\end{description}

\section{Datentypen}
\label{sec:Datentypen}
Datentypen beschreiben die eigentlichen Ausprägungen eines Merkmals und können zu einer zusätzlichen
Klassifikation beitragen. Das ist wichtig um erkennen zu können welche Verarbeitungschritte mit den Datenwerten
möglich sind. Meist erfolgt eine Einteilung in drei Klassen. Während \citep{Bertin} von qualitativen,
geordneten und quantitativen Komponenten spricht, unterscheiden \citep{Preim} nominale, ordinale und
quantitative Datentypen. (Wo ist das bei Schumann?)
In dieser Arbeit werden die neueren Begriffe aus \citep{Preim} verwendet.
\begin{description}
\item[Nominale Datentypen]
beschreiben meist Namen von Datenobjekten. Ihr Abstand ist äquidistant, da vor einer eingehenden Analyse sich
keine Ausprägungen besonders nah oder entfernt stehen. Die einzige mögliche Operation ist der Test auf
Gleichheit beziehungsweise Ungleichheit. Es gibt keine allgemeingültige, eindeutige Reihenfolge
nach der sortiert werden könnte. Dadurch kann nur eine Reihenfolge nach bestimmten Gesichtpunkten erfolgen,
das heißt eine Ordnung eingebracht werden, zum Beispiel durch alphabetische Sortierung von Namen.
\item[Ordinale Datentypen]
haben die gleichen Voraussetzungen wie nominale Typen, außer für die Reihenfolge.
Diese ist bei diesem Typ allgemeingültig festgelegt. Als zusätzlicher Operator kann die Richtung der
Ausprägung durch die Ordnungsrelation genannt werden.
beispiel bei bertin glaub ich!
\item[Quantitative Datentypen] besitzen einen Wertebereich und gestatten die Durchfühung von arithmetischen Operationen. Es existiert eine
Maßeinheit mit der die Abstände zwischen einzelnen Ausprägungen angegeben werden können. Durch eine 
künstliche Einteilung in Intervalle kann dieser Typ in ordinale Datentypen übersetzt werden. Als Beispiel
dafür können Temperaturwerte beschrieben werden, die in kalt, warm und heiß unterteilt werden.
\end{description}
\section{Graphische Semiologie}
\label{sec:graphischeSemiologie}
Die graphische Semiologie ist ein in \citep{Bertin} erstmals beschriebenes System zur Klassifikation von graphischen Zeichen.
Es stammt ursprünglich aus der thematischen Kartographie\footnote{"`Thematische Karten enthalten vorwiegend
Erscheinungen oder Vorkommnisse nicht topographischer Art welche jedoch mit der Erdoberfläche in Verbindung
stehen. Es handelt sich hierbei um Dinge, die georäumliche Lage, Verbreitung oder Bewegung besitzen, sowohl
um reale Dinge, als auch um Beziehungen, Funktionen, Hypothesen, geistige Vorstellungen, Möglichkeiten und
Projekte."'\citep{Gitta} }. Dies ist ein Teilgebiet der Geographie, das erste Anwedungsgebiet für
Visualisierung.
Die Semiotik dieser Theorie definiert ein "`Grundalphabet"' an graphischen Elementen, wobei
jedem einzelnen Zeichen eine bestimmte Bedeutung zugeordnet wird. \citep{Bertin} geht dabei von einem
monosemiotischen\footnote{"`Die Betrachtung einer Zeichenverbindung setzt die Kenntnis der Bedeutung jedes
einzelnen Zeichens voraus."'\citep[S.\,3]{Bertin}} System aus, das den rationalen Teil der Bilderwelt, also der Diagramme
als graphische Darstellung eindeutig beschreibt.
Da Menschen aber bestimmten grafischen Zeichen unterschiedliche Bedeutungen zuordnen, muss ein "`rationaler Moment"'
stattfinden, bei dem sich alle an der Kommunikation Beteiligte auf Bedeutungen einigen
die bestimmte Zeichen haben. Erst dann kann über die Verbindung der Zeichen untereinander dikstutiert
werden. Diese Verbindungen entsprechen der eigentlichen Information.
Mit der graphischen Semiologie können also Informationen in ein graphische Zeichensystem
transkribiert werden.
Dieses System umfasst folgende acht Zeichen, die zur Kodierung von Daten in eine graphische Darstellung benutzt
werden können. Sie werden visuelle Variablen genannt.
\begin{itemize}
\item Position auf der Ebene (angegeben durch x und y)
\item Größe
\item Helligkeitswert
\item Musterung oder Textur
\item Farbe
\item Richtung oder Orientierung
\item Form des Elements
\end{itemize}
In Abbildung XX werden diese dargestellt.
Jede dieser Variablen hat spezifische Eigenschaften, die einzelne Variable unterschiedlich gut oder schlecht
für spezielle Aufgaben eignen. Um die Auswahl der geeignetesten Variablen zu vereinfachen, schlägt
\citep{Bertin} Konstruktionsregeln vor.
Mithilfe dieser Regeln lassen sich die visuellen Variablen auswählen, mit denen die
prägnanteste\footnote{siehe Abschnitt \ref{sec:Ziele}} Darstellung konstruiert werden kann.
Es werden dabei drei allgemeine Konstruktionsregeln definiert:
\begin{itemize}
\item graphische Darstellung mit möglichst wenig Elementen, sodass die graphische Darstellung
als Ganzes mi einem Minimum an Wahrnehmungsaufwand erfasst werden kann
\item graphische Darstellung vereinfachen, ohne die Zahl der Beziehungen zu verringern
\item graphische Darstellung durch Reduzierung vereinfachen
\end{itemize}
Zusätzlich zu diesen Regeln werden spezielle Regeln genannt. Diese sind stark abhängig von der Anzahl
der vorhandenen unabhängigen und abhängigen Variablen der Ausgangsdaten und der gewählten
grafischen Darstellung. So sollten beispielsweise für die wichtigsten und am deutlichsten
geordneten Variablen die zwei Ebenen der Fläche verwendet werden, während Variablen wie
Farbe und Muster als dritte Möglichkeit genutzt werden können um Informationen zu kodieren.
Erst wenn zusätzliche Variablen hinzugefügt werden, sollte eine Nebeneinanderstellung oder
Überlagerung benutzt werden.
Durch die Anwendung der Konstruktionsregeln können nun die visuellen Variablen genutzt werden um
die graphische Darstellung, als Ziel der Visualisierung, entstehen zu lassen.\footnote{Eine Definition
des Begriffs "`grapische Darstellung"' erfolgt im Abschnitt \ref{sec:Darstellungen}.}

\chapter{Informationsvisualisierung}
\label{cha:Informationsvisualisierung}
\section{Definition}
\label{sec:Definition}
Die Visualisierung im allgemeinen ist eine "rechnergestützte, visuelle Präsentation von Daten, Informationen und Wissen
in einer für den Menschen adäquaten und für die jeweilige Anwendung in diesem Kontext sinnvollen Form
zu verstehen."\citep[S.\,3]{Schumann}
Dabei wird die rein wissenschaftlich-technische Visualisierung beschrieben, die ausschließlich mit Ausgangsdaten arbeitet,
die einen physikalischen Bezugsrahmen und somit einen konkreten Orts- und Zeitbezug haben. Diese Form der
Visualiserung wird auch Datenvisualisierung genannt.
Da die Informationsdefinition bis jetzt nur quantitativ durchgeführt wurde\footnote{Vgl. Shannon}, stellen sich 
Fragen wie "Wie wichtig ist eine gegebene Information in einem gegegebenen Kontext?"\citep[S.\,341]{Schumann}
oder "Wie kann Menschen geholfen werden, diese Datenfülle zu überblicken, zu verstehen und Einsichten und Erkenntnisse
darüber zu gewinnen?"\citep[S.\,435]{Preim}.
Die Informationsvisualisierung als spezielle Form der Datenvisualisierung versucht Antworten auf solche
Fragen zu finden, die durch ein größeres Spektrum an unterschiedlichen Daten entstehen.
In \citep[S.\,434]{Preim} wird Informationsvisualisierung wie folgt definiert:
\begin{quote}
Informationsvisualisierung beschäftigt sich mit der Visualisierung vorrangig abstrakter Daten, wie
Multiparameterdaten(z.B. Medienobjekte mit verschiedenen Attributen), Hierarchien, Netzwerken, Text
oder Softwaresystemen, die sich alle auch über die Zeit verändern können.
\end{quote}
Das Einsatzgebiet ist nicht mehr nur auf wissenschaftliche Bereiche beschränkt,
sondern wird auch als alternative Suchmethode in Datenbanken\footnote{Vgl. Visual Data Mining KEIM},
als Wissensvermittlung in kulturellen Bereichen\footnote{Farben von Maccandless} und zur Visualisierung von
sozialen Netzwerken verwendet.
Insbesondere die Suche nach Beziehungen zwischen Datenobjekten steht dabei im Vordergrund,
da Informationsräume größer, komplexer und vernetzter werden und damit im Gegensatz
zu physikalischen Daten ein "mentales Bild"\footnote{Vgl. ???????????????????} fehlt.
Es besteht also keine Möglichkeit für räumliche Metaphern um einen Ortsbezug herzustellen.
Durch die Verschiebung der Inhalte der Datengrundlage aus dem wissenschaftlichen Kontext
in die Alltagskultur, ändern sich auch die Zielgruppe der Visualisierung. Durch das Internet
wird der Personenkreis stark vergrößert, der ein Interesse und Nutzen an Visualisierungen
haben kann, aber keinen mathematischen, natur- oder ingeneurswissenschaftlichen Hintergrund
hat. Damit entstehen weitere Anforderungen. So muss die Visualisierung vom Benutzer
schnell und einfach erfasst und ohne Vorkenntnisse verstanden werden können.
Außerdem muss sie eine "angemessene und grafische Qualität haben, um über den
reinen Nutzwert hinaus auch Qualitäten in Bezug auf Nutzungsfreude und Unterhaltungswert besitzen".\citep[S.\,438]{Preim}
Dafür reichen einfache Datentabellen und Tabellenkalkulationsprogramme wie beispielsweise Microsoft Excel
nicht mehr aus, um notwendige alternative Darstellungsformen zu finden.

Trotzdem muss erwähnt werden, dass die Grenzen zwischen den einzelnen Disziplinen fließend sind
und eine genaue Beschreibung dieser noch aussteht. Informationsvisualisierung kann durchaus
auch wissenschaftlich betrieben werden, da sich die Methoden und verfahren stark ähneln.

Somit adressiert das Arbeitsfeld der Informationsvisualisierung, die Thema dieser Arbeit ist,
einen Spezialfall der Datenvisualisierung, der alle Anforderungen an Datenvisualisierung enthält
und mit zusätztlichen Anforderungen, wie Zielgruppe, Repräsentation und Medium, erweitert. Dieses
Feld benutzt zur Erhebung, Speicherung, Weiterverarbeitung und Ausgabe ausschließlich digitale Techniken.
Der Begriff Visualisierung steht in dieser Arbeit synonym für Informationsvisualisierung.

\section{Verwandte Arbeitsfelder}
\label{sec:Arbeitsfelder}
Oft berühren Teilgebiete der Informationsvisualiserung verwandte Arbeitsfelder oder werden für die Problemlösung
in anderen Bereichen verwendet. Dieser Umstand macht für diese Arbeit eine klare Abgrenzung notwendig.
Nachfolgend werden Arbeitsgebiete beschrieben, die häufig mit der Informationsvisualisierung in Verbindung
gebracht oder sogar verwechselt werden. Häufig sind die Grenzen der einzelnen Arbeitsbereiche nicht klar
voneinander getrennt und eine genaue Abgrenzung dieser steht noch aus. Die nachfolgende Liste beschreibt nur
eine Auswahl und erhebt keinen Anspruch auf Vollständigkeit.
\begin{description}
\item[Computergrafik]
Die Computergrafik ist ein Teil der Informatik und beschreibt die Ausgabe von zwei- und dreidimensionalen
Objekten als Raster oder Vektorgrafik. Informationsvisualisierung benutzt diese Techniken, ist aber kein Teil
dieses Gebietes.
\item[Präsentations- und Prozessvisualisierung]
Häufig werden auch die Präsentationsvisualisierung und Prozessvisualisierung als Visualisierung bezeichnet, sind
aber eigene Gebiete in denen es auch um die Sichtbarmachung von Informationen geht, diese aber nicht aus
großen Datenmengen gewonnen wird und daher auch ohne Softwareunterstützung durchgeführt werden kann.
\item[Data Mining] ist der automatische Versuch, Datenmengen zu ordnen und Erkenntnisse darüber mithilfe
von Algorithmen zu finden. Im Gegensatz dazu versucht die Visualisierung eine geeignete grafische Repräsentation
bereitzustellen, die dem Nutzer die Möglichkeit gibt, diese Erklenntnisse selbst zu finden. Für die Datengewinnung
ist die Visualisierung auf Techniken des Data Minig angewiesen. Es gibt Bestrebungen beide Gebiete zu
Verbinden um Synergien zu bilden.\footnote{Vgl. Visual Data Mining KEIM}
\item[Interface- und Interactiondesign]
Diese Felder beschreiben die Gestaltung von Benutzeroberflächen. Damit arbeiten Sie wie die Visualisierung an
der Schnittstelle zwischen Mensch und Maschine. Interfacedesign benutzt häufig Techniken der Visualisierung
in Verbindung mit eigenen Arbeitsweisen um graphische Konzepte zu realisieren. Diese sind auch in diesem
Bereich primäre Form der Informationsübertragung.
\item[Computational Design]
Dieser von \citep{BenFry} eingeführte Begriff beschreibt die Vereinigung vieler Disziplinen zu einem neuen
interdisziplinären Arbeitsfeld. Die Visualisierung ist ein zentraler Bestandteil des Computational Design,
welches eine neue Form von ....
\end{description}

\section{Bearbeitungsziele}
\label{sec:Ziele}
Grundsätzlich ist das Ziel einer Visualisierung die Analyse einer gegebenen Datenmenge zu unterstützen und diese
Ergebnisse effizient präsentieren zu können und damit einen Erkenntnisgewinn zu schaffen.
So kann die Visualisierung nach \citep{Schumann} für folgende drei allgemeine Stufen der Analyse eingesetzt werden:
\begin{description}
\item[Explorative Analyse]
beschreibt die Daten selbst als Ausgangspunkt der Forschung. Durch interaktive und ungerichtete Suche in den Daten
mithilfe der Visualisierung soll eine Hypthese entwickelt werden. Dazu muss eine geeignete weit gefasste und nicht
beschränkte Darstellung gefunden werden
\item[Konfirmative Analyse]
Hier existieren bereits ein oder mehrere Hypothesen die mithilfe der Visualisierung überprüft werden soll.
\item[Präsentation]
Ergebnisse aus der Analyse der Daten werden mithilfe der Visualisierung dargestellt um sie für Dritte verständlich
zu machen und mit Ihnen über den Sachverhalt kommunizieren zu können.
\end{description}
Wichtig dabei ist vor allem in der Informationsvisualisierung eine ansprechende und ästhetische Darstellung, denn
ein guter Eindruck verstärkt den Willen sich mit einer Darstellung auseinanderzusetzen.

Um adäquate Visualisierungen klassifizieren zu können, nennen \citep{Schumann} drei Eigenschaften die eine
gelungene Visualisierung beschreiben. Diese sind Effektivität, Expressivität und Angemessenheit.
\begin{description}
\item[Expressivität]
Die Visualisierung soll nur die in den Daten enthaltenen Informationen möglichst unverfälscht wiedergeben.
\item[Effektivität]
Die Darstellung muss zu den visuellen Fähigkeiten des Betrachters, den Eigenschaften des Ausgabegerätes
passen.
\item[Angemessenheit]
Ressourcen und Rechenaufwand und damit die Kosten einer Visualisierung sollen den Anforderungen entsprechen.
\end{description}
Die Expressivität und Effektivität entspricht der einzigen Klassifikation aus \citep{Bertin}, die als Prägnanz bezeichnet wird.
\begin{quote}
Wenn eine Konstruktion zur Beantwortung einer gestellten Frage unter sonst gleichen Voraussetzungen eine
kürzere Betrachtungszeit erfordert als eine andere Konstruktion, so bezeichne man diese als prägnanter in
Bezug auf die gestellte Frage.\citep[S.\,17]{Bertin}
\end{quote}
Darüber hinaus ist es schwer allgemeingültige Aussagen treffen zu können, wie eine komplexer Sachverhalt und dessen
Informationen am effizientesten zu visualisieren ist, da die Visualisierung stark anwendungsabhängig ist und
immer von den Anforderungen Daten, Zielgruppe, Bearbeitungsziel, Repräsentation und Medium abhängig ist. 

\section{Visualisierungspipeline}
\label{sec:Pipeline}
es gibt mehrere aber ähnlich beschreibungen des ablaufs einer visualisierung.
ben fry und schumann  und preim
grafische Transkription (BERTIN)

MAPPING

Verbindung von Variablen der Information mit Variablen der Grafik.
dabei müssen die besonderheiten und merkmale der Komponenten der INFO (siehe bertin) klar sein und
müssen auf adäquate visuelle Variablen angewendet werden.
trotz einer nahezu unendlichen auswahl an möglichkeiten zur konstruktion einer grafik
sollten ein paar regeln beachtet werden (qualitative klassen nicht auf quantitative variablen usw.)

\section{Graphische Darstellung}
\label{sec:Darstellungen}
Die grafische Darstellung ist das Produkt einer Visualisierung mit dessen Hilfe
die Ziele aus Abschnitt \ref{sec:Ziele} erfüllt werden können. Sie besteht
immer aus den in Abschnitt \ref{sec:graphischeSemiologie} genannten
visuellen Variablen.

Bertin unterscheidet nur zwischen Diagramme / Netze / Karten

Begriff Diagramm?

verschiedene Darstellungsformen
sind alle stark anwendungsabhängig und es muss für jede anforderung festgelegt werden (siehe das kapitel
wo steht welche probleme man lösen kann (siehe schumann mit den 3 dingen einer viz, das letzte war kommunikation))
Preim/Dachselt ergänzen zu den von schumann genannten noch die viz von relationen als eigenständige klassifizierung von daten

hier die "datentypen" aufzählen

Auflsitung und kurze Beschreibungen aller möglichen Abbildungen (siehe Schumann S. 126)

begriff definieren als ergebnis einer visualisierung in digitaler oder realer form
enthält die 

hier ein paar wichtige vertreter der viz formen erklären und zeigen

doch wie können nun die unterschiedlichen Klassen von Daten auf die unterschiedlichen graphischen Variablen und damit
auf die unterschiedlichen graphischen Darstellungen angewendet werden um eine Visualisierung durchzuführen. das sehen
sehen sie im nächsten kapitel.

\chapter{Konzept einer geeigneten Softwarelösung}
\label{cha:Software}
\section{Grundprinzip der Informationsvisualisierung}
\label{sec:Grundprinzip}
Die Übetragung von symbolischen Informationen auf geometrische Informationen kann als grundlegendes Prinzip der
Visualisierung bezeichnet werden. Dieser Schritt ist die ausführende Stufe, die als Mapping in der
Visualisierungspipeline bezeichnet wird. Er wird in der Literatur als selbstverständlich angesehen, da damit
das Wesen der Visualisierung beschreibt. Bevor es zu diesem Schritt kommen kann, ist es aber umso komplexer
alle Ausgangsbedingungen zu beachten, die zu einer Visualisierung führen, die alle Bearbeitungsziele aus
Abschnitt \ref{sec:Ziele} erfüllt. Das bedeutet, dass alle Schritte vor dem Mapping wie zum Beispiel die Auswahl
aller Parameter die zu einer geigneten Visualisierung führen kann nicht von einer Software erledigt
werden sollten und stattdessen von einem Menschen in einem durchaus auch kreativen Prozess gefunden werden sollen.
Nur die arbeitsintensive Aufgabe der Übertragung der einzelnen Datenwerte auf die visuellen Variablen muss
parametrisiert vom Rechner übernommen werden, ohne das der Nutzer davor in seinem Findungsprozess eingeschränkt
worden ist. Der Nutzer kann somit völlig frei immer wieder Parameter verändern und die Ausgabe direkt steuern, währen der
Rechner alle Änderungen sofort auf die Ausgabe überträgt. Somit kann eine kreative Form der Auseinandersetzung
mit Daten gefunden werden, die neue Visualisierungsformen und damit neue Sichtweisen der Problemlösung
erschließen kann.


Wie Kapitel 1 und 2 zeigen gibt es eine Vielzahl an Daten und grafischen
Darstellungen. Zusätzlich dazu sind neue formen durch mash ups möglich
deshalb muss ein Ansatz gewählt werden  wo man nicht nur eine form der viz mit ihren vorteilen und nachteilen auswählen kann.
stattdessen soll ein tool alle freiheiten lassen, visuelle variablen frei mit den daten verbinden zu lassen

es ist schwer allgemeingültige aussagen zu treffen wie eine Information am besten visualisiert werden kann 
und somit muss eine Anwendung einen möglichst generischen ansatz bieten damit der benutzer ohne 
einschränkung seine spezielle aufgabe die er mit der viz lösen will lösen kann.

welche viz eignet sich am besten für meine konkrete aufgabe?
gibt es mischformen von bis jetzt gefundenen viz mit denen ich meine aufgabe noch besser lösen kann?
gibt es neue ansätze für viz die bis jetzt noch nicht beschrieben sind. (unterstützung der forschung nach neuen formen der viz)

um einen mgölcihst großen bereich aller öglichen viz formen abdecken zu können, wird daher ein ansatz gewählt, der dem benutzer erlaubt die atomaren elemente einer grafik automatisiert designen zu können. somit werden große mengen an datenpunkten in kürzester zeit darstellbar und weiterverarbeitbar.
beispielhafte implementierung “datasynth”
anforderung an so eine software (beispiel1: journalist, beispiel2: privat/künstler)
-> datasynth als Erkundungstool für daten, als datenleser (ist das nicht auch eine kompetenz die man entwickeln sollte: daten lesen und verstehen zu können, also heisst es nicht auch heutzutage und in zukunft immer mehr: daten verstehen heißt die welt verstehen)

Warum visuelle Programmierung? DEFINITION! und nochmal WARUM?
weil es dem zugrundeliegenden prinzip des MAPPING der viz entspricht

statt custom tools etc und immer wieder neu programmieren.....jetzt ein tool

komplexität hinter einem einfachen interface verstecken (klavier aus memo’s talk in london)

einordnung der software mit vergleichen zu anderen apps (grundlage sind funktionalität, also was kommt dabei raus) ist so ein ding zwischen statistiktool spss, 

iterativer prozess der exploration wird unterstützt (vgl. mantra visueller informationssuche) (vgl. preim/dachselt, s 443 ganz unten)

um den vielseitigen anforderungen an eine visualisierung gerecht zu werden, soll daher eine softwar entwickelt werden, die auf einem Level ansetzt den jeder Visualisierungsprozess durchlaufen muss: das Mapping bzw graphische Semiologie. Somit kann der gesamte Bereich der Visualisierungsmöglichkeiten theoretisch abgedeckt werden.

man kann jede visualisierung in ihre grundlegenden graphischen elemente zerlegen.
was sind die grundlegenden graphischen elemente? (herausfinden! vielleicht in bertin!)

\section{Rahmenbedingungen}
Für die Arbeit mit der Infomationsvisualisierung, speziell in Bezug auf die digitale
Transformation von Daten zu Grafiken gelten einige Rahmenbedingungen, die vor der
Konzeption einer Software der Informationsvisualisierung bedacht werden müssen.


Ein Großteil der Ausgabeformate sind zweidimensional\footnote{Es gibt immer wieder
Ansätze, die die 3D-Technik nutzen um Visualisierungen darzustellen. Diese Entwicklungen
müssen aber noch weiter erforscht werden um ihre Tauglichkeit zu prüfen.}. Dabei kann
die Ausgabe digital auf einem Display oder als Druck einer grafischen Darstellung
erfolgen. Soll eine grafische Darstellung benutzt werden, in der mehr als 2 Variablen
für die Positionierung der Grafikprimitive im Raum verwendet werden, muss daher für die
Ausgabe eine Projektion vorgenommen werden. Die Projektion ist die mathematische
Realisierung des Modells der virtuellen Kamera. In \citep[S.\,26]{Computergrafik} werden die 
Eigenschaften dieser Kamera wie folgt beschrieben:
\begin{itemize}
\item die Position der Kamera ist gegeben durch die Koordinaten eines Punkts;
\item der Bildausschnitt ist rechtwinklig;
\item der Schärfebereich der Kamera ist unendlich groß.
\end{itemize}
Für diese virtuelle Kamera wird in der Computergrafik die Zentralprojektion verwendet.
Bei dieser wird jeder Punkt im Raum mit einem Projektionsstrahl (in Form einer Geraden)
auf eine Ebene abgebildet. Die Ebene kann beispielsweise ein Monitor sein. Alle 
Projektionsstrahlen schneiden sich in einem Punkt außerhalb dieser Ebene, dem sogenannten
Projektionszentrum. Abbildung XXX veranschaulicht dieses Prinzip. Die Parallelprojektion
findet als Sonderfall der Zentralprojektion ebenfalls Anwendung.\footnote{Bei der
Parallelprojektion liegt das Projektionszentrum unendlich weit entfernt. Somit verlaufen
die Projektionsstrahlen parallel. Vgl. \citep{wiki_projektion}} Der Nutzen der virtuellen
Kamera kann durch Nutzerinteraktion erhöht werden. Der Anwender kann somit Parameter der
virtuellen Kamera, wie beispielsweise Position und Zoom selbst beeinflussen um den Fokus
auf einzelne Teilbereiche der grafischen Darstellung zu setzen.\footnote{Vgl. Focus und
.... Techniken in \citep[S.\,1]{Schumann} und \citep[S.\,1]{Preim}}

Durch die Eigenschaften heutiger Ausgabegeräte müssen durch die Visualisierung erzeugte
Grafiken gerastert werden. Die Technik der Rasterung überführt die kontinuierlichen Werte
einer Projektion in diskrete Werte des Geräte-Koordinatensystems. Dabei werden Werte
gerundet und in die zweidimensionale Matrix\footnote{Auflösung der Ausgabe in Pixel oder DPI}
des Ausgabegerätes übernommen.

Auch mögliche Farbwerte der einzelnen Bildpunkte und damit die Farbräume der Ausgabegeräte
müssen beachtet werden. Die Ausgabe auf Computermonitoren erfolgt im RGB-Farbraum während
für Druckerzeugnisse unterschiedliche Farbräume möglich sind.

Die Rahmenbedingungen der Bildsynthese konnten in diesem Abschnitt nur grundlegend beschrieben
werden. Eine tiefgreifendere Beschreibung des Themas erfolgt in \citep{Computergrafik}.

Die Daten und deren durch Visualisierung erzeugten visuellen Repräsentationen sind immer
gebunden an ihr Speicher- und Ausgabeformat.
Zuersteinmal müssen die Daten gesammelt und gespeichert werden. Dazu müssen adäquate
Formate gefunden werden, die die Software verarbeiten kann. Es gibt bereits
etablierte Ansätze große Datenmengen zu speichern und zu übertragen. Dazu müssen
die Daten maschinenlesbar codiert werden. Dabei kommen etablierte Formate wie
CSV und XML zum Einsatz. Daneben existieren noch weitere Formate mit spezifischen
Vor- un Nachteilen. JSON\footnote{JavaScript Object Notation} hat Ähnlichkeit mit XML,
ist dafür aber besser von Menschen lesbar. Im wissenschaftlichen Bereich findet
häufig das netCDF\footnote{bissi erklärung hier Vgl. \citep{Schumann}} Format
Anwendung. Neben diesen sehr bekannten Formaten, existieren noch einige weitere
Möglichkeiten, Daten zu speichern.

Zur Speicherung der graphischen Darstellungen einer Visualisierung eignen sich bekannte
Formate wie JPEG, PNG, BMP, TIFF und viele andere. Dabei müssen formatspezifische
Eigenschaften wie beispielsweise die Kompression beachtet werden.

Für die Mensch-Maschine-Interaktion stehen meist nur Maus und Tastatur zur Verfügung.
Außerdem gibt es neue Ansätze der Bewegungsteuerung mit Datenhandschuhen und
Kamera-Tracking zur Bewegungs- und Gestenerkennung. Diese müssen aber noch weiter
erforscht werden, bevor ein effizienter Einsatz in der Informationsvisualisierung
erfolgen kann.

Aus Sicht des Anwenders spielt außerdem die Wahrnehmungs- und Auflösungsfähigkeit
des menschlichen Auges eine Rolle und wieviel davon im Gehirn verarbeitet werden kann.
Dieser und andere Aspekte wird dem Arbeitsfeld der Kognitionspsychologie und
Neurowissenschaften zugeordnet und soll deshalb nur genannt bleiben.

\section{Anforderungen}
\label{sec:Anforderungen}
8 visuelle Variablen nach Bertin ((eine Anforderung an datasynth: muss alle diese abbilden können)):

möglichkeit alle datentypen abbilden bzw verarbeiten zu können
bearbeitungsziele sollen schnell und unkompliziert erfüllt werden können

möglichkeit alle informationstypen zu viz0

1. konkretisierung der eigenen problemstellung
software erstellen, was muss sie können, wofür soll sie da sein
also warum z.b. visuelles programmieren usw.
2. entwicklung von hypothesen (oder definition von anforderungen)
was muss die software leisten können?
3. ausführliche beschreibung Untersuchungsmethodik und Vorgehensweise
????

weil mit dem Grundprinzip der Abbildung gearbeitet wird, müssen alle Möglichkeiten dieser in der Software zur Verfügung stehen

keine vorgabe eines bestimmten system sondern die möglichkeit direkt mit grapischen primitiven und ihren attributen wie farb, etc. arbeiten zu können

cross-platformness

möglichst viel Parametrisiert um Wertebereiche direkt anpassen zu können
siehe auch abschnitt visuelle Programmierung










\section{Analyse bestehender Software}
\label{sec:bestehendeSoftware}
diskussion bisheriger lösungsansätze
vorstellen aller software die es bis jetzt gibt, siehe oben
evtl. (SWOT-)Analyse und damit aufzeigen der schwächen der anderen software

es gibt eine vielzahl unterschiedlichster programme und programmbibliotheken die genutzt werden können um daten zu visualisieren.
aus den verschiedenen bereichen: statistik, grafik, ...
es wird hier nur auf eine auswahl eingegangen, die elemente enthalten, die in datasynth sein sollten
vvvv
pd - Pure Data
prefuse
graphviz
...

Eine Liste aller untersuchten Software findet sich in Anhang XXX.



\chapter{Umsetzung eines Prototyps}
\label{cha:Umsetzung}
1. dokumentation der untersuchungsdurchführung (des Entwicklungsvorganges)
welche tools wurden wie angewendet, c++, of, git, boost, etc etc
2. darstellung der ergebnisse (verdeutlichung durch beispiele, erläuterung des erkenntnisfortschritts)
präsentation von viz mit der software?!

Einschränkungen durch Implementation

um der Bearbeitungszeit dieser Arbeit gerecht zu werden, kann nur eine prototypische Version implementiert werden.
aus diesem grund wird als freie Lizenz  öffentlich und transparent entwickelt, um die weiterentwicklung mit anderen weiterführen zu können


künstliche Grenzen weil ja nur Prototyp entwickelt wird.
statisch, 2D vollständigkeit wird durch dateninput festgelegt (vgl. schumann 6.2.1, s. 175)

Die Implementierung in dieser Arbeit beschränkt sich auf eine statische Ausgabe ohne Interaktionsmöglichkeiten,
kann aber dahingehend erweitert werden.\footnote{Vgl. Abschnitt \ref{sec:Ausblick}}

\section{Technologien}
\label{sec:Technologien}
C++
openFrameworks
boost
\section{visuelle programmierung}
\label{sec:visPro}
rapid prototyping / keine programmierkenntnisse erforderlich, ein durchschnittliches mathematisches verständnis reicht
theoretische konzeption
erklärung der einzelnen teile wie nodes etc doch erst bei implementierung?

soll unterstützend sein bei der arbeit mit dem eigentlichen thema und das wesen der problemlösung verdeutlichen

context switches vermeiden (siehe tufte 50) und die gleiche visuelle representation für das problem zeigen.
dadurch das (bei ausreichendem displayplatz) alle elemente des UI und die aktuelle Ausgabe angezeigt werden können, ist der nutzer nicht durch "context switches" abgelenkt und kann sich auf die data viz konzentrieren.
das gilt auch für das verändern von parametern, da im selben augenblick, wie parameter vom nutzer geändert werden, ändern sich auch die ausgabe.
damit kann der nutzer einerseits sofort erkennen was der parameter eigentlich macht und augenblicklich vergleichen und anpassen für seine präferierte lösung
\subsection{Spread}
\subsection{Node}
\subsection{Pin}
\subsection{Connection}
\section{wichtige Kernfunktionen}
\label{sec:Kernfunktionen}
auszüge aus quelltext mit erklärung
\chapter{Auswertung}
\label{cha:Auswertung}
bewertung der ergebnisse vor dem hintergrund der hypothesen/problemstellung (Test des konstrukts und vergleich mit den Anforderungen
was kann die software liefern? wofür bildet sie nur die grundlage? was kann sie nicht?

2. ableiten von schlußfolgerungen
????
so eine software macht sinn, macht keinen sinn?
\section{Probleme bei der Entwicklung}
\label{sec:Probleme}
reflection/introspection von c++
universelle datentypen (schwierig in c++)
geeignete daten finden
mulit-window ausgabe (gelöst mit ofxFenster, da glut das nicht hergibt)
\section{Vorteile}
\label{sec:Vorteile}
durhc parameter kann der benutzer die Wertebereiche der Abbildungen direkt verändern und kann somit auch ohne komplette kenntnis der daten live die beste "einstellung der parameter" herauszufinden, anstatt vorher Metadaten kennen bzw studieren bzw anlegen zu müssen (min,max, ...)

mehrere viz können statisch in einer präsentation kombiniert werden. so kann ohne benutzerinteraktion mehrere blickwinkel auf den datensatz ermöglicht werden

\section{Nachteile}
\label{sec:Nachteile}
benutzer hat alle freiheiten aber muss dadurch auch die grundregeln der viz beherrschen und verstehen ( z.b. kreis radius/fläche, was eignet sich für was am besten)
gestaltungsregeln müssen vom nutzer angwendet werden um viz zu verstärken
Klärung der möglichen Fragen, use nach BERTIN (Theorie des graphischen Bildes)

erweiterbarkeit:
wenn eine gewisse funktionalität noch nicht als node vorliegt, kann diese hinzuprogrammiert werden. verweis dabei auf die angedachten features zur erleichterung von nutzer entwicklungen mit beispielsweise ruby

das statische:
fehlende nutzerinteraktion und dadurch fehlende interaktive kombination von viz techniken (klick auf glyphe erzeugt eine genaue viz der werte dieses datenobjektes)

low-level-ansatz:
führt dazu, dass man immer vom urschleim anfangen muss um komplexe objekte zu erzeugen. deshalb wichtiges feature: kapselbarkeit von mehreren nodes zu einer komplexen high-level-node
so könnte man z.b. eine Sunburst node kreiiren die dann zwar 10 anstöpselmöglichkeiten hat aber sonst nix weiter
man benutzt grafische primitive und manche komplexe viz hat sehr viele primitive in komplexen abhängigkeiten, also kapseln

\chapter{Zusammenfassung}
\label{cha:Zusammenfassung}
1. zusammenfassung der ergebnisse, lesson learned
???
2. optional: persönliche bemerkungen, hinweis auf weiteren forschungsbedarf, ausblick in dei zukunft
was kannnoch alles an der Software getan werden?
\section{Fazit}
\label{sec:Fazit}
eignet sich die software?! JA NEEIN ?
\section{Ausblick}
\label{sec:Ausblick}
Da die software lediglich einen Prototypen darstellt ergeben sich mannigfalitge Erweiterungsmöglichkeiten. Hier sollen einige weniger, dafür aber sehr wichtige mögliche Erweiterungen genannt werden.

ruby
erweiterung auf andere bereiche des visualisierungsprozesses
kapselung von patches
  vielfältige möglichkeiten wie
    erweiterung und kapselung von verschiedenen viz templates als nodes (Isofläche Node oder Flow Ribbons)
    eigene erstellung von ikonen /vgl. schumann s. 197)
    (dazu erfüllt datasynth alle genannten anforderungen von sich aus (editor, binder, viewer)

v4p laden und speichern möglich! crazy!

erweiterung der ausgabemöglichkeiten (statt ausgabe auf bildschirm, ausgabe als postscript, ausgabe als interaktive 3D HTML5 Anwendung (dazu wären navigations und interaktionsmöglichkeiten notwendig (vgl. schumann s. 175), ...)

eng verbunden damit sind die möglichkeit allgemeine interaktionsmöglichkeiten einzubauen um parameter für beispielsweise selektionsbedingungen auch von end-anwendern der viz benutzbar zu machen

evaluationsmöglichkeit (wie kann ich schon in datasynth testen ob die ausgabe geeignet ist) (muss erforscht werden)

automatische generierung von legenden/skalen(+einteilungen), muss erforscht werden inwieweit das überhaupt machbar ist bei einem so universellen ansatz oder ob es nicht doch besser ist, diese dinge der nachbearbeitung zu überlassen (weil datasynth ja nur die massen-arbeit machen soll und nicht einzelne details am ende)

eventbasierte steuerung

threaded nodes

reiner export als abstrakte werte (koordinaten, höhe, breite, typ) in gängige 3D-Austausch-Formate

export von einzelnen teilbereichen (ebenen) zur graphischen weiterverarbeitung mit anderer software

\chapter{Anhang}
\section{Liste von bestehender Softwarelösungen}
todo: alle links zusammensuchen

Die nachfolgende Tabelle gibt eine unvollständige, aber umfassende
Liste an Softwarelösungen für die Visualisierung. Einige Anwendungen
sind auf Visualisierung großer Datenmengen spezialisiert, andere
berühren den Bereich nur mit einigen Funktionen.

\begin{tabular}{l|l}
\hline
Name & Webadresse \\
\hline
Pure Data & http://www.puredata.info/ \\
vvvv & http://www.vvvv.org/ \\
\end{tabular}
\section{Beispiel: Bevölkerungsdaten Stadt Leipzig}
viz mit streckenzügen (sternförmig, parallel), kreisen (matrix),

\bibliographystyle{natdin}
\bibliography{diplom}
\listoftables
\listoffigures
%\printnomenclature
\end{document}

