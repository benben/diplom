\documentclass[a4paper, 12pt, onepage, pdftex, headsepline, footsepline]{scrreprt}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{setspace}
\onehalfspacing

\usepackage[ngerman]{babel}
\usepackage{natbib}
\usepackage{url} %correct url display in cites

\pagestyle{headings}

\typearea[current]{calc}

%add hyphenation later

\begin{document}
\title{Visuell programmierbarer Non-Standard-Informationsvisualisierer}
\author{Benjamin Knofe}
\subject{Diplomarbeit}
\publishers{Hochschule für Technik, Wirtschaft und Kultur Leipzig}
\dedication{viele nette Leute}
\maketitle
\tableofcontents
\chapter{Einleitung}
%\section{Ein Abschnitt}
\label{sec:Einleitung}

Die Menge an digital gespeicherten Daten nimmt stetig zu. In 2011 werden laut einer neuen Studie\footnote{Vgl. \citep{EMC}}
voraussichtlich 1,8 Zettabyte\footnote{1 Zettabyte = 1.000.000.000.000 Gigabyte}
erzeugt und kopiert. In nahezu allen Bereichen unseren
täglichen Lebens werden Daten erhoben, gemessen und gespeichert. Dazu zählen vor allem die Bereiche
der Wissenschaft, Wirtschaft und Kultur. Auch die Politik und Verwaltung unserer Gesellschaft
verfolgt eine neue Strategie im Umgang mit Daten. So haben Städte wie beispielsweise Leipzig eine 
API oder Staaten wie Großbritannien verfolgen ein Konzept für e-Government mit dem
Open-Data-Gedanken, um Daten frei verfügbar zu machen. Um diesen Entwicklungen Rechnung zu tragen,
müssen neue Strategien entwickelt werden, die diese Daten für die jeweiligen menschlichen Adressaten
sinnvoll extrahieren, aufzuarbeiten und darzustellen. Aus diesem Grund haben sich in den letzen 50
Jahren verschiedene Forschungsfelder, wie Statistik, Data Mining, Computergrafik als Teilgebiet der
Informatik und Computational Design entwickelt. Ein Forschungsgebiet welches Thema dieser Arbeit
sein soll, verbindet all diese Gebiete um den aktuellen Entwicklungen unserer digitalen Welt
Rechnung zu tragen: die Visualisierung. In diesem Forschungsgebiet wird die Frage geklärt wie immer
abstraktere und komplexer werdende Daten in einem für den Menschen adäquaten Weise aufbereitet und
dargestellt werden können, um die gewünschten Informationen in Form von Mustern, Wiederholungen und
Anomalien identifizieren zu können. Dabei zeichnet sich eine Entwicklung ab aus einem rein
wissenschaftlichen Kontext hin zu einem populären Bereich um alltägliche Probleme lösen zu können.
Auch wenn jede Fornm der Visualisierung konkrete Ziele hat, mit denen sehr spezielle Probleme gelöst
werden, addressieren diese nicht mehr nur Experten und Wissenschaftler. Auch alltägliche Anwendungen
wie soziale Netzwerke, der Einkauf Online oder im Supermarkt, die Suche nach Informationen im
Internet oder in der Bibliothelk können mit Visualisierung als Teil des User Interface unterstüzt
werden und müssen somit auch für ungeübte Anwender verständlich und benutzbar sein. Dabei sollte
die Visualisierung ansprechend sein und damit eine angenehme und ästhtisch ansprechende Benutzung
gewährlsieten zu können aber gleichzeitig auch intuitiv sein, um ohne Vorkenntnisse nutzen aus
dieser Form der Mensch-Maschine-Interaktion ziehen zu können. So kann die tägliche Arbeit
unterstützt werden, damit es Gelegenheitsanwendern leicht gemacht wird, Informationen und
Wissen noch besser mit anderen teilen zu können. Somit liegt es an den Tools, die den menschen
unterstützen und die möglichkeit geben, diese daten für ihre jeweiligen zwecke nutzen zu können.
dabei gibt es eine vielzahl von unterschiedlichen problemen und fragestellungen die gelöst werden
müssen.

\section{Problemstellung}
Die Visualisierung als Arbeitsfeld ist eine hochkomplexe, hochspezialisierte Wissenschaft bei der
mathematische, informationstechnische und gestalterische Grenzen beachtet und in Einklang gebracht
werden müssen. Da die Entwicklung unserer Informationsgesellschaft viel schneller voranschreitet als
die Entwicklung neuer tools und damit das verständnis der eigentlichen Adressaten (die menschen, für
die diese daten erhoben wurden) müssen neue Wege gefunden werden, dieses Problem zu lösen. So können
immer komplexere Datenstrukturen nicht mehr mit aktuell vorhandenen klassischen Softwarelösungen wie 
beispielsweise Tabellenkalkulationssoftware
einfach dargstellt werden. Stattdessen wird ein neuer tiefergehendender Ansatz und die dazugehörige
Software gebraucht um das Wesen der Daten, die Information, wieder begreifbar zu machen.
Es entstehen Softwarelösungen die auf Teilbereiche der Visualisierung wie beispielsweise der Medizin,
Biotechnologie oder der Geoinformationssysteme spezialisiert sind. Diese Anwendungen sind nur von
Wissenschaftlern oder spezialisierten Experten verwendbar und erfordern ein hohes Maß an Vorwissen
und Zeit.
Andere Benutzer entwickeln eigene Workflows um eine Visualisierung umzusetzen.
Dabei wird auf Tools zurückgegriffen die aus verwandten Bereichen, wie beisüpielsweise der Grafiksoftware stammen.
Dadurch erhöht sich der Arbeitsaufwand und die Qualität leidet. Bis heute existiert keine
Softwarelösung die eine universelle Möglichkeit bietet alle Formen und Anwendungsbereiche von
Visualisierung zu adressieren um eine jeweils für die Anwendung und den Adressatenkreis adäquates
Ergebnis zu liefern.
In dieser Arbeit soll ein Lösungsversuch geliefert werden, der auf einen grundlegenden und
abstrakteren Ansatz der Visualisierung abzielt, als es bisherige Softwarelösungen getan haben.
Ergänzt wird dieser durch die Implementation eines Prototypen, der den Ansatz beispielhaft
implementiert.

2. problemstellung / ziel der arbeit
einen software prototypen zu entwickeln, der auf basis einer der grundprinzipien der visualisierung beruht: variablen von daten auf variablen der grafik anzuwenden

\section{Aufbau der Arbeit}
Um zu einem Läsungsansatz und der Beispielimplemntierung zu kommen wird die Arbeit wie folgt durchgeführt.
Im Kapitel X wird eine Klassifikation dieser beiden Begriffe in Hinblick auf die folgenden Vizualisierungsmethoden genommen werden.

3. methodisches vorgehen und aufbau
klärung der begriffe/probleme/einordnung in den workflow, festlegen der besten tools und patterns die software zu entwickeln, software beispielhaft implementieren Text.

\chapter{Grundlagen}
In diesem Teil der Arbeit wird auf die grundlegenden Begriffe eingegangen die einen Zugang
zum Arbeitsfeld der Visualisierung voraussetzen.
\section{Begriffsdefinition Daten und Information}
Daten werden in \cite{Gabler} für den allgemeinen Bereich der Informatik als "zum Zweck der Verarbeitung
zusammengefasste Zeichen, die aufgrund bekannter oder unterstellter Abmachungen Informationen
(d.h. Angaben über Sachverhalte und Vorgänge) darstellen" 
beschrieben.
Damit ähnelt sich die Definition von \cite{Gabler} mit der Definition des ISO 2382 Standards. 
Daten sind also die Träger der Information. Somit ist der Anwender nicht direkt an den Daten
als solche interessiert sondern an den Informationen, die er mit verschiedenen Techniken aus
diesen Daten gewinnen kann.
Betrachtung dieser Arbeit sind alle digital gespeicherten Daten.
eingrenzung auf digitale daten

daten in der wissenschaft haben immer einen räumlichen bezug. beispiel: messwerte in einem see, ...

Der Begriff der Information ist schwer einzugrenzen und wird in unterschiedlichen Wissenschaften
in verschiedensten Weisen ausgelegt. Auch in Bezug auf den Begriff der Daten gibt es keine klare Abgrenzung.
In der Informationstheorie wird die "Information als eine quantitativ
bestimmbare Wissenzunahme durch die Übermittlung von Zeichen in einem Kommunikationssystem" definiert (HÖHER).
Dabei spielt es ersteinmal keine Rolle welche Zeichen und welche Übertragungsform gewählt wird.
BERTIN versucht den Begriff in Bezug auf graphische Darstellungen einzugrenzen. So beschreibt er Information
als transribierbaren Inhalt eines Gedankens, der "aus einer oder mehrere in Bezug auf den Gedanken
ursprünglichen Beziehungen zwischen einer endlichen Menge von Variationsbegriffen und einer Invarianten” besteht.
(Was ist Varianten / Invarianten?)
BERTIN benutzt dabei ausschließlich den Begriff der Information, die mit einer graphischen Darstellung transkribiert
und kommuniziert werden soll.
(Hier noch ein bißchen mehr)
Der Begriff der Information soll in dieser Arbeit als Wissenzuwachs angenommen werden, der durch die
Visualisierung erreicht werden soll und aufgrund der reinen Daten, die zwar diese Informationen enthalten,
aber für den menschlichen Betrachter nicht erfassbar sind, nicht erkennbar wäre. Somit kann man sagen das die
Visualisierung eine Transformation der Information aus den Daten in ein leicht verständliches und intuitives
Zeichensystem für den Meschen überführt.

Informationsbegriff nach Bertin???
...

\section{Eigenschaften von Daten}

In diesem Kapitel wird der Inhalt der Daten und die damit zu extrahierenden Informationen eingegrenzt.
Damit gelten Daten als Ausgangspunkt für die Konzeption einer Visualisierung. Die speziellen
Eigenschaften von DAten sind maßgeblich für weitere Schritte der Visualisierung (siehe auch Pipeline).
Die Kenntnis der Beschaffenheit der Daten ist unabdingbar.
\cite{Schumann} beschreibt ein Modell der Eigenschaften von Daten. Somit hat jeder Datensatz (als Menge von
Daten) folgende Eigenschaften nach denen er klassifiziert werden kann.


Beobachtungsraum


Der Beobachtungsraum beschreibt den Raum in dem Daten erhoben werden. Dieser Raum kann ein
dreidimensionaler Raum sein, kann aber auch abstrakt beschrieben werden und nur eine einzige oder
mehr als drei Dimensionen enthalten. Alle Dimensionen die den Beobachtunsgraum aufspannen,
können als unabhängige Variablen(fußnote: kurze erklärung zu running clock / epoch-based) angesehen werden.


Beobachtungspunkt


Ein Beobachtungspunkt beschreibt Punkte im Beobachtungsraum an denen Daten vorhanden sind. Die Anzahl und Verteilung
dieser Punkte ist unabhängig von der Beschaffenheit des Beobachtungsraumes. Beobachtunsgpunkte haben einen
Wirkungskreis, der die "räumliche" Gültigkeit der Werte beschreibt. Dieser kann punktuell, lokal oder global sein.


Merkmal


Das Merkmal ist eine Größe die an einem Beobachtungspunkt gemessen oder berechnet wurde. Dabei können
einem Beobachtungspunkt mehrere Merkmale zugeordnet werden. Merkmale gelten dabei als abhängige Variablen.


Ausprägung


Die Ausprägung beschreibt den Wertebereich und damit alle Werte, die ein Merkmal annehmen kann.
Dabei sind die Datentypen Skalr, Vektor und Tensor möglich. (fußnote mit kurzer erklärung was das is)

Alle diese Eigenschaften können nun genutzt werden um Daten zu klassifizieren.


Metadaten

klassifizierung von informationen in bezug auf viz

was für daten können verwendet werden? wetterdaten? pachube, sämtliche (Web)-Apis

möchte sich diese arbeit mit der spezialform von daten, den abstrakten Daten beschäftigen, die keinen räumlichen
und oder zeitlichen bezug haben.
abstrakte daten haben alle anforderungen die auch normale daten haben und deswegen kann datasynth beides

\section{Klassifikation von Daten}


multivariate Daten


Bei multivariaten Daten existiert kein direkteer Beobachtungsraum oder dieser kann vernachlässigt werden, da er
keine Rolle für die Weiterverarbeitung der Daten spielt. Sonderformen der multivariaten Daten sind die univariaten,
bivariaten und trivariaten Daten. (mehr beschreibung?!)


mehrdimensionale Daten


Bei mehrdimensionalen Daten wird lediglich der Beobachtungsraum beschrieben. Dabei werden die abhängigen Variablen
vernachlässigt und nur die Anzahl der Dimensionen des Beobachtungsraumes beschreibt die Art der Daten.


raumbezogene Daten


"Raumbezogene Daten liegen dann vor, wenn der Beobachtungsraum Ortskoordinaten enthält,
die ein 2- oder 3-dimensionales räumliches Bezugssystem definieren." (SCHUMANN, Seite 219)
Das bedeutet das mindestens zwei und höchsten drei unabhängige Variablen des Datensatzes beispielsweise
ein Koordinatensystem beschreiben.


zeitbezogene Daten


Bie zeitbezogenen Daten kann mindestens eine unabhängige Variable in einen zeitlichen Kontext eingeordnet werden.
(PREIM / DACHSELT steht da glaub ich mehr) hier nochn beispiel.
und noch mehr dazu: statisch, quasistatisch, dynamisch


abstrakte Daten


Bilden eine Sonderform der Daten, da weder ein raum noch ein zeitbezug möglich und sinnvoll ist. Oft dienen diese
Daten als Grundlage der Informationsviz (siehe das kapitel dazu) und stammen aus dem digitalen umfeld(?)
Als Beispiel können Aktienkurse, Verbindungsstatistiken von Netzwerkbetreibern und Relationen zwischen
Dokumenten, Medien und Personen genannt werden.\footnote{Vgl. \citep{Preim}}


strukturelle Beziehungen zwischen Datenobjekten


Diese Daten beschreiben nicht direkte Beobachtungspunkte und Merkmalsausprägungen sondern die Beziehung zwischen
abhängigen Variablen untereinander, unabhängigen Variablen untereinander oder zwischen abhängigen und unabhängigen
Variablen.
(PREIM / DACHSELT) steht dazu was

\section{graphische Semiologie}

Die graphische Semiologie ist ein in \cite{Bertin} erstmals beschriebenes System zur Klassifikation von graphischen Zeichen.
Dabei wird versucht die grapische Darstellung auf ein "Grundalphabet" an graphischen Elementen zu reduzieren, wobei
jedem einzelnen Zeichen eine bestimmte Bedeutung zugeordnet wird. \citep{Bertin} spricht dabei von einem
monosemiotischen System aus, das den rationalen Teil der Bilderwelt, also der Diagramme
als graphische Darstellung eindeutig beschreibt.
Da Menschen aber bestimmten grafischen Zeichen unterschiedliche Bedeutungen zuordnen, muss ein "rationaler Moment" (VGL BERTIN)
stattfinden, bei dem sich alle an der Kommunikation Beteiligte auf Bedeutungen einigen die bestimmte Zeichen
haben. ERst dann kann über die Verbindung der Zeichen untereinander dikstutiert werden, was wiederrum der
Information entspricht.
Die graphische Semiologie ist also ein Zeichensystem mithilfe dessen Information in das graphische Zeichensystem
transkribiert werden kann.
Das graphische System umfasst folgende Zeichen die visuelle Variablen genannt werden.

*Position auf der Ebene (angegeben durch x und y)
*Größe
*Helligkeitswert
*Musterung oder Textur
*Farbe
*Richtung oder Orientierung
*Form des Elements

(hier das bild von bertin wo alle viz variablen dargestellt werden)

klärung und definition aller graphischen grundlagen
graphische semiologie?
was macht eine grafik eigentlich aus.....?

Diagramm?

graphische Semiologie
BERTIN spricht von grapischer Semiologie, also von einem genau festgelegten und endlichen Zeichensystem für die graphische Repräsentation von Information.
Information bedeutet dabei siehe BERtin 13 Somit fasst Bertin den Informationsbegriff etwas allgemeiner und fasst damit Daten ein. (stimmt das?)

8 visuelle Variablen nach Bertin ((eine Anforderung an datasynth: muss alle diese abbilden können)):

\section{graphische Darstellungen}

Die graphische Darstellung besteht aus graphischen Variablen.

hier ein paar wichtige vertreter der viz formen erklären und zeigen

doch wie können nun die unterschiedlichen Klassen von Daten auf die unterschiedlichen graphischen Variablen und damit
auf die unterschiedlichen graphischen Darstellungen angewendet werden um eine Visualisierung durchzuführen. das sehen
sehen sie im nächsten kapitel.

\chapter{Informationsvisualisierung}

\section{Definition}
Die Visualisierung im allgemeinen ist eine "rechnergestützte, visuelle Präsentation von Daten, Informationen und Wissen
in einer für den Menschen adäquaten und für die jeweilige Anwendung in diesem Kontext sinnvollen Form
zu verstehen."\citep[S.\,3]{Schumann}
Dabei wird die rein wissenschaftlich-technische Visualisierung beschrieben, die ausschließlich mit Ausgangsdaten arbeitet,
die einen physikalischen Bezugsrahmen und somit einen konkreten Orts- und Zeitbezug haben. Diese Form der
Visualiserung wird auch Datenvisualisierung genannt.
Da die Informationsdefinition bis jetzt nur quantitativ durchgeführt wurde\footnote{Vgl. Shannon}, stellen sich 
Fragen wie "Wie wichtig ist eine gegebene Information in einem gegegebenen Kontext?"\citep[S.\,341]{Schumann}
oder "Wie kann Menschen geholfen werden, diese Datenfülle zu überblicken, zu verstehen und Einsichten und Erkenntnisse
darüber zu gewinnen?"\citep[S.\,435]{Preim}.
Die Informationsvisualisierung als spezielle Form der Datenvisualisierung versucht Antworten auf solche
Fragen zu finden, die durch ein größeres Spektrum an unterschiedlichen Daten entstehen.
In \citep[S.\,434]{Preim} wird Informationsvisualisierung wie folgt definiert:
\begin{quote}
Informationsvisualisierung beschäftigt sich mit der Visualisierung vorrangig abstrakter Daten, wie
Multiparameterdaten(z.B. Medienobjekte mit verschiedenen Attributen), Hierarchien, Netzwerken, Text
oder Softwaresystemen, die sich alle auch über die Zeit verändern können.
\end{quote}
Das Einsatzgebiet ist nicht mehr nur auf wissenschaftliche Bereiche beschränkt,
sondern wird auch als alternative Suchmethode in Datenbanken\footnote{Vgl. Visual Data Mining KEIM},
als Wissensvermittlung in kulturellen Bereichen\footnote{Farben von Maccandless} und zur Visualisierung von
sozialen Netzwerken verwendet.
Insbesondere die Suche nach Beziehungen zwischen Datenobjekten steht dabei im Vordergrund,
da Informationsräume größer, komplexer und vernetzter werden und damit im Gegensatz
zu physikalischen Daten ein "mentales Bild"\footnote{Vgl. ???????????????????} fehlt.
Somit adressiert das Arbeitsfeld der Informationsvisualisierung, die Thema dieser Arbeit ist,
einen Spezialfall der Datenvisualisierung, der alle Anforderungen an Datenvisualisierung enthält
und mit zusätztlichen Anforderungen, wie Zielgruppe, Repräsentation und Medium, erweitert.
Der Begriff Visualisierung steht damit synonym für Informationsvisualisierung.
Durch die Verschiebung der Inhalte der Datengrundlage aus dem wissenschaftlichen Kontext
in die Alltagskultur, ändern sich auch die Zielgruppe der Visualisierung. Durch das Internet
wird der Personenkreis stark vergrößert, der ein Interesse und Nutzen an Visualisierungen
haben kann, aber keinen mathematischen, natur- oder ingeneurswissenschaftlichen Hintergrund
hat. Damit entstehen weitere Anforderungen. So muss die Visualisierung vom Benutzer
schnell und einfach erfasst und ohne Vorkenntnisse verstanden werden können.
Außerdem muss sie eine "angemessene und grafische Qualität haben, um über den
reinen Nutzwert hinaus auch Qualitäten in Bezug auf Nutzungsfreude und Unterhaltungswert besitzen".\citep[S.\,438]{Preim}
Dafür reichen einfache Datentabellen und Tabellenkalkulationsprogramme wie beispielsweise Microsoft Excel
nicht mehr aus, um notwendige alternative Darstellungsformen zu finden.

Trotzdem muss erwähnt werden, dass die Grenzen zwischen den einzelnen Disziplinen fließend sind
und eine genaue Beschreibung dieser noch aussteht. Informationsvisualisierung kann durchaus
auch wissenschaftlich betrieben werden, da sich die Methoden und verfahren stark ähneln.

\section{Abgrenzung}

Oft berühren Teilgebiete der Informationsvisualiserung verwandte Arbeitsfelder oder werden für die Problemlösung
in anderen Bereichen verwendet. Um die 
einordnung an der einteilung von ben fry

Computergrafik
Präsentationvisualisierung
Data Mining
Interfacedesign


Data Mining ist der automatische Versuch, Datenmengen zu ordnen und Erkenntnisse darüber mithilfe von Algorithmen zu finden (DEF? ZIZAT?)
Visualisierung versucht dabei eine geeignete grafische Repräsentation zu finden, die dem Nutzer selbst die Möglichkeit gibt,
diese Erklenntnisse zu finden.

verwandte Arbeitsfelder

viz ist auch ein teil des UI da visuelle repräsentation die primäre quelle der informationsübertragung ist, ob in text, bild oder grafiken.

Häufig sind die Grenzen der einzelnen Arbeitsbereiche nicht klar voneinander getrennt. Verwandte Arbeitsfelder sind (Visual) Data Mining, ....
Weiterhin ist die Visualisierung im allgemeinen ein Teil anderer Arbeitsbereiche. Zum Beispiel spielt die Vizualisierung im Interface Design eine ebenso wichtige Rolle wie im Data Mining.

Abgrenzung zu anderen Bereichen (vielleicht eigener gliederungspunkt) -> data mining.....
Abgrenzung nach innen (ben fry)

\section{Ziele}

was muss eine gute viz können?! (effektivität, expressivität, ...)

unterhaltungswert des graphen und ästhetik spielen eine rolle, denn man muss was gerne anschauen wollen damit man sich überhuapt damit auseinandersetzt
warum braucht man das? welche probleme werden damit gelöst?
welche anforderungen? (in welchen bereichen des täglichen lebens, der wirtschaft)

Welches Problem gibt es?
Warum?
Andere Lösungsansätze?
begrifflichkeit klären und sagen man verwendet ab jetzt nur noch viz stellvertretend für info/data-/sci-viz

sehr spezifische und stark anwendungs und erkenntnis gewinn abhängige anforderungen an visualisierung. 
es ist schwer allgemeingültige aussagen zu treffen wie eine Information am besten visualisiert werden kann und somit muss eine Anwendung einen möglichst generischen ansatz bieten damit der benutzer ohne einschränkung seine spezielle aufgabe die er mit der viz lösen will lösen kann.

erkenntnisgewinn und aufgabe die ich lösen möchte. also eine viz hat ja immer ein konkretes problem was der uafgabe zugrunde liegt und mit viz gelöst werden soll. (das nochmal genau klassifizieren)

welche viz eignet sich am besten für meine konkrete aufgabe?
gibt es mischformen von bis jetzt gefundenen viz mit denen ich meine aufgabe noch besser lösen kann?
gibt es neue ansätze für viz die bis jetzt noch nicht beschrieben sind. (unterstützung der forschung nach neuen formen der viz)

Was ist das Interaktionsziel? (Begriff klären)

diese arbeit bezieht sich auf informationsvisualisierung als sonderfall der datenvisualisietrung. damit werden alle dinge der datavz beachtet und zusätzlich alle sonderfälle der infoviz beachtet

wissenschaftlich, technisch, .... anwendungsgebiete?!
\section{Visualisierungspipeline}
es gibt mehrere aber ähnlich beschreibungen des ablaufs einer visualisierung.
ben fry und schumann  und preim
\section{Grundprinzip}
dieser schritt wird in der literatur als selbstverständlich angesehen. dagegen bedeuten die regeln wie man unterschiedliceh datentypen und in welcher form darstellt um das beste ergebnis auf eine bestimmte frage zu erhalten sind viel komplexer.
deshalb soll eine software entwickelt werden, die diese triviale aber für einen menschen sehr arbeitsintensive arbeit übernimmt, ohne dabei irgendwelchen einschränkugen zu unterliegen.

ein schritt in der viz pipeline

entwicklung einer kleinen "theorie"
wie können die grundprinzipien der viz auf eine software überrtragen werden?
welche vorteile/nachteile hat das?
welche probleme werden damit gelöst? (keine festlegung mehr auf balken.....)
welche neuen erkenntnisse können damit entstehen? (neue sichtweisen auf daten werden entdeckt, was wiederrum neue sichtweisen des eigentlichen problems aufzeigt)
zugriff und einfluß und übersicht auf alle parameter der geometrie und deren attribute....
dadurch: direkter einfluß aber auch direktes verständis der einzelnen elemente

grafische Transkription (BERTIN)

Auflsitung und kurze Beschreibungen aller möglichen Abbildungen (siehe Schumann S. 126)

als universellen in jeder viz theorie vorkommenden schritt

MAPPING

Verbindung von Variablen der Information mit Variablen der Grafik.
dabei müssen die besonderheiten und merkmale der Komponenten der INFO (siehe bertin) klar sein und müssen auf adäquate visuelle Variablen angewendet werden.
trotz einer nahezu unendlichen auswahl an möglichkeiten zur konstruktion einer grafik sollten ein paar regeln beachtet werden (qualitative klassen nicht auf quantitative variablen usw.)


verschiedene Darstellungsformen
sind alle stark anwendungsabhängig und es muss für jede anforderung festgelegt werden (siehe das kapitel wo steht welche probleme man lösen kann (siehe schumann mit den 3 dingen einer viz, das letzte war kommunikation))
Preim/Dachselt ergänzen zu den von schumann genannten noch die viz von relationen als eigenständige klassifizierung von daten

hier die "datentypen" aufzählen

\chapter{Konzept einer geeigneten Softwarelösung}
um einen mgölcihst großen bereich aller öglichen viz formen abdecken zu können, wird daher ein ansatz gewählt, der dem benutzer erlaubt die atomaren elemente einer grafik automatisiert designen zu können. somit werden große mengen an datenpunkten in kürzester zeit darstellbar und weiterverarbeitbar.
beispielhafte implementierung “datasynth”
anforderung an so eine software (beispiel1: journalist, beispiel2: privat/künstler)
-> datasynth als Erkundungstool für daten, als datenleser (ist das nicht auch eine kompetenz die man entwickeln sollte: daten lesen und verstehen zu können, also heisst es nicht auch heutzutage und in zukunft immer mehr: daten verstehen heißt die welt verstehen)

Warum visuelle Programmierung? DEFINITION! und nochmal WARUM?
weil es dem zugrundeliegenden prinzip des MAPPING der viz entspricht

statt custom tools etc und immer wieder neu programmieren.....jetzt ein tool

komplexität hinter einem einfachen interface verstecken (klavier aus memo’s talk in london)

einordnung der software mit vergleichen zu anderen apps (grundlage sind funktionalität, also was kommt dabei raus) ist so ein ding zwischen statistiktool spss, 

iterativer prozess der exploration wird unterstützt (vgl. mantra visueller informationssuche) (vgl. preim/dachselt, s 443 ganz unten)

um den vielseitigen anforderungen an eine visualisierung gerecht zu werden, soll daher eine softwar entwickelt werden, die auf einem Level ansetzt den jeder Visualisierungsprozess durchlaufen muss: das Mapping bzw graphische Semiologie. Somit kann der gesamte Bereich der Visualisierungsmöglichkeiten theoretisch abgedeckt werden.

man kann jede visualisierung in ihre grundlegenden graphischen elemente zerlegen.
was sind die grundlegenden graphischen elemente? (herausfinden! vielleicht in bertin!)
\section{Anforderungen}

möglichkeit alle datentypen abbilden bzw verarbeiten zu können
bearbeitungsziele sollen schnell und unkompliziert erfüllt werden können

möglichkeit alle informationstypen zu viz0

1. konkretisierung der eigenen problemstellung
software erstellen, was muss sie können, wofür soll sie da sein
also warum z.b. visuelles programmieren usw.
2. entwicklung von hypothesen (oder definition von anforderungen)
was muss die software leisten können?
3. ausführliche beschreibung Untersuchungsmethodik und Vorgehensweise
????

weil mit dem Grundprinzip der Abbildung gearbeitet wird, müssen alle Möglichkeiten dieser in der Software zur Verfügung stehen

keine vorgabe eines bestimmten system sondern die möglichkeit direkt mit grapischen primitiven und ihren attributen wie farb, etc. arbeiten zu können

möglichst viel Parametrisiert um Wertebereiche direkt anpassen zu können

cross-platformness

freie Lizenz

rails als beispiel für MIT Lizenz

\section{Grenzen der Software}
\subsection{technische Grenzen}
pixel (bildschirm)
farbe (rgb)
\subsection{theoretische Grenzen}
viz von mehr als 3 dimensionen -> projektion
\subsection{biologische Grenzen}
wahrnehmungs- und auflösungsfähigkeit des menschen
verständnis (wieviel kann ein mensch mit einmal überblicken)
\subsection{Grenzen durch Implementation}
künstliche Grenzen weil ja nur Prototyp entwickelt wird.
statisch, 2D vollständigkeit wird durch dateninput festgelegt (vgl. schumann 6.2.1, s. 175)

\section{Analyse bestehender Software}
diskussion bisheriger lösungsansätze
vorstellen aller software die es bis jetzt gibt, siehe oben
evtl. (SWOT-)Analyse und damit aufzeigen der schwächen der anderen software

es gibt eine vielzahl unterschiedlichster programme und programmbibliotheken die genutzt werden können um daten zu visualisieren.
aus den verschiedenen bereichen: statistik, grafik, ...
es wird hier nur auf eine auswahl eingegangen, die elemente enthalten, die in datasynth sein sollten
vvvv
pd - Pure Data
prefuse
graphviz
...
\chapter{Umsetzung eines Prototyps}
1. dokumentation der untersuchungsdurchführung (des Entwicklungsvorganges)
welche tools wurden wie angewendet, c++, of, git, boost, etc etc
2. darstellung der ergebnisse (verdeutlichung durch beispiele, erläuterung des erkenntnisfortschritts)
präsentation von viz mit der software?!
\section{Technologien}
C++
openFrameworks
boost
\section{visuelle programmierung}
rapid prototyping / keine programmierkenntnisse erforderlich, ein durchschnittliches mathematisches verständnis reicht
theoretische konzeption
erklärung der einzelnen teile wie nodes etc doch erst bei implementierung?

soll unterstützend sein bei der arbeit mit dem eigentlichen thema und das wesen der problemlösung verdeutlichen

context switches vermeiden (siehe tufte 50) und die gleiche visuelle representation für das problem zeigen.
dadurch das (bei ausreichendem displayplatz) alle elemente des UI und die aktuelle Ausgabe angezeigt werden können, ist der nutzer nicht durch "context switches" abgelenkt und kann sich auf die data viz konzentrieren.
das gilt auch für das verändern von parametern, da im selben augenblick, wie parameter vom nutzer geändert werden, ändern sich auch die ausgabe.
damit kann der nutzer einerseits sofort erkennen was der parameter eigentlich macht und augenblicklich vergleichen und anpassen für seine präferierte lösung
\subsection{Spread}
\subsection{Node}
\subsection{Pin}
\subsection{Connection}
\section{wichtige Kernfunktionen}
auszüge aus quelltext mit erklärung
\chapter{Auswertung}
bewertung der ergebnisse vor dem hintergrund der hypothesen/problemstellung (Test des konstrukts und vergleich mit den Anforderungen
was kann die software liefern? wofür bildet sie nur die grundlage? was kann sie nicht?

2. ableiten von schlußfolgerungen
????
so eine software macht sinn, macht keinen sinn?
\section{Probleme bei der Entwicklung}
reflection/introspection von c++
universelle datentypen (schwierig in c++)
geeignete daten finden
mulit-window ausgabe (gelöst mit ofxFenster, da glut das nicht hergibt)
\section{Vorteile}
durhc parameter kann der benutzer die Wertebereiche der Abbildungen direkt verändern und kann somit auch ohne komplette kenntnis der daten live die beste "einstellung der parameter" herauszufinden, anstatt vorher Metadaten kennen bzw studieren bzw anlegen zu müssen (min,max, ...)

mehrere viz können statisch in einer präsentation kombiniert werden. so kann ohne benutzerinteraktion mehrere blickwinkel auf den datensatz ermöglicht werden

\section{Nachteile}
benutzer hat alle freiheiten aber muss dadurch auch die grundregeln der viz beherrschen und verstehen ( z.b. kreis radius/fläche, was eignet sich für was am besten)
gestaltungsregeln müssen vom nutzer angwendet werden um viz zu verstärken
Klärung der möglichen Fragen, use nach BERTIN (Theorie des graphischen Bildes)

erweiterbarkeit:
wenn eine gewisse funktionalität noch nicht als node vorliegt, kann diese hinzuprogrammiert werden. verweis dabei auf die angedachten features zur erleichterung von nutzer entwicklungen mit beispielsweise ruby

das statische:
fehlende nutzerinteraktion und dadurch fehlende interaktive kombination von viz techniken (klick auf glyphe erzeugt eine genaue viz der werte dieses datenobjektes)

low-level-ansatz:
führt dazu, dass man immer vom urschleim anfangen muss um komplexe objekte zu erzeugen. deshalb wichtiges feature: kapselbarkeit von mehreren nodes zu einer komplexen high-level-node
so könnte man z.b. eine Sunburst node kreiiren die dann zwar 10 anstöpselmöglichkeiten hat aber sonst nix weiter
man benutzt grafische primitive und manche komplexe viz hat sehr viele primitive in komplexen abhängigkeiten, also kapseln

\chapter{Zusammenfassung}
1. zusammenfassung der ergebnisse, lesson learned
???
2. optional: persönliche bemerkungen, hinweis auf weiteren forschungsbedarf, ausblick in dei zukunft
was kannnoch alles an der Software getan werden?
\section{Fazit}
\section{Ausblick}
Da die software lediglich einen Prototypen darstellt ergeben sich mannigfalitge Erweiterungsmöglichkeiten. Hier sollen einige weniger, dafür aber sehr wichtige mögliche Erweiterungen genannt werden.

ruby
erweiterung auf andere bereiche des visualisierungsprozesses
kapselung von patches
  vielfältige möglichkeiten wie
    erweiterung und kapselung von verschiedenen viz templates als nodes (Isofläche Node oder Flow Ribbons)
    eigene erstellung von ikonen /vgl. schumann s. 197)
    (dazu erfüllt datasynth alle genannten anforderungen von sich aus (editor, binder, viewer)

v4p laden und speichern möglich! crazy!

erweiterung der ausgabemöglichkeiten (statt ausgabe auf bildschirm, ausgabe als postscript, ausgabe als interaktive 3D HTML5 Anwendung (dazu wären navigations und interaktionsmöglichkeiten notwendig (vgl. schumann s. 175), ...)

eng verbunden damit sind die möglichkeit allgemeine interaktionsmöglichkeiten einzubauen um parameter für beispielsweise selektionsbedingungen auch von end-anwendern der viz benutzbar zu machen

evaluationsmöglichkeit (wie kann ich schon in datasynth testen ob die ausgabe geeignet ist) (muss erforscht werden)

automatische generierung von legenden/skalen(+einteilungen), muss erforscht werden inwieweit das überhaupt machbar ist bei einem so universellen ansatz oder ob es nicht doch besser ist, diese dinge der nachbearbeitung zu überlassen (weil datasynth ja nur die massen-arbeit machen soll und nicht einzelne details am ende)

eventbasierte steuerung

threaded nodes

reiner export als abstrakte werte (koordinaten, höhe, breite, typ) in gängige 3D-Austausch-Formate

export von einzelnen teilbereichen (ebenen) zur graphischen weiterverarbeitung mit anderer software

\section*{Viz und so}

Text über viz mit einer Fußnote\footnote{Streng genommen eine ziemlich sinnfreie.}

\section*{Querverweise}

Aber er hat einen coolen Verweis, siehe .
Mal sehen wie das in einer Fußnote aussieht.

Um Querverweise nutzen zu können muss man z.B. auf Abschnitt~\ref{sec:testi} verweisen.

\bibliographystyle{natdin}
\bibliography{diplom}
\listoftables
\listoffigures
%\printnomenclature
\chapter{Anhang}
\section{Beispiel: Bevölkerungsdaten Stadt Leipzig}
viz mit streckenzügen (sternförmig, parallel), kreisen (matrix),
\end{document}

